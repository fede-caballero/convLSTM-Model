{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6399b35-6488-4a16-92d6-d7d9acfe944d",
   "metadata": {
    "id": "e6399b35-6488-4a16-92d6-d7d9acfe944d",
    "outputId": "689dccdb-fb13-4a4c-8968-ae9f4c6fbf56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTORCH_CUDA_ALLOC_CONF set to: expandable_segments:True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "print(f\"PYTORCH_CUDA_ALLOC_CONF set to: {os.environ.get('PYTORCH_CUDA_ALLOC_CONF')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a95315-21c1-41de-a409-09f3319d9b68",
   "metadata": {
    "id": "98a95315-21c1-41de-a409-09f3319d9b68",
    "outputId": "3902861a-46cd-4c01-af9c-d236f1cd9edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (2.1.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (1.15.3)\n",
      "Requirement already satisfied: netCDF4 in /opt/conda/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: xarray in /opt/conda/lib/python3.11/site-packages (2025.6.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.11/site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.10.3)\n",
      "Requirement already satisfied: cftime in /opt/conda/lib/python3.11/site-packages (from netCDF4) (1.6.4.post1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from netCDF4) (2024.8.30)\n",
      "Requirement already satisfied: packaging>=23.2 in /opt/conda/lib/python3.11/site-packages (from xarray) (24.1)\n",
      "Requirement already satisfied: pandas>=2.1 in /opt/conda/lib/python3.11/site-packages (from xarray) (2.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (0.14.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.58.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (72.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.1->xarray) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.1->xarray) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pyproj in /opt/conda/lib/python3.11/site-packages (3.7.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from pyproj) (2024.8.30)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install numpy scipy netCDF4 xarray torch torchvision torchaudio torchmetrics matplotlib\n",
    "!pip install pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "BrhYI9SSVo_t",
   "metadata": {
    "id": "BrhYI9SSVo_t",
    "outputId": "0a7831e7-cd07-446e-badb-1dc03a590380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.11/site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from gdown) (4.66.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-5.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f803dd-b188-46c0-96a9-496c8ae389ea",
   "metadata": {
    "id": "02f803dd-b188-46c0-96a9-496c8ae389ea",
    "outputId": "f621b64f-534d-4e6c-c68b-e27c2c70e147",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1kdTtKBjpQWNgijR7AH75t92KT-pptyNu\n",
      "From (redirected): https://drive.google.com/uc?id=1kdTtKBjpQWNgijR7AH75t92KT-pptyNu&confirm=t&uuid=b4d20672-77eb-4cfc-8de2-814bd84ab73f\n",
      "To: /home/sample.tar.gz\n",
      "100%|██████████████████████████████████████| 2.09G/2.09G [00:38<00:00, 54.8MB/s]\n",
      "/opt/conda/lib/python3.11/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1-pwMWi_eIH5z_J-RIhVg0vQNmpx1ijap\n",
      "From (redirected): https://drive.google.com/uc?id=1-pwMWi_eIH5z_J-RIhVg0vQNmpx1ijap&confirm=t&uuid=1da26544-b76a-4789-a3da-6526edf3da98\n",
      "To: /home/model.tar.gz\n",
      "100%|████████████████████████████████████████| 459M/459M [00:09<00:00, 49.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "!cd /home\n",
    "!gdown --id 1kdTtKBjpQWNgijR7AH75t92KT-pptyNu\n",
    "!gdown --id 1-pwMWi_eIH5z_J-RIhVg0vQNmpx1ijap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46053838-a6f8-4835-9572-b7a409d2f94a",
   "metadata": {
    "id": "46053838-a6f8-4835-9572-b7a409d2f94a",
    "outputId": "6a68f00c-b475-407f-90a5-ebbb4324abe1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample/\n",
      "sample/200712016/\n",
      "sample/200712016/042117.nc\n",
      "sample/200712016/043242.nc\n",
      "sample/200712016/051014.nc\n",
      "sample/200712016/044426.nc\n",
      "sample/200712016/044718.nc\n",
      "sample/200712016/042659.nc\n",
      "sample/200712016/050138.nc\n",
      "sample/200712016/051557.nc\n",
      "sample/200712016/045556.nc\n",
      "sample/200712016/043834.nc\n",
      "sample/200712016/050432.nc\n",
      "sample/200712016/045305.nc\n",
      "sample/200712016/045847.nc\n",
      "sample/200712016/042407.nc\n",
      "sample/200712016/042950.nc\n",
      "sample/200712016/050723.nc\n",
      "sample/200712016/043541.nc\n",
      "sample/2007010113/\n",
      "sample/2007010113/181556.nc\n",
      "sample/2007010113/180937.nc\n",
      "sample/2007010113/181905.nc\n",
      "sample/2007010113/175352.nc\n",
      "sample/2007010113/174426.nc\n",
      "sample/2007010113/180010.nc\n",
      "sample/2007010113/175703.nc\n",
      "sample/2007010113/174117.nc\n",
      "sample/2007010113/182830.nc\n",
      "sample/2007010113/174735.nc\n",
      "sample/2007010113/173808.nc\n",
      "sample/2007010113/180628.nc\n",
      "sample/2007010113/182215.nc\n",
      "sample/2007010113/181246.nc\n",
      "sample/2007010113/180319.nc\n",
      "sample/2007010113/175045.nc\n",
      "sample/2007010113/182524.nc\n",
      "sample/2007010122/\n",
      "sample/2007010122/235009.nc\n",
      "sample/2007010122/231524.nc\n",
      "sample/2007010122/234659.nc\n",
      "sample/2007010122/234349.nc\n",
      "sample/2007010122/232453.nc\n",
      "sample/2007010122/231215.nc\n",
      "sample/2007010122/232143.nc\n",
      "sample/2007010122/235628.nc\n",
      "sample/2007010122/230906.nc\n",
      "sample/2007010122/235318.nc\n",
      "sample/2007010122/233421.nc\n",
      "sample/2007010122/235937.nc\n",
      "sample/2007010122/231833.nc\n",
      "sample/2007010122/232802.nc\n",
      "sample/2007010122/233730.nc\n",
      "sample/2007010122/233112.nc\n",
      "sample/2007010122/234040.nc\n",
      "sample/200701229/\n",
      "sample/200701229/073614.nc\n",
      "sample/200701229/071749.nc\n",
      "sample/200701229/074529.nc\n",
      "sample/200701229/075138.nc\n",
      "sample/200701229/070225.nc\n",
      "sample/200701229/073309.nc\n",
      "sample/200701229/070834.nc\n",
      "sample/200701229/071138.nc\n",
      "sample/200701229/072357.nc\n",
      "sample/200701229/072053.nc\n",
      "sample/200701229/074833.nc\n",
      "sample/200701229/070529.nc\n",
      "sample/200701229/071443.nc\n",
      "sample/200701229/072701.nc\n",
      "sample/200701229/074224.nc\n",
      "sample/200701229/073005.nc\n",
      "sample/200701229/073920.nc\n",
      "sample/200610187/\n",
      "sample/200610187/040215.nc\n",
      "sample/200610187/040600.nc\n",
      "sample/200610187/041716.nc\n",
      "sample/200610187/042832.nc\n",
      "sample/200610187/044335.nc\n",
      "sample/200610187/041332.nc\n",
      "sample/200610187/035445.nc\n",
      "sample/200610187/043604.nc\n",
      "sample/200610187/043218.nc\n",
      "sample/200610187/040946.nc\n",
      "sample/200610187/042101.nc\n",
      "sample/200610187/043948.nc\n",
      "sample/200610187/042447.nc\n",
      "sample/200610187/044720.nc\n",
      "sample/200610187/035830.nc\n",
      "sample/200610187/035101.nc\n",
      "sample/200610187/034716.nc\n",
      "sample/2007012213/\n",
      "sample/2007012213/111804.nc\n",
      "sample/2007012213/105932.nc\n",
      "sample/2007012213/110238.nc\n",
      "sample/2007012213/103453.nc\n",
      "sample/2007012213/104104.nc\n",
      "sample/2007012213/110848.nc\n",
      "sample/2007012213/110543.nc\n",
      "sample/2007012213/103758.nc\n",
      "sample/2007012213/104714.nc\n",
      "sample/2007012213/104409.nc\n",
      "sample/2007012213/111155.nc\n",
      "sample/2007012213/105628.nc\n",
      "sample/2007012213/112111.nc\n",
      "sample/2007012213/105018.nc\n",
      "sample/2007012213/105323.nc\n",
      "sample/2007012213/103148.nc\n",
      "sample/2007012213/111500.nc\n",
      "sample/2007010121/\n",
      "sample/2007010121/231524.nc\n",
      "sample/2007010121/225629.nc\n",
      "sample/2007010121/232453.nc\n",
      "sample/2007010121/231215.nc\n",
      "sample/2007010121/232143.nc\n",
      "sample/2007010121/230906.nc\n",
      "sample/2007010121/230247.nc\n",
      "sample/2007010121/225938.nc\n",
      "sample/2007010121/225320.nc\n",
      "sample/2007010121/225012.nc\n",
      "sample/2007010121/231833.nc\n",
      "sample/2007010121/230557.nc\n",
      "sample/2007010121/224703.nc\n",
      "sample/2007010121/224046.nc\n",
      "sample/2007010121/232802.nc\n",
      "sample/2007010121/233112.nc\n",
      "sample/2007010121/224355.nc\n",
      "sample/200701297/\n",
      "sample/200701297/060820.nc\n",
      "sample/200701297/054540.nc\n",
      "sample/200701297/062433.nc\n",
      "sample/200701297/063416.nc\n",
      "sample/200701297/055209.nc\n",
      "sample/200701297/055837.nc\n",
      "sample/200701297/062118.nc\n",
      "sample/200701297/060151.nc\n",
      "sample/200701297/055523.nc\n",
      "sample/200701297/060506.nc\n",
      "sample/200701297/061449.nc\n",
      "sample/200701297/054855.nc\n",
      "sample/200701297/061134.nc\n",
      "sample/200701297/063731.nc\n",
      "sample/200701297/062747.nc\n",
      "sample/200701297/061803.nc\n",
      "sample/200701297/063102.nc\n",
      "sample/2007012223/\n",
      "sample/2007012223/205424.nc\n",
      "sample/2007012223/212444.nc\n",
      "sample/2007012223/211541.nc\n",
      "sample/2007012223/210630.nc\n",
      "sample/2007012223/205124.nc\n",
      "sample/2007012223/205725.nc\n",
      "sample/2007012223/210327.nc\n",
      "sample/2007012223/204822.nc\n",
      "sample/2007012223/204521.nc\n",
      "sample/2007012223/212142.nc\n",
      "sample/2007012223/211842.nc\n",
      "sample/2007012223/213046.nc\n",
      "sample/2007012223/210931.nc\n",
      "sample/2007012223/212745.nc\n",
      "sample/2007012223/213348.nc\n",
      "sample/2007012223/210026.nc\n",
      "sample/2007012223/204219.nc\n",
      "sample/2007010111/\n",
      "sample/2007010111/063117.nc\n",
      "sample/2007010111/070248.nc\n",
      "sample/2007010111/064045.nc\n",
      "sample/2007010111/063426.nc\n",
      "sample/2007010111/065322.nc\n",
      "sample/2007010111/062808.nc\n",
      "sample/2007010111/065014.nc\n",
      "sample/2007010111/065940.nc\n",
      "sample/2007010111/064705.nc\n",
      "sample/2007010111/062459.nc\n",
      "sample/2007010111/071216.nc\n",
      "sample/2007010111/063735.nc\n",
      "sample/2007010111/064355.nc\n",
      "sample/2007010111/071526.nc\n",
      "sample/2007010111/070557.nc\n",
      "sample/2007010111/070905.nc\n",
      "sample/2007010111/065630.nc\n",
      "sample/2007012219/\n",
      "sample/2007012219/171910.nc\n",
      "sample/2007012219/171306.nc\n",
      "sample/2007012219/175229.nc\n",
      "sample/2007012219/172211.nc\n",
      "sample/2007012219/174324.nc\n",
      "sample/2007012219/171004.nc\n",
      "sample/2007012219/173418.nc\n",
      "sample/2007012219/174022.nc\n",
      "sample/2007012219/173116.nc\n",
      "sample/2007012219/175531.nc\n",
      "sample/2007012219/172816.nc\n",
      "sample/2007012219/174626.nc\n",
      "sample/2007012219/174928.nc\n",
      "sample/2007012219/172513.nc\n",
      "sample/2007012219/175832.nc\n",
      "sample/2007012219/171608.nc\n",
      "sample/2007012219/173719.nc\n",
      "sample/200703219/\n",
      "sample/200703219/235222.nc\n",
      "sample/200703219/232919.nc\n",
      "sample/200703219/232042.nc\n",
      "sample/200703219/235808.nc\n",
      "sample/200703219/234636.nc\n",
      "sample/200703219/231205.nc\n",
      "sample/200703219/233757.nc\n",
      "sample/200703219/234050.nc\n",
      "sample/200703219/232626.nc\n",
      "sample/200703219/233212.nc\n",
      "sample/200703219/235515.nc\n",
      "sample/200703219/231457.nc\n",
      "sample/200703219/234343.nc\n",
      "sample/200703219/234929.nc\n",
      "sample/200703219/233505.nc\n",
      "sample/200703219/231750.nc\n",
      "sample/200703219/232334.nc\n",
      "sample/2007120110/\n",
      "sample/2007120110/135238.nc\n",
      "sample/2007120110/134402.nc\n",
      "sample/2007120110/133526.nc\n",
      "sample/2007120110/140415.nc\n",
      "sample/2007120110/132639.nc\n",
      "sample/2007120110/134110.nc\n",
      "sample/2007120110/141003.nc\n",
      "sample/2007120110/134654.nc\n",
      "sample/2007120110/132934.nc\n",
      "sample/2007120110/135533.nc\n",
      "sample/2007120110/140122.nc\n",
      "sample/2007120110/133818.nc\n",
      "sample/2007120110/141256.nc\n",
      "sample/2007120110/140709.nc\n",
      "sample/2007120110/135827.nc\n",
      "sample/2007120110/133229.nc\n",
      "sample/2007120110/134946.nc\n",
      "sample/200701299/\n",
      "sample/200701299/073248.nc\n",
      "sample/200701299/065344.nc\n",
      "sample/200701299/074550.nc\n",
      "sample/200701299/074235.nc\n",
      "sample/200701299/071316.nc\n",
      "sample/200701299/065659.nc\n",
      "sample/200701299/072932.nc\n",
      "sample/200701299/072302.nc\n",
      "sample/200701299/073604.nc\n",
      "sample/200701299/071000.nc\n",
      "sample/200701299/071946.nc\n",
      "sample/200701299/073919.nc\n",
      "sample/200701299/070643.nc\n",
      "sample/200701299/070013.nc\n",
      "sample/200701299/072617.nc\n",
      "sample/200701299/070328.nc\n",
      "sample/200701299/071631.nc\n",
      "sample/200701013/\n",
      "sample/200701013/020234.nc\n",
      "sample/200701013/012141.nc\n",
      "sample/200701013/013724.nc\n",
      "sample/200701013/020542.nc\n",
      "sample/200701013/021201.nc\n",
      "sample/200701013/020851.nc\n",
      "sample/200701013/014032.nc\n",
      "sample/200701013/013416.nc\n",
      "sample/200701013/015924.nc\n",
      "sample/200701013/015615.nc\n",
      "sample/200701013/012449.nc\n",
      "sample/200701013/014650.nc\n",
      "sample/200701013/013107.nc\n",
      "sample/200701013/014341.nc\n",
      "sample/200701013/012757.nc\n",
      "sample/200701013/014958.nc\n",
      "sample/200701013/015306.nc\n",
      "sample/2007012215/\n",
      "sample/2007012215/122556.nc\n",
      "sample/2007012215/125643.nc\n",
      "sample/2007012215/130254.nc\n",
      "sample/2007012215/130559.nc\n",
      "sample/2007012215/124424.nc\n",
      "sample/2007012215/121946.nc\n",
      "sample/2007012215/124120.nc\n",
      "sample/2007012215/121642.nc\n",
      "sample/2007012215/125949.nc\n",
      "sample/2007012215/122901.nc\n",
      "sample/2007012215/125338.nc\n",
      "sample/2007012215/123816.nc\n",
      "sample/2007012215/125034.nc\n",
      "sample/2007012215/123510.nc\n",
      "sample/2007012215/124728.nc\n",
      "sample/2007012215/122250.nc\n",
      "sample/2007012215/123204.nc\n",
      "sample/200702255/\n",
      "sample/200702255/211425.nc\n",
      "sample/200702255/205952.nc\n",
      "sample/200702255/205403.nc\n",
      "sample/200702255/210540.nc\n",
      "sample/200702255/204222.nc\n",
      "sample/200702255/203631.nc\n",
      "sample/200702255/203926.nc\n",
      "sample/200702255/205657.nc\n",
      "sample/200702255/204517.nc\n",
      "sample/200702255/205107.nc\n",
      "sample/200702255/203041.nc\n",
      "sample/200702255/202747.nc\n",
      "sample/200702255/210246.nc\n",
      "sample/200702255/210835.nc\n",
      "sample/200702255/203336.nc\n",
      "sample/200702255/202450.nc\n",
      "sample/200702255/204812.nc\n",
      "sample/2006102113/\n",
      "sample/2006102113/225834.nc\n",
      "sample/2006102113/225443.nc\n",
      "sample/2006102113/223529.nc\n",
      "sample/2006102113/231359.nc\n",
      "sample/2006102113/231008.nc\n",
      "sample/2006102113/223920.nc\n",
      "sample/2006102113/225053.nc\n",
      "sample/2006102113/221228.nc\n",
      "sample/2006102113/222747.nc\n",
      "sample/2006102113/224702.nc\n",
      "sample/2006102113/230224.nc\n",
      "sample/2006102113/223138.nc\n",
      "sample/2006102113/222357.nc\n",
      "sample/2006102113/230615.nc\n",
      "sample/2006102113/224311.nc\n",
      "sample/2006102113/221618.nc\n",
      "sample/2006102113/222007.nc\n",
      "sample/200712012/\n",
      "sample/200712012/013440.nc\n",
      "sample/200712012/014855.nc\n",
      "sample/200712012/014311.nc\n",
      "sample/200712012/013150.nc\n",
      "sample/200712012/011153.nc\n",
      "sample/200712012/014601.nc\n",
      "sample/200712012/010810.nc\n",
      "sample/200712012/014021.nc\n",
      "sample/200712012/012316.nc\n",
      "sample/200712012/011734.nc\n",
      "sample/200712012/012026.nc\n",
      "sample/200712012/010500.nc\n",
      "sample/200712012/013731.nc\n",
      "sample/200712012/012859.nc\n",
      "sample/200712012/010208.nc\n",
      "sample/200712012/012607.nc\n",
      "sample/200712012/011443.nc\n",
      "sample/200712015/\n",
      "sample/200712015/034318.nc\n",
      "sample/200712015/041212.nc\n",
      "sample/200712015/040919.nc\n",
      "sample/200712015/035147.nc\n",
      "sample/200712015/033144.nc\n",
      "sample/200712015/040624.nc\n",
      "sample/200712015/041824.nc\n",
      "sample/200712015/034021.nc\n",
      "sample/200712015/041532.nc\n",
      "sample/200712015/035743.nc\n",
      "sample/200712015/035450.nc\n",
      "sample/200712015/033436.nc\n",
      "sample/200712015/040036.nc\n",
      "sample/200712015/034609.nc\n",
      "sample/200712015/034858.nc\n",
      "sample/200712015/033729.nc\n",
      "sample/200712015/040329.nc\n",
      "sample/200610191/\n",
      "sample/200610191/014109.nc\n",
      "sample/200610191/014454.nc\n",
      "sample/200610191/015952.nc\n",
      "sample/200610191/015608.nc\n",
      "sample/200610191/011459.nc\n",
      "sample/200610191/013725.nc\n",
      "sample/200610191/011115.nc\n",
      "sample/200610191/014838.nc\n",
      "sample/200610191/015223.nc\n",
      "sample/200610191/013340.nc\n",
      "sample/200610191/010731.nc\n",
      "sample/200610191/012956.nc\n",
      "sample/200610191/010347.nc\n",
      "sample/200610191/012611.nc\n",
      "sample/200610191/012227.nc\n",
      "sample/200610191/011843.nc\n",
      "sample/200610191/010003.nc\n",
      "sample/2006102115/\n",
      "sample/2006102115/233315.nc\n",
      "sample/2006102115/225834.nc\n",
      "sample/2006102115/231751.nc\n",
      "sample/2006102115/235623.nc\n",
      "sample/2006102115/225443.nc\n",
      "sample/2006102115/234059.nc\n",
      "sample/2006102115/231359.nc\n",
      "sample/2006102115/231008.nc\n",
      "sample/2006102115/232533.nc\n",
      "sample/2006102115/232142.nc\n",
      "sample/2006102115/232924.nc\n",
      "sample/2006102115/233709.nc\n",
      "sample/2006102115/230224.nc\n",
      "sample/2006102115/235232.nc\n",
      "sample/2006102115/230615.nc\n",
      "sample/2006102115/234450.nc\n",
      "sample/2006102115/234841.nc\n",
      "sample/200610211/\n",
      "sample/200610211/004401.nc\n",
      "sample/200610211/001359.nc\n",
      "sample/200610211/004016.nc\n",
      "sample/200610211/002515.nc\n",
      "sample/200610211/010249.nc\n",
      "sample/200610211/005904.nc\n",
      "sample/200610211/001013.nc\n",
      "sample/200610211/005133.nc\n",
      "sample/200610211/000242.nc\n",
      "sample/200610211/003631.nc\n",
      "sample/200610211/002129.nc\n",
      "sample/200610211/005518.nc\n",
      "sample/200610211/002900.nc\n",
      "sample/200610211/003245.nc\n",
      "sample/200610211/004747.nc\n",
      "sample/200610211/000628.nc\n",
      "sample/200610211/001744.nc\n",
      "sample/200702257/\n",
      "sample/200702257/222406.nc\n",
      "sample/200702257/223250.nc\n",
      "sample/200702257/222955.nc\n",
      "sample/200702257/225308.nc\n",
      "sample/200702257/224133.nc\n",
      "sample/200702257/221820.nc\n",
      "sample/200702257/222113.nc\n",
      "sample/200702257/224427.nc\n",
      "sample/200702257/220643.nc\n",
      "sample/200702257/221230.nc\n",
      "sample/200702257/221525.nc\n",
      "sample/200702257/220936.nc\n",
      "sample/200702257/224720.nc\n",
      "sample/200702257/222701.nc\n",
      "sample/200702257/223543.nc\n",
      "sample/200702257/223837.nc\n",
      "sample/200702257/225014.nc\n",
      "sample/200701221/\n",
      "sample/200701221/000417.nc\n",
      "sample/200701221/002240.nc\n",
      "sample/200701221/005019.nc\n",
      "sample/200701221/004106.nc\n",
      "sample/200701221/003458.nc\n",
      "sample/200701221/000112.nc\n",
      "sample/200701221/003802.nc\n",
      "sample/200701221/001633.nc\n",
      "sample/200701221/002850.nc\n",
      "sample/200701221/004715.nc\n",
      "sample/200701221/001328.nc\n",
      "sample/200701221/001024.nc\n",
      "sample/200701221/000720.nc\n",
      "sample/200701221/003154.nc\n",
      "sample/200701221/004410.nc\n",
      "sample/200701221/002545.nc\n",
      "sample/200701221/001936.nc\n",
      "sample/2006102111/\n",
      "sample/2006102111/223529.nc\n",
      "sample/2006102111/213400.nc\n",
      "sample/2006102111/214924.nc\n",
      "sample/2006102111/221228.nc\n",
      "sample/2006102111/213751.nc\n",
      "sample/2006102111/222747.nc\n",
      "sample/2006102111/223138.nc\n",
      "sample/2006102111/222357.nc\n",
      "sample/2006102111/220055.nc\n",
      "sample/2006102111/214141.nc\n",
      "sample/2006102111/215314.nc\n",
      "sample/2006102111/220838.nc\n",
      "sample/2006102111/214532.nc\n",
      "sample/2006102111/221618.nc\n",
      "sample/2006102111/220446.nc\n",
      "sample/2006102111/215704.nc\n",
      "sample/2006102111/222007.nc\n",
      "sample/200702259/\n",
      "sample/200702259/233636.nc\n",
      "sample/200702259/235355.nc\n",
      "sample/200702259/234222.nc\n",
      "sample/200702259/235101.nc\n",
      "sample/200702259/232754.nc\n",
      "sample/200702259/235649.nc\n",
      "sample/200702259/232207.nc\n",
      "sample/200702259/234514.nc\n",
      "sample/200702259/230737.nc\n",
      "sample/200702259/235941.nc\n",
      "sample/200702259/231325.nc\n",
      "sample/200702259/232501.nc\n",
      "sample/200702259/234807.nc\n",
      "sample/200702259/233929.nc\n",
      "sample/200702259/233343.nc\n",
      "sample/200702259/231031.nc\n",
      "sample/200702259/233049.nc\n",
      "sample/2007012221/\n",
      "sample/2007012221/194440.nc\n",
      "sample/2007012221/191429.nc\n",
      "sample/2007012221/190522.nc\n",
      "sample/2007012221/192935.nc\n",
      "sample/2007012221/193537.nc\n",
      "sample/2007012221/192634.nc\n",
      "sample/2007012221/193839.nc\n",
      "sample/2007012221/192330.nc\n",
      "sample/2007012221/192029.nc\n",
      "sample/2007012221/191729.nc\n",
      "sample/2007012221/190221.nc\n",
      "sample/2007012221/191124.nc\n",
      "sample/2007012221/185618.nc\n",
      "sample/2007012221/190823.nc\n",
      "sample/2007012221/193236.nc\n",
      "sample/2007012221/185920.nc\n",
      "sample/2007012221/194139.nc\n",
      "sample/2007012217/\n",
      "sample/2007012217/154153.nc\n",
      "sample/2007012217/154453.nc\n",
      "sample/2007012217/155700.nc\n",
      "sample/2007012217/160304.nc\n",
      "sample/2007012217/154754.nc\n",
      "sample/2007012217/155055.nc\n",
      "sample/2007012217/153245.nc\n",
      "sample/2007012217/155357.nc\n",
      "sample/2007012217/161513.nc\n",
      "sample/2007012217/153849.nc\n",
      "sample/2007012217/152637.nc\n",
      "sample/2007012217/160002.nc\n",
      "sample/2007012217/153547.nc\n",
      "sample/2007012217/161211.nc\n",
      "sample/2007012217/152940.nc\n",
      "sample/2007012217/160909.nc\n",
      "sample/2007012217/160607.nc\n",
      "sample/2007012225/\n",
      "sample/2007012225/230123.nc\n",
      "sample/2007012225/224314.nc\n",
      "sample/2007012225/231028.nc\n",
      "sample/2007012225/230425.nc\n",
      "sample/2007012225/224011.nc\n",
      "sample/2007012225/223711.nc\n",
      "sample/2007012225/223107.nc\n",
      "sample/2007012225/225519.nc\n",
      "sample/2007012225/230727.nc\n",
      "sample/2007012225/223411.nc\n",
      "sample/2007012225/225820.nc\n",
      "sample/2007012225/222805.nc\n",
      "sample/2007012225/231632.nc\n",
      "sample/2007012225/224617.nc\n",
      "sample/2007012225/224917.nc\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf /home/sample.tar.gz\n",
    "!tar -xzvf /home/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec770cc-2e7d-4ca2-b908-7ee098a5b596",
   "metadata": {
    "id": "9ec770cc-2e7d-4ca2-b908-7ee098a5b596",
    "outputId": "392d73ea-0d1f-4f22-b60b-3d378251092b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version PyTorch built with: 12.1\n",
      "Number of GPUs: 1\n",
      "GPU Name: NVIDIA H200\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version PyTorch built with: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb893018-e461-4170-bd08-9cefba404415",
   "metadata": {
    "id": "eb893018-e461-4170-bd08-9cefba404415",
    "outputId": "659baab6-c872-42d7-ee99-a44ea00fd074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El directorio '/home/sample' contiene 100 subcarpetas (directorios).\n",
      "\n",
      "Algunas de las subcarpetas encontradas:\n",
      "- 200712016\n",
      "- 2007010113\n",
      "- 2007010122\n",
      "- 200701229\n",
      "- 200610187\n",
      "- 2007012213\n",
      "- 2007010121\n",
      "- 200701297\n",
      "- 2007012223\n",
      "- 2007010111\n",
      "... y 90 más.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# El path base que quieres inspeccionar\n",
    "base_path = \"/home/sample\"\n",
    "\n",
    "# Verificar si el path base existe\n",
    "if not os.path.exists(base_path):\n",
    "    print(f\"Error: El directorio base '{base_path}' no existe.\")\n",
    "else:\n",
    "    # Listar todos los contenidos del directorio base\n",
    "    try:\n",
    "        all_contents = os.listdir(base_path)\n",
    "\n",
    "        # Filtrar para quedarnos solo con los directorios\n",
    "        subdirectories = [d for d in all_contents if os.path.isdir(os.path.join(base_path, d))]\n",
    "\n",
    "        # Contar la cantidad de subdirectorios\n",
    "        num_subdirectories = len(subdirectories)\n",
    "\n",
    "        print(f\"El directorio '{base_path}' contiene {num_subdirectories} subcarpetas (directorios).\")\n",
    "\n",
    "        # Opcional: Imprimir los primeros N nombres de subcarpetas para verificar\n",
    "        if num_subdirectories > 0:\n",
    "            print(\"\\nAlgunas de las subcarpetas encontradas:\")\n",
    "            for i, subdir_name in enumerate(subdirectories):\n",
    "                if i < 10: # Imprime las primeras 10 (o menos si hay menos)\n",
    "                    print(f\"- {subdir_name}\")\n",
    "                else:\n",
    "                    break\n",
    "            if num_subdirectories > 10:\n",
    "                print(f\"... y {num_subdirectories - 10} más.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error al intentar listar los contenidos de '{base_path}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da8c5fd3-2adb-477c-a88c-43534f9e647a",
   "metadata": {
    "id": "da8c5fd3-2adb-477c-a88c-43534f9e647a",
    "outputId": "13641949-af46-44a2-a46a-c47df8cc0195"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 04:04:06,337 - INFO - Semillas configuradas con valor: 42\n",
      "2025-06-11 04:04:06,341 - INFO - Encontrados 100 directorios de eventos para procesar.\n",
      "2025-06-11 04:04:06,343 - INFO - División de eventos - Entrenamiento: 80 directorios, Validación: 20 directorios\n",
      "2025-06-11 04:04:06,350 - INFO - Generadas 400 secuencias de entrenamiento y 100 de validación.\n",
      "2025-06-11 04:04:06,352 - INFO - Usando una muestra aleatoria de 50 secuencias para esta ejecución.\n",
      "2025-06-11 04:04:06,354 - INFO - Muestra final -> Entrenamiento: 40, Validación: 10\n",
      "2025-06-11 04:04:06,356 - INFO - RadarDataset inicializado con 40 secuencias.\n",
      "2025-06-11 04:04:06,358 - INFO - RadarDataset inicializado con 10 secuencias.\n",
      "2025-06-11 04:04:06,967 - INFO - Modelo ConvLSTM3D_Enhanced creado: 3 capas, Hidden dims: [64, 64, 64], LayerNorm: True, PredSteps: 1\n",
      "2025-06-11 04:04:06,971 - INFO - Arquitectura del modelo:\n",
      "ConvLSTM3D_Enhanced(\n",
      "  (layers): ModuleList(\n",
      "    (0): ConvLSTM2DLayer(\n",
      "      (cell): ConvLSTMCell(\n",
      "        (conv): Conv2d(65, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (layer_norm): LayerNorm((64, 500, 500), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1-2): 2 x ConvLSTM2DLayer(\n",
      "      (cell): ConvLSTMCell(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (layer_norm): LayerNorm((64, 500, 500), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (output_conv): Conv3d(64, 1, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "2025-06-11 04:04:06,973 - INFO - Número total de parámetros entrenables: 96,740,929\n",
      "2025-06-11 04:04:06,975 - INFO - Cargando modelo pre-entrenado desde: /home/model/best_convlstm_model.pth\n",
      "2025-06-11 04:04:08,023 - INFO - Modelo cargado. Dtype parámetros: torch.float32\n",
      "2025-06-11 04:04:08,369 - INFO - Modelo listo para predicción. Dtype: torch.float32, Dispositivo: cuda:0\n",
      "2025-06-11 04:04:08,371 - INFO - Generando predicciones de ejemplo...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "NetCDF: Not a valid data type or _FillValue type mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 796\u001b[0m\n\u001b[1;32m    793\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProceso completado.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 796\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 787\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_loader \u001b[38;5;129;01mand\u001b[39;00m num_prediction_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    786\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerando predicciones de ejemplo...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 787\u001b[0m     \u001b[43mgenerate_prediction_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_for_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_prediction_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    791\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo hay datos disponibles en val_loader o train_loader para generar predicciones de ejemplo.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 584\u001b[0m, in \u001b[0;36mgenerate_prediction_netcdf\u001b[0;34m(model, data_loader, config, device, num_samples)\u001b[0m\n\u001b[1;32m    581\u001b[0m             pred_physical_dbz_final \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan_to_num(pred_physical_dbz_cleaned, nan\u001b[38;5;241m=\u001b[39mfill_value_float)\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# 5. Escribimos el array final y limpio.\u001b[39;00m\n\u001b[0;32m--> 584\u001b[0m             \u001b[43mdbz_v\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m pred_physical_dbz_final[np\u001b[38;5;241m.\u001b[39mnewaxis, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m    586\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicción t+\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlead_time_minutes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mmin guardada en: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    588\u001b[0m sample_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:5630\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable.__setitem__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:5917\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable._put\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2164\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NetCDF: Not a valid data type or _FillValue type mismatch"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import logging\n",
    "import xarray as xr # <<< MEJORA: Usar xarray para una lectura robusta\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import torchmetrics\n",
    "import torch.amp\n",
    "import matplotlib.pyplot as plt\n",
    "import pyproj\n",
    "from netCDF4 import Dataset as NCDataset\n",
    "\n",
    "\n",
    "# Configuración del Logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Configuración para reproducibilidad y rendimiento\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    logging.info(f\"Semillas configuradas con valor: {seed}\")\n",
    "\n",
    "class RadarDataset(Dataset):\n",
    "    def __init__(self, sequence_paths, seq_len=12, pred_len=5, \n",
    "                 min_dbz_norm=-29.0, max_dbz_norm=65.0):\n",
    "        self.sequence_paths = sequence_paths\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.min_dbz_norm = min_dbz_norm\n",
    "        self.max_dbz_norm = max_dbz_norm\n",
    "        logging.info(f\"RadarDataset inicializado con {len(self.sequence_paths)} secuencias.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence_files = self.sequence_paths[idx]\n",
    "        data_list = []\n",
    "\n",
    "        for file_path in sequence_files:\n",
    "            try:\n",
    "                # <<< MEJORA: Lectura automática y segura con xarray >>>\n",
    "                # xarray maneja _FillValue, scale_factor y add_offset automáticamente\n",
    "                with xr.open_dataset(file_path, mask_and_scale=True, decode_times=False) as ds:\n",
    "                    # .values extrae un array de numpy puro con NaNs donde corresponde\n",
    "                    dbz_physical = ds['DBZ'].values\n",
    "                \n",
    "                # Normalización, preservando NaNs\n",
    "                dbz_clipped = np.clip(dbz_physical, self.min_dbz_norm, self.max_dbz_norm)\n",
    "                dbz_normalized = (dbz_clipped - self.min_dbz_norm) / (self.max_dbz_norm - self.min_dbz_norm)\n",
    "                \n",
    "                data_list.append(dbz_normalized[0, ..., np.newaxis]) # [0] para quitar dim de tiempo, newaxis para canal\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error procesando archivo {file_path}. Omitiendo secuencia. Error: {e}\")\n",
    "                # Devolver la siguiente muestra si esta falla\n",
    "                return self.__getitem__((idx + 1) % len(self))\n",
    "        \n",
    "        full_sequence = np.stack(data_list, axis=1) # Forma: (Z, T, H, W, C)\n",
    "        \n",
    "        input_tensor = full_sequence[:, :self.seq_len, ...]\n",
    "        output_tensor = full_sequence[:, self.seq_len:, ...]\n",
    "\n",
    "        # Reemplazar NaNs con 0 para la entrada (X)\n",
    "        x = torch.from_numpy(np.nan_to_num(input_tensor, nan=0.0)).float()\n",
    "        # Mantener NaNs para el objetivo (Y) para la pérdida enmascarada\n",
    "        y = torch.from_numpy(output_tensor).float()\n",
    "        \n",
    "        # --- Lógica para devolver Timestamps (DEBES IMPLEMENTAR LA EXTRACCIÓN REAL) ---\n",
    "        last_input_filepath = sequence_files[self.seq_len - 1]\n",
    "        # filename_no_ext = os.path.splitext(os.path.basename(last_input_file_path))[0]\n",
    "        # last_input_dt_utc_placeholder = datetime.utcnow() # ¡ESTO ES SOLO UN PLACEHOLDER!\n",
    "        # try:\n",
    "        #     # Intenta parsear el timestamp del nombre del archivo o del subdirectorio\n",
    "        #     # Ejemplo: parts = filename_no_ext.split('_'); timestamp_str = parts[0][-8:] + parts[1]\n",
    "        #     # last_input_dt_utc = datetime.strptime(timestamp_str, \"%Y%m%d%H%M%S\")\n",
    "        #     pass # Implementa tu lógica de parseo aquí\n",
    "        # except Exception as e_time:\n",
    "        #     logging.warning(f\"No se pudo parsear el timestamp de {last_input_file_path} en dataset. Usando placeholder. Error: {e_time}\")\n",
    "        #     # last_input_dt_utc = last_input_dt_utc_placeholder # Mantener el placeholder si falla\n",
    "    \n",
    "        # return x, y, last_input_dt_utc_placeholder # Si devuelves timestamp\n",
    "        return x, y, last_input_filepath # Si NO devuelves timestamp por ahora\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "        nn.init.xavier_uniform_(self.conv.weight)\n",
    "        if self.bias:\n",
    "            nn.init.zeros_(self.conv.bias)\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        return h_next, c_next\n",
    "    def init_hidden(self, batch_size, image_size, device):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=device))\n",
    "\n",
    "class ConvLSTM2DLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, use_layer_norm=True, img_size=(500,500), bias=True, return_all_layers=False):\n",
    "        super(ConvLSTM2DLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.use_layer_norm = use_layer_norm\n",
    "        self.img_size = img_size\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "        self.cell = ConvLSTMCell(input_dim, hidden_dim, kernel_size, bias)\n",
    "        \n",
    "        # <<< LÓGICA DE LAYERNORM MOVIDA AQUÍ ADENTRO >>>\n",
    "        if self.use_layer_norm:\n",
    "            self.layer_norm = nn.LayerNorm([hidden_dim, self.img_size[0], self.img_size[1]])\n",
    "\n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        b, seq_len, _, h, w = input_tensor.size()\n",
    "        device = input_tensor.device\n",
    "        if hidden_state is None:\n",
    "            hidden_state = self.cell.init_hidden(b, (h, w), device)\n",
    "\n",
    "        layer_output_list = []\n",
    "        h_cur, c_cur = hidden_state\n",
    "        for t in range(seq_len):\n",
    "            h_cur, c_cur = self.cell(input_tensor=input_tensor[:, t, :, :, :], cur_state=[h_cur, c_cur])\n",
    "            layer_output_list.append(h_cur)\n",
    "\n",
    "        if self.return_all_layers:\n",
    "            layer_output = torch.stack(layer_output_list, dim=1) # (B, T, C_hidden, H, W)\n",
    "\n",
    "            # <<< APLICAMOS LAYERNORM AQUÍ ADENTRO >>>\n",
    "            if self.use_layer_norm:\n",
    "                # LayerNorm espera (N, C, H, W) o similar, lo aplicamos a cada paso de tiempo\n",
    "                B_ln, T_ln, C_ln, H_ln, W_ln = layer_output.shape\n",
    "                # Reshape para aplicar LayerNorm a todos los frames a la vez\n",
    "                output_reshaped_for_ln = layer_output.contiguous().view(B_ln * T_ln, C_ln, H_ln, W_ln)\n",
    "                normalized_output = self.layer_norm(output_reshaped_for_ln)\n",
    "                layer_output = normalized_output.view(B_ln, T_ln, C_ln, H_ln, W_ln)\n",
    "        else:\n",
    "            layer_output = h_cur.unsqueeze(1) # Si solo devolvemos el último, no normalizamos por ahora para simplificar\n",
    "\n",
    "        return layer_output, (h_cur, c_cur)\n",
    "\n",
    "\n",
    "class ConvLSTM3D_Enhanced(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dims=[64, 64, 64], kernel_sizes=[(3,3), (3,3), (3,3)],\n",
    "                 num_layers=3, pred_steps=1, use_layer_norm=True, use_residual=False,\n",
    "                 img_height=500, img_width=500):\n",
    "        super(ConvLSTM3D_Enhanced, self).__init__()\n",
    "        \n",
    "        if isinstance(hidden_dims, int): hidden_dims = [hidden_dims] * num_layers\n",
    "        if isinstance(kernel_sizes, tuple): kernel_sizes = [kernel_sizes] * num_layers\n",
    "        assert len(hidden_dims) == num_layers and len(kernel_sizes) == num_layers\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.num_layers = num_layers\n",
    "        self.pred_steps = pred_steps\n",
    "        self.use_layer_norm = use_layer_norm\n",
    "        self.use_residual = use_residual\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        current_dim = self.input_dim\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            # <<< INICIO DE LA CORRECCIÓN CLAVE >>>\n",
    "            # Para todas las capas MENOS la última, devolvemos la secuencia completa.\n",
    "            # Para la ÚLTIMA capa, devolvemos solo el estado final.\n",
    "            is_last_layer = (i == num_layers - 1)\n",
    "            self.layers.append(\n",
    "                ConvLSTM2DLayer(\n",
    "                    input_dim=current_dim, \n",
    "                    hidden_dim=hidden_dims[i],\n",
    "                    kernel_size=kernel_sizes[i],\n",
    "                    use_layer_norm=use_layer_norm,\n",
    "                    img_size=(img_height, img_width),\n",
    "                    return_all_layers=not is_last_layer # Será True para todas menos la última\n",
    "                )\n",
    "            )\n",
    "            # <<< FIN DE LA CORRECCIÓN CLAVE >>>\n",
    "            current_dim = hidden_dims[i]\n",
    "\n",
    "        self.output_conv = nn.Conv3d(\n",
    "            in_channels=hidden_dims[-1],\n",
    "            out_channels=self.input_dim * self.pred_steps,\n",
    "            kernel_size=(1, 3, 3), \n",
    "            padding=(0, 1, 1)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        nn.init.xavier_uniform_(self.output_conv.weight)\n",
    "        nn.init.zeros_(self.output_conv.bias)\n",
    "        \n",
    "        logging.info(f\"Modelo ConvLSTM3D_Enhanced creado: {num_layers} capas, Hidden dims: {hidden_dims}, LayerNorm: {use_layer_norm}, PredSteps: {pred_steps}\")\n",
    "\n",
    "    def forward(self, x_volumetric):\n",
    "        num_z_levels, b, seq_len, h, w, c_in = x_volumetric.shape\n",
    "        all_level_predictions = []\n",
    "\n",
    "        for z_idx in range(num_z_levels):\n",
    "            current_input = x_volumetric[z_idx, ...].permute(0, 1, 4, 2, 3)\n",
    "            hidden_states_for_level = [None] * self.num_layers\n",
    "\n",
    "            for i in range(self.num_layers):\n",
    "                layer_input = current_input\n",
    "                layer_output, hidden_state = checkpoint(\n",
    "                    self.layers[i],\n",
    "                    layer_input,\n",
    "                    hidden_states_for_level[i],\n",
    "                    use_reentrant=False\n",
    "                )\n",
    "                hidden_states_for_level[i] = hidden_state\n",
    "                current_input = layer_output\n",
    "\n",
    "            output_for_conv3d = current_input.permute(0, 2, 1, 3, 4)\n",
    "            raw_conv_output = self.output_conv(output_for_conv3d)\n",
    "            \n",
    "            prediction_features = raw_conv_output.squeeze(2)\n",
    "            level_prediction = prediction_features.view(b, self.pred_steps, self.input_dim, h, w)\n",
    "            level_prediction = level_prediction.permute(0, 1, 3, 4, 2)\n",
    "            level_prediction = self.sigmoid(level_prediction)\n",
    "            \n",
    "            all_level_predictions.append(level_prediction)\n",
    "\n",
    "        predictions_volumetric = torch.stack(all_level_predictions, dim=0)\n",
    "        return predictions_volumetric\n",
    "\n",
    "\n",
    "class SSIMLoss(nn.Module):\n",
    "    def __init__(self, data_range=1.0, kernel_size_for_metric=7):\n",
    "        super(SSIMLoss, self).__init__()\n",
    "        # No necesitas try-except aquí si estás usando una versión de torchmetrics que lo soporta\n",
    "        self.ssim_metric = torchmetrics.StructuralSimilarityIndexMeasure(\n",
    "            data_range=data_range,\n",
    "            kernel_size=kernel_size_for_metric,\n",
    "            reduction='elementwise_mean' # Común, o None y luego .mean()\n",
    "        ).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    def forward(self, img1, img2): # Espera (Z, B, T_pred, H, W, C)\n",
    "        num_z, batch_s, pred_t, height, width, channels = img1.shape\n",
    "\n",
    "        # SSIM se aplica típicamente a imágenes (o slices 2D/3D con un canal)\n",
    "        # Aplanar Z, B, T_pred en la dimensión de batch para SSIM\n",
    "        # Permutar para tener (Batch_flat, Canales, H, W)\n",
    "        img1_reshaped = img1.permute(0, 1, 2, 5, 3, 4).contiguous().view(-1, channels, height, width)\n",
    "        img2_reshaped = img2.permute(0, 1, 2, 5, 3, 4).contiguous().view(-1, channels, height, width)\n",
    "\n",
    "        ssim_val_elementwise = self.ssim_metric(img1_reshaped, img2_reshaped) # Esto dará un valor por imagen en el batch aplanado\n",
    "        ssim_val_mean = ssim_val_elementwise.mean() # Tomar la media sobre todos los elementos del batch aplanado\n",
    "        logging.info(f\"SSIM Mean: {ssim_val_mean.item():.4f}\")\n",
    "        return 1.0 - ssim_val_mean # Queremos maximizar SSIM, así que minimizamos 1-SSIM\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, config):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config.get('weight_decay', 1e-4))\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=config.get('lr_patience', 3), verbose=True)\n",
    "\n",
    "    # criterion_mse = nn.MSELoss().to(device)\n",
    "    criterion_loss = nn.HuberLoss(reduction='none').to(device)\n",
    "    criterion_ssim = None\n",
    "    huber_loss_weight = 1.0\n",
    "    ssim_loss_weight = 0.0\n",
    "    \n",
    "    if config.get('use_ssim_loss', False):\n",
    "        criterion_ssim = SSIMLoss(data_range=1.0, kernel_size_for_metric=config.get('ssim_kernel_size', 7)).to(device)\n",
    "        ssim_loss_weight = config.get('ssim_loss_weight', 0.5)\n",
    "        huber_loss_weight = 1.0 - ssim_loss_weight\n",
    "        logging.info(f\"Usando SSIM loss con peso {ssim_loss_weight} y Huber ponderado con peso {huber_loss_weight}\")\n",
    "\n",
    "    scaler = torch.amp.GradScaler(enabled=config['use_amp'])\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses, val_losses = [], []\n",
    "    accumulation_steps = config.get('accumulation_steps', 1)\n",
    "\n",
    "    logging.info(f\"Iniciando entrenamiento: {config['epochs']} épocas, LR: {config['learning_rate']}, Batch (efectivo): {config['batch_size'] * accumulation_steps}\")\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        torch.cuda.empty_cache()\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        for batch_idx, (x, y, _) in enumerate(train_loader):\n",
    "            x = x.to(device).permute(1, 0, 2, 3, 4, 5)\n",
    "            y = y.to(device).permute(1, 0, 2, 3, 4, 5)\n",
    "\n",
    "            with torch.amp.autocast(device_type=device.type, dtype=torch.float16, enabled=config['use_amp']):\n",
    "                predictions = model(x)\n",
    "                if predictions.shape != y.shape: continue\n",
    "\n",
    "                valid_mask = ~torch.isnan(y)\n",
    "                \n",
    "                # 1. Calcular la pérdida Huber ponderada\n",
    "                weights = torch.ones_like(y[valid_mask])\n",
    "                weights[y[valid_mask] > config.get('high_dbz_threshold_norm', 0.4)] = config.get('high_penalty_weight', 10.0)\n",
    "                pixel_wise_loss = criterion_loss(predictions[valid_mask], y[valid_mask])\n",
    "                weighted_huber_loss = (pixel_wise_loss * weights).mean()\n",
    "                \n",
    "                # 2. Calcular la pérdida SSIM (si está habilitada)\n",
    "                if criterion_ssim is not None:\n",
    "                    preds_for_ssim = torch.nan_to_num(predictions, nan=0.0)\n",
    "                    y_for_ssim = torch.nan_to_num(y, nan=0.0)\n",
    "                    loss_ssim_component = criterion_ssim(preds_for_ssim, y_for_ssim)\n",
    "                    # 3. Combinar ambas pérdidas\n",
    "                    current_loss = huber_loss_weight * weighted_huber_loss + ssim_loss_weight * loss_ssim_component\n",
    "                else:\n",
    "                    # Si no se usa SSIM, la pérdida es solo la Huber ponderada\n",
    "                    current_loss = weighted_huber_loss\n",
    "\n",
    "                loss_to_accumulate = current_loss / config.get('accumulation_steps', 1)\n",
    "\n",
    "            scaler.scale(loss_to_accumulate).backward()\n",
    "\n",
    "\n",
    "            if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                if config.get('clip_grad_norm', None):\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config['clip_grad_norm'])\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            running_train_loss += current_loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % config.get('log_interval', 1) == 0:\n",
    "                logging.info(f\"Época {epoch+1}/{config['epochs']} [{batch_idx+1}/{len(train_loader)}] - Pérdida (batch): {current_loss.item():.6f}\")\n",
    "\n",
    "        avg_train_loss = running_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Validación\n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            running_val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for x_val, y_val, _ in val_loader:\n",
    "                    x_val = x_val.to(device).permute(1, 0, 2, 3, 4, 5)\n",
    "                    y_val = y_val.to(device).permute(1, 0, 2, 3, 4, 5)\n",
    "\n",
    "                    with torch.amp.autocast(device_type=device.type, dtype=torch.float16, enabled=config['use_amp']):\n",
    "                        predictions_val = model(x_val)\n",
    "                        \n",
    "                        # <<< MISMA LÓGICA DE CÁLCULO DE PÉRDIDA PARA VALIDACIÓN >>>\n",
    "                        valid_mask_val = ~torch.isnan(y_val)\n",
    "                        weights_val = torch.ones_like(y_val[valid_mask_val])\n",
    "                        weights_val[y_val[valid_mask_val] > config.get('high_dbz_threshold_norm', 0.4)] = config.get('high_penalty_weight', 10.0)\n",
    "                        pixel_wise_loss_val = criterion_loss(predictions_val[valid_mask_val], y_val[valid_mask_val])\n",
    "                        weighted_huber_loss_val = (pixel_wise_loss_val * weights_val).mean()\n",
    "                        \n",
    "                        current_val_loss = weighted_huber_loss_val\n",
    "\n",
    "                        if criterion_ssim is not None:\n",
    "                            preds_val_for_ssim = torch.nan_to_num(predictions_val, nan=0.0)\n",
    "                            y_val_for_ssim = torch.nan_to_num(y_val, nan=0.0)\n",
    "                            val_loss_ssim_component = criterion_ssim(preds_val_for_ssim, y_val_for_ssim)\n",
    "                            current_val_loss = huber_loss_weight * weighted_huber_loss_val + ssim_loss_weight * val_loss_ssim_component\n",
    "                    running_val_loss += current_val_loss.item()\n",
    "            \n",
    "            avg_val_loss = running_val_loss / len(val_loader)\n",
    "\n",
    "            if len(val_loader) > 0:  # Evitar división por cero\n",
    "                avg_val_loss = running_val_loss / len(val_loader)\n",
    "                val_losses.append(avg_val_loss)\n",
    "                scheduler.step(avg_val_loss)\n",
    "                epoch_duration = time.time() - epoch_start_time\n",
    "                logging.info(f\"Época {epoch+1} completada en {epoch_duration:.2f}s. Pérdida (train): {avg_train_loss:.6f}, Pérdida (val): {avg_val_loss:.6f}\")\n",
    "\n",
    "                if avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    torch.save({'epoch': epoch + 1, 'model_state_dict': model.state_dict(),\n",
    "                                'optimizer_state_dict': optimizer.state_dict(), 'loss': best_val_loss},\n",
    "                               os.path.join(config['model_save_dir'], \"best_convlstm_model.pth\"))\n",
    "                    logging.info(f\"Mejor modelo guardado (Pérdida Val: {best_val_loss:.6f})\")\n",
    "            else:  # Si len(val_loader) es 0\n",
    "                epoch_duration = time.time() - epoch_start_time\n",
    "                logging.info(f\"Época {epoch+1} completada en {epoch_duration:.2f}s. Pérdida (train): {avg_train_loss:.6f} (Dataset de validación vacío, no se calculó pérdida de validación)\")\n",
    "        else:  # Si no hay val_loader\n",
    "            epoch_duration = time.time() - epoch_start_time\n",
    "            logging.info(f\"Época {epoch+1} completada en {epoch_duration:.2f}s. Pérdida (train): {avg_train_loss:.6f} (No hay val_loader)\")\n",
    "\n",
    "        # Guardar checkpoint de época\n",
    "        if (epoch + 1) % config.get('checkpoint_interval', 1) == 0:\n",
    "            torch.save({'epoch': epoch + 1, 'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(), 'train_losses': train_losses,\n",
    "                        'val_losses': val_losses if (val_loader and len(val_loader) > 0) else []},\n",
    "                       os.path.join(config['model_save_dir'], f\"checkpoint_epoch_{epoch+1}.pth\"))\n",
    "            logging.info(f\"Checkpoint guardado en la época {epoch+1}\")\n",
    "\n",
    "    logging.info(\"Entrenamiento finalizado.\")\n",
    "    if train_loader and len(train_losses) > 0:  # Solo plotear si hubo entrenamiento y pérdidas\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(train_losses, label='Pérdida Entrenamiento')\n",
    "        if val_loader and len(val_losses) > 0:\n",
    "            plt.plot(val_losses, label='Pérdida Validación')\n",
    "        plt.xlabel('Épocas')\n",
    "        plt.ylabel('Pérdida')\n",
    "        plt.legend()\n",
    "        plt.title('Curvas de Pérdida del Entrenamiento')\n",
    "        plt.savefig(os.path.join(config['model_save_dir'], \"loss_curves.png\"))\n",
    "        plt.close()\n",
    "        logging.info(f\"Curvas de pérdida guardadas en {os.path.join(config['model_save_dir'], 'loss_curves.png')}\")\n",
    "\n",
    "    return model, {'train_losses': train_losses, 'val_losses': val_losses}\n",
    "\n",
    "\n",
    "def generate_prediction_netcdf(model, data_loader, config, device, num_samples=1):\n",
    "    model.to(device).eval()\n",
    "    \n",
    "    output_dir = config['predictions_output_dir']\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # --- Parámetros de la Salida (leídos desde tu config) ---\n",
    "    min_dbz, max_dbz = config['min_dbz'], config['max_dbz']\n",
    "    scale_out = np.float32(config['output_nc_scale_factor'])\n",
    "    offset_out = np.float32(config['output_nc_add_offset'])\n",
    "    fill_byte_out = np.int8(config['output_nc_fill_value'])\n",
    "    fill_physical_out = (float(fill_byte_out) * scale_out) + offset_out\n",
    "\n",
    "    # --- Preparación de la Grilla (leído desde tu config) ---\n",
    "    num_z, num_y, num_x = config['expected_shape']\n",
    "    z_coords = np.arange(1.0, 1.0 + num_z * 1.0, 1.0, dtype=np.float32)\n",
    "    x_coords = np.arange(-249.5, -249.5 + num_x * 1.0, 1.0, dtype=np.float32)\n",
    "    y_coords = np.arange(-249.5, -249.5 + num_y * 1.0, 1.0, dtype=np.float32)\n",
    "    \n",
    "    # Pre-calcular grillas de lat/lon para los metadatos\n",
    "    proj = pyproj.Proj(proj=\"aeqd\", lon_0=config['sensor_longitude'], lat_0=config['sensor_latitude'], R=config['earth_radius_m'])\n",
    "    x_grid_m, y_grid_m = np.meshgrid(x_coords * 1000.0, y_coords * 1000.0)\n",
    "    lon0_grid, lat0_grid = proj(x_grid_m, y_grid_m, inverse=True)\n",
    "\n",
    "    sample_count = 0\n",
    "    with torch.no_grad():\n",
    "        # El DataLoader ahora debe devolver x, y, y el path del último input\n",
    "        for x_input_volume, _, last_input_filepath_batch in data_loader:\n",
    "            if sample_count >= num_samples: break\n",
    "            \n",
    "            x_to_model = x_input_volume[0:1].permute(1, 0, 2, 3, 4, 5).to(device)\n",
    "            last_input_filepath = last_input_filepath_batch[0]\n",
    "\n",
    "            with torch.amp.autocast(device_type=device.type, dtype=torch.float16, enabled=config['use_amp']):\n",
    "                predictions_norm = model(x_to_model)\n",
    "            \n",
    "            for pred_step_idx in range(config['pred_len']):\n",
    "                pred_norm_step = predictions_norm[:, 0, pred_step_idx, :, :, 0].cpu().numpy()\n",
    "\n",
    "                # --- Proceso de Desnormalización y Empaquetado ---\n",
    "                # 1. Desnormalizar a valores físicos (dBZ)\n",
    "                pred_physical_dbz_raw = pred_norm_step * (max_dbz - min_dbz) + min_dbz\n",
    "\n",
    "                # <<< LÍNEA DE SEGURIDAD CRÍTICA AÑADIDA >>>\n",
    "                pred_physical_dbz_clipped = np.clip(pred_physical_dbz_raw, min_dbz, max_dbz)\n",
    "                \n",
    "                # 2. Aplicar umbral físico: todo lo irrelevante se convierte en NaN\n",
    "                # <<< CORRECCIÓN CLAVE: AÑADIR .copy() >>>\n",
    "                pred_physical_dbz_cleaned = pred_physical_dbz_clipped.copy()\n",
    "                pred_physical_dbz_cleaned[pred_physical_dbz_cleaned < config.get('MIN_RELEVANT_DBZ', 5.0)] = np.nan\n",
    "                \n",
    "                # 3. Preparar para empaquetado: Reemplazar NaNs con el valor físico de relleno\n",
    "                #dbz_for_packing = np.where(np.isnan(pred_physical_dbz_cleaned), fill_physical_out, pred_physical_dbz_cleaned)\n",
    "                \n",
    "                # 4. Empaquetar a byte\n",
    "                #dbz_packed_byte = np.round((dbz_for_packing - offset_out) / scale_out).astype(np.int8)\n",
    "                #dbz_packed_byte[np.isclose(dbz_for_packing, fill_physical_out)] = fill_byte_out\n",
    "                #dbz_final_packed = dbz_packed_byte[np.newaxis, ...]\n",
    "\n",
    "                # --- Cálculo de Timestamps para ESTE paso de predicción ---\n",
    "                try:\n",
    "                    parts = last_input_filepath.split('/')\n",
    "                    date_str, time_str = parts[-2][:8], os.path.splitext(parts[-1])[0]\n",
    "                    last_input_dt_utc = datetime.strptime(date_str + time_str, '%Y%m%d%H%M%S')\n",
    "                except Exception:\n",
    "                    last_input_dt_utc = datetime.utcnow()\n",
    "\n",
    "                lead_time_minutes = (pred_step_idx + 1) * config['prediction_interval_minutes']\n",
    "                forecast_dt_utc = last_input_dt_utc + timedelta(minutes=lead_time_minutes)\n",
    "                \n",
    "                # --- Escritura del Archivo NetCDF Completo para este paso ---\n",
    "                file_ts = forecast_dt_utc.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                output_filename = os.path.join(output_dir, f\"pred_t+{lead_time_minutes}min_{file_ts}_sample{sample_count}.nc\")\n",
    "\n",
    "                with NCDataset(output_filename, 'w', format='NETCDF3_CLASSIC') as ds_out:\n",
    "                        # <<< INICIO DE TU CÓDIGO DE ESCRITURA DETALLADO (ADAPTADO) >>>\n",
    "                        \n",
    "                        # --- Atributos Globales ---\n",
    "                        ds_out.Conventions = \"CF-1.6\"\n",
    "                        ds_out.title = f\"{config.get('radar_name', 'SAN_RAFAEL')} - Forecast t+{lead_time_minutes}min\"\n",
    "                        ds_out.institution = config.get('institution_name', \"UCAR\")\n",
    "                        ds_out.source = config.get('data_source_name', \"ConvLSTM Model Prediction\")\n",
    "                        ds_out.history = f\"Created {datetime.now(timezone.utc).isoformat()} by ConvLSTM prediction script.\"\n",
    "                        ds_out.comment = f\"Forecast data from model. Lead time: {lead_time_minutes} min.\"\n",
    "\n",
    "                        # --- Dimensiones ---\n",
    "                        ds_out.createDimension('time', None)\n",
    "                        ds_out.createDimension('bounds', 2)\n",
    "                        ds_out.createDimension('longitude', num_x) # ANTES: x0\n",
    "                        ds_out.createDimension('latitude', num_y)  # ANTES: y0\n",
    "                        ds_out.createDimension('altitude', num_z)  # ANTES: z0\n",
    "\n",
    "                        # --- Variables de Tiempo ---\n",
    "                        time_value = (forecast_dt_utc.replace(tzinfo=None) - datetime(1970, 1, 1)).total_seconds()\n",
    "                        \n",
    "                        time_v = ds_out.createVariable('time', 'f8', ('time',))\n",
    "                        time_v.standard_name = \"time\"; time_v.long_name = \"Data time\"\n",
    "                        time_v.units = \"seconds since 1970-01-01T00:00:00Z\"; time_v.axis = \"T\"\n",
    "                        time_v.bounds = \"time_bounds\"; time_v.comment = forecast_dt_utc.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "                        time_v[:] = [time_value]\n",
    "\n",
    "                        # Puedes ajustar la lógica de start/stop time si lo necesitas, o simplificarla\n",
    "                        start_time_v = ds_out.createVariable('start_time', 'f8', ('time',))\n",
    "                        start_time_v[:] = [time_value - 180] # Ejemplo: 3 minutos antes\n",
    "                        stop_time_v = ds_out.createVariable('stop_time', 'f8', ('time',))\n",
    "                        stop_time_v[:] = [time_value]\n",
    "                        time_bnds_v = ds_out.createVariable('time_bounds', 'f8', ('time', 'bounds',))\n",
    "                        time_bnds_v[:] = [[time_value - 180, time_value]]\n",
    "\n",
    "                        # --- Variables de Coordenadas ---\n",
    "                        x_v = ds_out.createVariable('longitude', 'f4', ('longitude',)); x_v.setncatts({'standard_name':\"projection_x_coordinate\", 'units':\"km\", 'axis':\"X\"}); x_v[:] = x_coords\n",
    "                        y_v = ds_out.createVariable('latitude', 'f4', ('latitude',)); y_v.setncatts({'standard_name':\"projection_y_coordinate\", 'units':\"km\", 'axis':\"Y\"}); y_v[:] = y_coords\n",
    "                        z_v = ds_out.createVariable('altitude', 'f4', ('altitude',)); z_v.setncatts({'standard_name':\"altitude\", 'units':\"km\", 'axis':\"Z\", 'positive':\"up\"}); z_v[:] = z_coords\n",
    "                        \n",
    "                        # --- Variables de Georreferenciación ---\n",
    "                        lat0_v = ds_out.createVariable('lat0', 'f4', ('latitude', 'longitude',)); lat0_v.setncatts({'standard_name':\"latitude\", 'units':\"degrees_north\"}); lat0_v[:] = lat0_grid\n",
    "                        lon0_v = ds_out.createVariable('lon0', 'f4', ('latitude', 'longitude',)); lon0_v.setncatts({'standard_name':\"longitude\", 'units':\"degrees_east\"}); lon0_v[:] = lon0_grid\n",
    "                        \n",
    "                        gm_v = ds_out.createVariable('grid_mapping_0', 'i4'); gm_v.setncatts({'grid_mapping_name':\"azimuthal_equidistant\", 'longitude_of_projection_origin':config['sensor_longitude'], 'latitude_of_projection_origin':config['sensor_latitude'], 'false_easting':0.0, 'false_northing':0.0, 'earth_radius':config['earth_radius_m']})\n",
    "\n",
    "                        # --- Variable Principal DBZ (Versión Final y Robusta) ---\n",
    "                        # 1. Definimos un valor de relleno numérico estándar para datos flotantes.\n",
    "                        # AHORA\n",
    "                        fill_value_float = np.float32(-999.0)\n",
    "\n",
    "                        # 2. Creamos la variable, especificando el fill_value desde el principio.\n",
    "                        dbz_v = ds_out.createVariable('DBZ', 'f4', ('time', 'altitude', 'latitude', 'longitude'), \n",
    "                                                    fill_value=fill_value_float)\n",
    "\n",
    "                        # 3. Añadimos los atributos, INCLUYENDO explícitamente _FillValue y missing_value.\n",
    "                        dbz_v.setncatts({\n",
    "                            'units': 'dBZ',\n",
    "                            'long_name': 'DBZ',\n",
    "                            'standard_name': 'reflectivity',\n",
    "                            '_FillValue': fill_value_float,\n",
    "                            'missing_value': fill_value_float\n",
    "                        })\n",
    "\n",
    "                        # 4. Reemplazamos los NaNs de nuestro array con este valor de relleno antes de escribir.\n",
    "                        pred_physical_dbz_final = np.nan_to_num(pred_physical_dbz_cleaned, nan=fill_value_float)\n",
    "\n",
    "                        # 5. Escribimos el array final y limpio.\n",
    "                        dbz_v[:] = pred_physical_dbz_final[np.newaxis, ...]\n",
    "\n",
    "                logging.info(f\"Predicción t+{lead_time_minutes}min guardada en: {output_filename}\")\n",
    "\n",
    "            sample_count += 1\n",
    "\n",
    "\n",
    "def prepare_and_split_data(root_dir, train_ratio, total_seq_len, seq_stride=1):\n",
    "    \"\"\"\n",
    "    Escanea un directorio donde cada subdirectorio es un evento, ordena los\n",
    "    eventos cronológicamente, y genera secuencias de entrenamiento y validación.\n",
    "    \"\"\"\n",
    "    # 1. Encontrar todos los directorios de eventos\n",
    "    try:\n",
    "        all_event_dirs = sorted([\n",
    "            d for d in os.listdir(root_dir)\n",
    "            if os.path.isdir(os.path.join(root_dir, d)) and not d.startswith('.')\n",
    "        ])\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"El directorio del dataset no fue encontrado en: {root_dir}\")\n",
    "        return [], []\n",
    "\n",
    "    if not all_event_dirs:\n",
    "        logging.warning(f\"No se encontraron directorios de eventos en {root_dir}\")\n",
    "        return [], []\n",
    "\n",
    "    logging.info(f\"Encontrados {len(all_event_dirs)} directorios de eventos para procesar.\")\n",
    "\n",
    "    # 2. Dividir la LISTA DE DIRECTORIOS cronológicamente\n",
    "    split_idx = int(len(all_event_dirs) * train_ratio)\n",
    "    train_dirs = all_event_dirs[:split_idx]\n",
    "    val_dirs = all_event_dirs[split_idx:]\n",
    "    \n",
    "    logging.info(f\"División de eventos - Entrenamiento: {len(train_dirs)} directorios, Validación: {len(val_dirs)} directorios\")\n",
    "\n",
    "    def create_sliding_windows(event_dir_list, base_path):\n",
    "        \"\"\"Función interna para generar secuencias con ventanas deslizantes.\"\"\"\n",
    "        all_sequences = []\n",
    "        for event_dir in event_dir_list:\n",
    "            dir_path = os.path.join(base_path, event_dir)\n",
    "            files = sorted(glob.glob(os.path.join(dir_path, \"*.nc\")))\n",
    "            \n",
    "            if len(files) >= total_seq_len:\n",
    "                for i in range(0, len(files) - total_seq_len + 1, seq_stride):\n",
    "                    sequence = files[i : i + total_seq_len]\n",
    "                    all_sequences.append(sequence)\n",
    "        return all_sequences\n",
    "\n",
    "    # 3. Generar las listas de secuencias para cada conjunto\n",
    "    train_sequences = create_sliding_windows(train_dirs, root_dir)\n",
    "    val_sequences = create_sliding_windows(val_dirs, root_dir)\n",
    "\n",
    "    logging.info(f\"Generadas {len(train_sequences)} secuencias de entrenamiento y {len(val_sequences)} de validación.\")\n",
    "    \n",
    "    return train_sequences, val_sequences\n",
    "\n",
    "def main():\n",
    "    set_seed(42)\n",
    "    config = {\n",
    "        'dataset_dir': \"/home/sample\",\n",
    "        'model_save_dir': \"/home/model\",\n",
    "        'predictions_output_dir': \"/home/predictions\",\n",
    "\n",
    "        # --- Parámetros de la Estrategia (12 -> 5) ---\n",
    "        'seq_len': 12,\n",
    "        'pred_len': 1,\n",
    "        'total_seq_len': 13,\n",
    "        'seq_stride': 1, # Usar 1 para máximo data augmentation\n",
    "\n",
    "        # --- Parámetros de División del Dataset ---\n",
    "        'train_val_split_ratio': 0.8, # 80% para entrenamiento\n",
    "        'max_sequences_to_use': 50, # Para una prueba rápida, luego poner a None para usar todo\n",
    "\n",
    "        # --- Parámetros de Normalización y Físicos (Consistentes con el dataset) ---\n",
    "        'min_dbz': -29.0,\n",
    "        'max_dbz': 65.0,\n",
    "        'MIN_RELEVANT_DBZ': 5.0, # Umbral físico para considerar un píxel como dato válido\n",
    "        'expected_shape': (18, 500, 500), # nz, ny, nx\n",
    "        \n",
    "        # --- Parámetros de la Salida NetCDF (para compatibilidad con TITAN) ---\n",
    "        'output_nc_scale_factor': 0.5,\n",
    "        'output_nc_add_offset': 33.5,\n",
    "        'output_nc_fill_value': -128,\n",
    "\n",
    "        'model_input_dim': 1,\n",
    "        'model_hidden_dims': [64, 64, 64,],\n",
    "        'model_kernel_sizes': [(3, 3), (3, 3), (3, 3)],\n",
    "        'model_num_layers': 3,\n",
    "        'pred_steps_model': 1,  # Debe coincidir con pred_len\n",
    "        'model_use_layer_norm': True,\n",
    "        'model_use_residual': False,\n",
    "\n",
    "\n",
    "        'batch_size': 2, # Ajustar según VRAM de la H200\n",
    "        'epochs': 10,     # Aumentar para el entrenamiento real (e.g., 50, 100)\n",
    "        'learning_rate': 2e-5,\n",
    "        'weight_decay': 1e-5,\n",
    "        'lr_patience': 3,\n",
    "        'use_amp': True,\n",
    "        'clip_grad_norm': 1.0,\n",
    "        'use_ssim_loss': True, # Usar SSIM como parte de la pérdida\n",
    "        'ssim_loss_weight': 0.3,\n",
    "\n",
    "        'high_dbz_threshold_norm': 0.30, # Corresponde a ~20-25 dBZ. Los píxeles por encima de esto se consideran \"importantes\".\n",
    "        'high_penalty_weight': 150.0,     # El error en estos píxeles importa 10 veces más.\n",
    "\n",
    "        # ... Otros parámetros de config que ya tenías ...\n",
    "        'sensor_latitude': -34.64799880981445,\n",
    "        'sensor_longitude': -68.01699829101562,\n",
    "        'earth_radius_m': 6378137.0,\n",
    "        'prediction_interval_minutes': 3\n",
    "    }\n",
    "\n",
    "    os.makedirs(config['model_save_dir'], exist_ok=True)\n",
    "    os.makedirs(config['predictions_output_dir'], exist_ok=True)\n",
    "\n",
    "    # 1. Usar nuestra nueva función para preparar los datos de forma robusta\n",
    "    train_seq_paths, val_seq_paths = prepare_and_split_data(\n",
    "        root_dir=config['dataset_dir'],\n",
    "        train_ratio=config['train_val_split_ratio'],\n",
    "        total_seq_len=config['total_seq_len'],\n",
    "        seq_stride=config.get('seq_stride', 1)\n",
    "    )\n",
    "\n",
    "    if not train_seq_paths and not val_seq_paths:\n",
    "        logging.error(\"No se generaron secuencias de entrenamiento ni de validación. Revisa la ruta del dataset y su contenido.\")\n",
    "        return\n",
    "        \n",
    "    # 2. Limitar el número de secuencias para una prueba rápida (si está configurado)\n",
    "    if config.get('max_sequences_to_use'):\n",
    "        logging.info(f\"Usando una muestra aleatoria de {config['max_sequences_to_use']} secuencias para esta ejecución.\")\n",
    "        # Mezclamos las listas para que la muestra sea variada\n",
    "        random.shuffle(train_seq_paths)\n",
    "        random.shuffle(val_seq_paths)\n",
    "        \n",
    "        num_train = int(config['max_sequences_to_use'] * config['train_val_split_ratio'])\n",
    "        num_val = config['max_sequences_to_use'] - num_train\n",
    "        \n",
    "        train_seq_paths = train_seq_paths[:num_train]\n",
    "        val_seq_paths = val_seq_paths[:num_val]\n",
    "        logging.info(f\"Muestra final -> Entrenamiento: {len(train_seq_paths)}, Validación: {len(val_seq_paths)}\")\n",
    "\n",
    "    # 3. Crear los Datasets y DataLoaders\n",
    "    # El constructor de RadarDataset ahora es mucho más simple, solo necesita la lista de secuencias\n",
    "    train_dataset = RadarDataset(train_seq_paths, seq_len=config['seq_len'], pred_len=config['pred_len'],\n",
    "                                 min_dbz_norm=config['min_dbz'], max_dbz_norm=config['max_dbz'])\n",
    "\n",
    "    val_dataset = RadarDataset(val_seq_paths, seq_len=config['seq_len'], pred_len=config['pred_len'],\n",
    "                               min_dbz_norm=config['min_dbz'], max_dbz_norm=config['max_dbz'])\n",
    "\n",
    "    # num_workers > 0 es ideal para acelerar la carga, pero puede dar problemas en algunos notebooks.\n",
    "    # Si tienes errores, prueba poniendo num_workers=0.\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    val_dataset_len = len(val_dataset) # Guardamos el largo para usarlo más adelante\n",
    "\n",
    "    # 4. Verificar que tenemos datos para continuar\n",
    "    if val_dataset_len == 0 and len(train_dataset) == 0:\n",
    "        logging.error(\"Los datasets de entrenamiento y validación están vacíos. No se puede continuar.\")\n",
    "        return\n",
    "\n",
    "    model = ConvLSTM3D_Enhanced(\n",
    "        input_dim=config['model_input_dim'], hidden_dims=config['model_hidden_dims'],\n",
    "        kernel_sizes=config['model_kernel_sizes'], num_layers=config['model_num_layers'],\n",
    "        pred_steps=config['pred_steps_model'], use_layer_norm=config['model_use_layer_norm'],\n",
    "        use_residual=config['model_use_residual'],\n",
    "        img_height=config['expected_shape'][1], img_width=config['expected_shape'][2]\n",
    "    )\n",
    "    model.float() # Asegurar que el modelo se inicialice en float32\n",
    "\n",
    "    logging.info(f\"Arquitectura del modelo:\\n{model}\")\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    logging.info(f\"Número total de parámetros entrenables: {total_params:,}\")\n",
    "\n",
    "    device_for_execution = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model_path = os.path.join(config['model_save_dir'], \"best_convlstm_model.pth\")\n",
    "    if os.path.exists(model_path):\n",
    "        logging.info(f\"Cargando modelo pre-entrenado desde: {model_path}\")\n",
    "        # Cargar a CPU, luego asegurar .float(), luego mover a device\n",
    "        checkpoint_data = torch.load(model_path, map_location='cpu', weights_only=True) #weights_only=True por seguridad\n",
    "        model.load_state_dict(checkpoint_data['model_state_dict'])\n",
    "        model.float() # Asegurar float32 después de cargar\n",
    "        logging.info(f\"Modelo cargado. Dtype parámetros: {next(model.parameters()).dtype}\")\n",
    "        trained_model = model\n",
    "    else:\n",
    "        logging.info(\"No se encontró modelo pre-entrenado. Entrenando desde cero...\")\n",
    "        if not train_loader:\n",
    "            logging.error(\"No hay datos de entrenamiento y no se encontró modelo pre-entrenado. Saliendo.\")\n",
    "            return\n",
    "        trained_model, history = train_model(model, train_loader, val_loader, config) # train_model se encarga de .to(device)\n",
    "\n",
    "    trained_model.to(device_for_execution) # Mover el modelo final al dispositivo\n",
    "    trained_model.float() # Re-asegurar float32 después de mover (por si acaso)\n",
    "    logging.info(f\"Modelo listo para predicción. Dtype: {next(trained_model.parameters()).dtype}, Dispositivo: {next(trained_model.parameters()).device}\")\n",
    "\n",
    "    # Priorizar val_loader para predicciones, si no, usar train_loader\n",
    "    prediction_loader = val_loader if val_loader and val_dataset_len > 0 else train_loader\n",
    "    num_prediction_samples = min(5, val_dataset_len if val_loader and val_dataset_len > 0 else (len(train_loader.dataset) if train_loader else 0))\n",
    "\n",
    "    if prediction_loader and num_prediction_samples > 0:\n",
    "        logging.info(\"Generando predicciones de ejemplo...\")\n",
    "        generate_prediction_netcdf(trained_model, prediction_loader, config,\n",
    "                                   device=device_for_execution,\n",
    "                                   num_samples=num_prediction_samples)\n",
    "    else:\n",
    "        logging.warning(\"No hay datos disponibles en val_loader o train_loader para generar predicciones de ejemplo.\")\n",
    "\n",
    "    logging.info(\"Proceso completado.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae001fd-5f38-499d-acdc-b5851649dbd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
