{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6399b35-6488-4a16-92d6-d7d9acfe944d",
   "metadata": {
    "id": "e6399b35-6488-4a16-92d6-d7d9acfe944d",
    "outputId": "689dccdb-fb13-4a4c-8968-ae9f4c6fbf56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTORCH_CUDA_ALLOC_CONF set to: expandable_segments:True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "print(f\"PYTORCH_CUDA_ALLOC_CONF set to: {os.environ.get('PYTORCH_CUDA_ALLOC_CONF')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a95315-21c1-41de-a409-09f3319d9b68",
   "metadata": {
    "id": "98a95315-21c1-41de-a409-09f3319d9b68",
    "outputId": "3902861a-46cd-4c01-af9c-d236f1cd9edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: netCDF4 in /opt/conda/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.10.3)\n",
      "Requirement already satisfied: cftime in /opt/conda/lib/python3.11/site-packages (from netCDF4) (1.6.4.post1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from netCDF4) (2024.8.30)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from netCDF4) (2.1.2)\n",
      "Requirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (24.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (2.5.1+cu121)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (0.14.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (72.1.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pyproj in /opt/conda/lib/python3.11/site-packages (3.7.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from pyproj) (2024.8.30)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install numpy scipy netCDF4 xarray torch torchvision torchaudio torchmetrics matplotlib\n",
    "!pip install pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "BrhYI9SSVo_t",
   "metadata": {
    "id": "BrhYI9SSVo_t",
    "outputId": "0a7831e7-cd07-446e-badb-1dc03a590380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.11/site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from gdown) (4.66.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-5.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f803dd-b188-46c0-96a9-496c8ae389ea",
   "metadata": {
    "id": "02f803dd-b188-46c0-96a9-496c8ae389ea",
    "outputId": "f621b64f-534d-4e6c-c68b-e27c2c70e147",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=18uG9KMSdBsVMK8OALvNrLBJS7M6jS2UR\n",
      "From (redirected): https://drive.google.com/uc?id=18uG9KMSdBsVMK8OALvNrLBJS7M6jS2UR&confirm=t&uuid=edabad71-e8b6-4119-a84a-39f68afca328\n",
      "To: /home/sample.tar.gz\n",
      "100%|██████████████████████████████████████| 1.62G/1.62G [00:37<00:00, 42.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "!cd /home\n",
    "!gdown --id 1kdTtKBjpQWNgijR7AH75t92KT-pptyNu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46053838-a6f8-4835-9572-b7a409d2f94a",
   "metadata": {
    "collapsed": true,
    "id": "46053838-a6f8-4835-9572-b7a409d2f94a",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "6a68f00c-b475-407f-90a5-ebbb4324abe1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample/\n",
      "sample/201001112/\n",
      "sample/201001112/210027.nc\n",
      "sample/201001112/205431.nc\n",
      "sample/201001112/205736.nc\n",
      "sample/201001112/205141.nc\n",
      "sample/201001112/204601.nc\n",
      "sample/201001112/210318.nc\n",
      "sample/201001112/204851.nc\n",
      "sample/201010232/\n",
      "sample/201010232/130250.nc\n",
      "sample/201010232/131156.nc\n",
      "sample/201010232/130854.nc\n",
      "sample/201010232/125949.nc\n",
      "sample/201010232/130552.nc\n",
      "sample/201010232/131458.nc\n",
      "sample/201010232/125646.nc\n",
      "sample/201211166/\n",
      "sample/201211166/200638.nc\n",
      "sample/201211166/194949.nc\n",
      "sample/201211166/195814.nc\n",
      "sample/201211166/200101.nc\n",
      "sample/201211166/200349.nc\n",
      "sample/201211166/195237.nc\n",
      "sample/201211166/195525.nc\n",
      "sample/201401206/\n",
      "sample/201401206/193226.nc\n",
      "sample/201401206/193543.nc\n",
      "sample/201401206/193900.nc\n",
      "sample/201401206/194851.nc\n",
      "sample/201401206/195208.nc\n",
      "sample/201401206/194534.nc\n",
      "sample/201401206/194217.nc\n",
      "sample/201111155/\n",
      "sample/201111155/222718.nc\n",
      "sample/201111155/221932.nc\n",
      "sample/201111155/222207.nc\n",
      "sample/201111155/222442.nc\n",
      "sample/201111155/221657.nc\n",
      "sample/201111155/223228.nc\n",
      "sample/201111155/222953.nc\n",
      "sample/201112109/\n",
      "sample/201112109/235715.nc\n",
      "sample/201112109/235207.nc\n",
      "sample/201112109/234424.nc\n",
      "sample/201112109/235441.nc\n",
      "sample/201112109/234657.nc\n",
      "sample/201112109/235950.nc\n",
      "sample/201112109/234932.nc\n",
      "sample/201111151/\n",
      "sample/201111151/165854.nc\n",
      "sample/201111151/170640.nc\n",
      "sample/201111151/165619.nc\n",
      "sample/201111151/170406.nc\n",
      "sample/201111151/165108.nc\n",
      "sample/201111151/170129.nc\n",
      "sample/201111151/165343.nc\n",
      "sample/201112105/\n",
      "sample/201112105/223426.nc\n",
      "sample/201112105/222918.nc\n",
      "sample/201112105/222136.nc\n",
      "sample/201112105/223152.nc\n",
      "sample/201112105/222409.nc\n",
      "sample/201112105/222644.nc\n",
      "sample/201112105/223700.nc\n",
      "sample/201010236/\n",
      "sample/201010236/225116.nc\n",
      "sample/201010236/224538.nc\n",
      "sample/201010236/224248.nc\n",
      "sample/201010236/223958.nc\n",
      "sample/201010236/224827.nc\n",
      "sample/201010236/223707.nc\n",
      "sample/201010236/223418.nc\n",
      "sample/201501051/\n",
      "sample/201501051/175251.nc\n",
      "sample/201501051/180612.nc\n",
      "sample/201501051/174055.nc\n",
      "sample/201501051/180255.nc\n",
      "sample/201501051/175621.nc\n",
      "sample/201501051/174653.nc\n",
      "sample/201501051/175938.nc\n",
      "sample/201001048/\n",
      "sample/201001048/233234.nc\n",
      "sample/201001048/232936.nc\n",
      "sample/201001048/232407.nc\n",
      "sample/201001048/232123.nc\n",
      "sample/201001048/231838.nc\n",
      "sample/201001048/232652.nc\n",
      "sample/201001048/231552.nc\n",
      "sample/201211164/\n",
      "sample/201211164/191607.nc\n",
      "sample/201211164/191029.nc\n",
      "sample/201211164/192434.nc\n",
      "sample/201211164/192145.nc\n",
      "sample/201211164/191856.nc\n",
      "sample/201211164/192722.nc\n",
      "sample/201211164/191319.nc\n",
      "sample/201410238/\n",
      "sample/201410238/232223.nc\n",
      "sample/201410238/232528.nc\n",
      "sample/201410238/230958.nc\n",
      "sample/201410238/231917.nc\n",
      "sample/201410238/231304.nc\n",
      "sample/201410238/230652.nc\n",
      "sample/201410238/231611.nc\n",
      "sample/201111154/\n",
      "sample/201111154/221148.nc\n",
      "sample/201111154/215852.nc\n",
      "sample/201111154/221422.nc\n",
      "sample/201111154/220636.nc\n",
      "sample/201111154/220913.nc\n",
      "sample/201111154/220126.nc\n",
      "sample/201111154/220402.nc\n",
      "sample/201212242/\n",
      "sample/201212242/194258.nc\n",
      "sample/201212242/193731.nc\n",
      "sample/201212242/193203.nc\n",
      "sample/201212242/192920.nc\n",
      "sample/201212242/194014.nc\n",
      "sample/201212242/193447.nc\n",
      "sample/201212242/192637.nc\n",
      "sample/201011281/\n",
      "sample/201011281/172913.nc\n",
      "sample/201011281/172057.nc\n",
      "sample/201011281/172628.nc\n",
      "sample/201011281/173157.nc\n",
      "sample/201011281/173442.nc\n",
      "sample/201011281/173727.nc\n",
      "sample/201011281/172343.nc\n",
      "sample/201001096/\n",
      "sample/201001096/224629.nc\n",
      "sample/201001096/223511.nc\n",
      "sample/201001096/225208.nc\n",
      "sample/201001096/224051.nc\n",
      "sample/201001096/224340.nc\n",
      "sample/201001096/224918.nc\n",
      "sample/201001096/223801.nc\n",
      "sample/201010275/\n",
      "sample/201010275/072134.nc\n",
      "sample/201010275/071558.nc\n",
      "sample/201010275/071308.nc\n",
      "sample/201010275/071846.nc\n",
      "sample/201010275/070729.nc\n",
      "sample/201010275/072425.nc\n",
      "sample/201010275/071018.nc\n",
      "sample/201112033/\n",
      "sample/201112033/211912.nc\n",
      "sample/201112033/211203.nc\n",
      "sample/201112033/210830.nc\n",
      "sample/201112033/210456.nc\n",
      "sample/201112033/211538.nc\n",
      "sample/201112033/210123.nc\n",
      "sample/201112033/205749.nc\n",
      "sample/201212243/\n",
      "sample/201212243/214233.nc\n",
      "sample/201212243/215042.nc\n",
      "sample/201212243/213950.nc\n",
      "sample/201212243/215325.nc\n",
      "sample/201212243/215607.nc\n",
      "sample/201212243/214516.nc\n",
      "sample/201212243/214759.nc\n",
      "sample/201401274/\n",
      "sample/201401274/220922.nc\n",
      "sample/201401274/221434.nc\n",
      "sample/201401274/221709.nc\n",
      "sample/201401274/220647.nc\n",
      "sample/201401274/221158.nc\n",
      "sample/201401274/221944.nc\n",
      "sample/201401274/220411.nc\n",
      "sample/201001045/\n",
      "sample/201001045/222308.nc\n",
      "sample/201001045/223126.nc\n",
      "sample/201001045/222023.nc\n",
      "sample/201001045/222554.nc\n",
      "sample/201001045/223413.nc\n",
      "sample/201001045/221739.nc\n",
      "sample/201001045/222841.nc\n",
      "sample/201112107/\n",
      "sample/201112107/232116.nc\n",
      "sample/201112107/231334.nc\n",
      "sample/201112107/230826.nc\n",
      "sample/201112107/231608.nc\n",
      "sample/201112107/231059.nc\n",
      "sample/201112107/231842.nc\n",
      "sample/201112107/232351.nc\n",
      "sample/201001053/\n",
      "sample/201001053/104827.nc\n",
      "sample/201001053/110506.nc\n",
      "sample/201001053/105113.nc\n",
      "sample/201001053/105646.nc\n",
      "sample/201001053/105933.nc\n",
      "sample/201001053/105400.nc\n",
      "sample/201001053/110220.nc\n",
      "sample/201401276/\n",
      "sample/201401276/225330.nc\n",
      "sample/201401276/225055.nc\n",
      "sample/201401276/224819.nc\n",
      "sample/201401276/224031.nc\n",
      "sample/201401276/224307.nc\n",
      "sample/201401276/225606.nc\n",
      "sample/201401276/224543.nc\n",
      "sample/201001118/\n",
      "sample/201001118/232520.nc\n",
      "sample/201001118/232814.nc\n",
      "sample/201001118/231936.nc\n",
      "sample/201001118/232228.nc\n",
      "sample/201001118/233407.nc\n",
      "sample/201001118/233110.nc\n",
      "sample/201001118/233705.nc\n",
      "sample/201312113/\n",
      "sample/201312113/182558.nc\n",
      "sample/201312113/181952.nc\n",
      "sample/201312113/181347.nc\n",
      "sample/201312113/182255.nc\n",
      "sample/201312113/181045.nc\n",
      "sample/201312113/182901.nc\n",
      "sample/201312113/181650.nc\n",
      "sample/201112104/\n",
      "sample/201112104/220339.nc\n",
      "sample/201112104/221352.nc\n",
      "sample/201112104/221120.nc\n",
      "sample/201112104/220613.nc\n",
      "sample/201112104/221627.nc\n",
      "sample/201112104/221901.nc\n",
      "sample/201112104/220846.nc\n",
      "sample/201212244/\n",
      "sample/201212244/220132.nc\n",
      "sample/201212244/221223.nc\n",
      "sample/201212244/220658.nc\n",
      "sample/201212244/220415.nc\n",
      "sample/201212244/221506.nc\n",
      "sample/201212244/215849.nc\n",
      "sample/201212244/220940.nc\n",
      "sample/201010234/\n",
      "sample/201010234/203557.nc\n",
      "sample/201010234/204421.nc\n",
      "sample/201010234/205245.nc\n",
      "sample/201010234/203845.nc\n",
      "sample/201010234/204958.nc\n",
      "sample/201010234/204709.nc\n",
      "sample/201010234/204133.nc\n",
      "sample/201312118/\n",
      "sample/201312118/211558.nc\n",
      "sample/201312118/211305.nc\n",
      "sample/201312118/212143.nc\n",
      "sample/201312118/211851.nc\n",
      "sample/201312118/210720.nc\n",
      "sample/201312118/211013.nc\n",
      "sample/201312118/210426.nc\n",
      "sample/201312114/\n",
      "sample/201312114/185019.nc\n",
      "sample/201312114/184112.nc\n",
      "sample/201312114/183809.nc\n",
      "sample/201312114/183506.nc\n",
      "sample/201312114/184717.nc\n",
      "sample/201312114/183203.nc\n",
      "sample/201312114/184414.nc\n",
      "sample/201410233/\n",
      "sample/201410233/213659.nc\n",
      "sample/201410233/211821.nc\n",
      "sample/201410233/212127.nc\n",
      "sample/201410233/213046.nc\n",
      "sample/201410233/212434.nc\n",
      "sample/201410233/213352.nc\n",
      "sample/201410233/212740.nc\n",
      "sample/201011286/\n",
      "sample/201011286/224225.nc\n",
      "sample/201011286/223339.nc\n",
      "sample/201011286/223634.nc\n",
      "sample/201011286/222810.nc\n",
      "sample/201011286/223054.nc\n",
      "sample/201011286/224510.nc\n",
      "sample/201011286/223941.nc\n",
      "sample/201401205/\n",
      "sample/201401205/191558.nc\n",
      "sample/201401205/192551.nc\n",
      "sample/201401205/191241.nc\n",
      "sample/201401205/192234.nc\n",
      "sample/201401205/191916.nc\n",
      "sample/201401205/190924.nc\n",
      "sample/201401205/192909.nc\n",
      "sample/201401203/\n",
      "sample/201401203/182958.nc\n",
      "sample/201401203/182323.nc\n",
      "sample/201401203/182641.nc\n",
      "sample/201401203/184307.nc\n",
      "sample/201401203/183632.nc\n",
      "sample/201401203/183950.nc\n",
      "sample/201401203/183315.nc\n",
      "sample/201112102/\n",
      "sample/201112102/194226.nc\n",
      "sample/201112102/195244.nc\n",
      "sample/201112102/195519.nc\n",
      "sample/201112102/194501.nc\n",
      "sample/201112102/195010.nc\n",
      "sample/201112102/193952.nc\n",
      "sample/201112102/194736.nc\n",
      "sample/201001119/\n",
      "sample/201001119/235529.nc\n",
      "sample/201001119/234603.nc\n",
      "sample/201001119/235158.nc\n",
      "sample/201001119/234004.nc\n",
      "sample/201001119/235827.nc\n",
      "sample/201001119/234304.nc\n",
      "sample/201001119/234900.nc\n",
      "sample/201001011/\n",
      "sample/201001011/172022.nc\n",
      "sample/201001011/172310.nc\n",
      "sample/201001011/171444.nc\n",
      "sample/201001011/171155.nc\n",
      "sample/201001011/171733.nc\n",
      "sample/201001011/170906.nc\n",
      "sample/201001011/172558.nc\n",
      "sample/201011288/\n",
      "sample/201011288/231839.nc\n",
      "sample/201011288/232123.nc\n",
      "sample/201011288/231256.nc\n",
      "sample/201011288/230720.nc\n",
      "sample/201011288/232408.nc\n",
      "sample/201011288/231005.nc\n",
      "sample/201011288/231544.nc\n",
      "sample/201401272/\n",
      "sample/201401272/182544.nc\n",
      "sample/201401272/183604.nc\n",
      "sample/201401272/183329.nc\n",
      "sample/201401272/182819.nc\n",
      "sample/201401272/182033.nc\n",
      "sample/201401272/182309.nc\n",
      "sample/201401272/183054.nc\n",
      "sample/201501054/\n",
      "sample/201501054/201832.nc\n",
      "sample/201501054/200840.nc\n",
      "sample/201501054/201158.nc\n",
      "sample/201501054/200523.nc\n",
      "sample/201501054/202149.nc\n",
      "sample/201501054/201515.nc\n",
      "sample/201501054/202506.nc\n",
      "sample/201001041/\n",
      "sample/201001041/204100.nc\n",
      "sample/201001041/204631.nc\n",
      "sample/201001041/204345.nc\n",
      "sample/201001041/205448.nc\n",
      "sample/201001041/205735.nc\n",
      "sample/201001041/205201.nc\n",
      "sample/201001041/204916.nc\n",
      "sample/201001091/\n",
      "sample/201001091/001850.nc\n",
      "sample/201001091/000147.nc\n",
      "sample/201001091/000728.nc\n",
      "sample/201001091/001559.nc\n",
      "sample/201001091/000437.nc\n",
      "sample/201001091/001309.nc\n",
      "sample/201001091/001018.nc\n",
      "sample/201010237/\n",
      "sample/201010237/230556.nc\n",
      "sample/201010237/231131.nc\n",
      "sample/201010237/230309.nc\n",
      "sample/201010237/225405.nc\n",
      "sample/201010237/225959.nc\n",
      "sample/201010237/230843.nc\n",
      "sample/201010237/225711.nc\n",
      "sample/201001114/\n",
      "sample/201001114/221142.nc\n",
      "sample/201001114/215556.nc\n",
      "sample/201001114/220152.nc\n",
      "sample/201001114/215846.nc\n",
      "sample/201001114/220804.nc\n",
      "sample/201001114/220447.nc\n",
      "sample/201001114/221503.nc\n",
      "sample/201010276/\n",
      "sample/201010276/073829.nc\n",
      "sample/201010276/073255.nc\n",
      "sample/201010276/073006.nc\n",
      "sample/201010276/074117.nc\n",
      "sample/201010276/072716.nc\n",
      "sample/201010276/073542.nc\n",
      "sample/201010276/074406.nc\n",
      "sample/201001035/\n",
      "sample/201001035/204527.nc\n",
      "sample/201001035/203652.nc\n",
      "sample/201001035/203941.nc\n",
      "sample/201001035/205154.nc\n",
      "sample/201001035/205442.nc\n",
      "sample/201001035/204907.nc\n",
      "sample/201001035/204229.nc\n",
      "sample/201112034/\n",
      "sample/201112034/212246.nc\n",
      "sample/201112034/214037.nc\n",
      "sample/201112034/213704.nc\n",
      "sample/201112034/213329.nc\n",
      "sample/201112034/214410.nc\n",
      "sample/201112034/212621.nc\n",
      "sample/201112034/212955.nc\n",
      "sample/201001099/\n",
      "sample/201001099/233433.nc\n",
      "sample/201001099/234303.nc\n",
      "sample/201001099/234554.nc\n",
      "sample/201001099/233723.nc\n",
      "sample/201001099/234844.nc\n",
      "sample/201001099/234012.nc\n",
      "sample/201001099/235133.nc\n",
      "sample/201401271/\n",
      "sample/201401271/151347.nc\n",
      "sample/201401271/150333.nc\n",
      "sample/201401271/151621.nc\n",
      "sample/201401271/150840.nc\n",
      "sample/201401271/150606.nc\n",
      "sample/201401271/151113.nc\n",
      "sample/201401271/150100.nc\n",
      "sample/201211165/\n",
      "sample/201211165/193548.nc\n",
      "sample/201211165/194125.nc\n",
      "sample/201211165/193836.nc\n",
      "sample/201211165/193011.nc\n",
      "sample/201211165/194701.nc\n",
      "sample/201211165/194412.nc\n",
      "sample/201211165/193259.nc\n",
      "sample/201011289/\n",
      "sample/201011289/232951.nc\n",
      "sample/201011289/233804.nc\n",
      "sample/201011289/232657.nc\n",
      "sample/201011289/233235.nc\n",
      "sample/201011289/234049.nc\n",
      "sample/201011289/234333.nc\n",
      "sample/201011289/233519.nc\n",
      "sample/201001098/\n",
      "sample/201001098/231447.nc\n",
      "sample/201001098/232854.nc\n",
      "sample/201001098/231735.nc\n",
      "sample/201001098/232314.nc\n",
      "sample/201001098/232603.nc\n",
      "sample/201001098/232025.nc\n",
      "sample/201001098/233143.nc\n",
      "sample/201010279/\n",
      "sample/201010279/082540.nc\n",
      "sample/201010279/083111.nc\n",
      "sample/201010279/083356.nc\n",
      "sample/201010279/084213.nc\n",
      "sample/201010279/082825.nc\n",
      "sample/201010279/083927.nc\n",
      "sample/201010279/083641.nc\n",
      "sample/201001039/\n",
      "sample/201001039/223346.nc\n",
      "sample/201001039/222520.nc\n",
      "sample/201001039/223056.nc\n",
      "sample/201001039/223635.nc\n",
      "sample/201001039/222807.nc\n",
      "sample/201001039/222232.nc\n",
      "sample/201001039/221942.nc\n",
      "sample/201001017/\n",
      "sample/201001017/230355.nc\n",
      "sample/201001017/230106.nc\n",
      "sample/201001017/224645.nc\n",
      "sample/201001017/225530.nc\n",
      "sample/201001017/224955.nc\n",
      "sample/201001017/225242.nc\n",
      "sample/201001017/225818.nc\n",
      "sample/201001111/\n",
      "sample/201001111/185527.nc\n",
      "sample/201001111/190105.nc\n",
      "sample/201001111/184410.nc\n",
      "sample/201001111/184659.nc\n",
      "sample/201001111/185237.nc\n",
      "sample/201001111/184948.nc\n",
      "sample/201001111/185816.nc\n",
      "sample/201301114/\n",
      "sample/201301114/220207.nc\n",
      "sample/201301114/215034.nc\n",
      "sample/201301114/215914.nc\n",
      "sample/201301114/214451.nc\n",
      "sample/201301114/215618.nc\n",
      "sample/201301114/215326.nc\n",
      "sample/201301114/214742.nc\n",
      "sample/201112032/\n",
      "sample/201112032/194410.nc\n",
      "sample/201112032/195106.nc\n",
      "sample/201112032/195433.nc\n",
      "sample/201112032/195800.nc\n",
      "sample/201112032/194043.nc\n",
      "sample/201112032/200128.nc\n",
      "sample/201112032/194738.nc\n",
      "sample/201401273/\n",
      "sample/201401273/214438.nc\n",
      "sample/201401273/214201.nc\n",
      "sample/201401273/214715.nc\n",
      "sample/201401273/214952.nc\n",
      "sample/201401273/213924.nc\n",
      "sample/201401273/215230.nc\n",
      "sample/201401273/220135.nc\n",
      "sample/201001093/\n",
      "sample/201001093/214956.nc\n",
      "sample/201001093/214123.nc\n",
      "sample/201001093/213832.nc\n",
      "sample/201001093/214414.nc\n",
      "sample/201001093/215246.nc\n",
      "sample/201001093/213541.nc\n",
      "sample/201001093/214705.nc\n",
      "sample/201410237/\n",
      "sample/201410237/230346.nc\n",
      "sample/201410237/225121.nc\n",
      "sample/201410237/225733.nc\n",
      "sample/201410237/224816.nc\n",
      "sample/201410237/224510.nc\n",
      "sample/201410237/225427.nc\n",
      "sample/201410237/230040.nc\n",
      "sample/201112039/\n",
      "sample/201112039/234001.nc\n",
      "sample/201112039/233327.nc\n",
      "sample/201112039/235024.nc\n",
      "sample/201112039/234329.nc\n",
      "sample/201112039/233644.nc\n",
      "sample/201112039/235342.nc\n",
      "sample/201112039/234646.nc\n",
      "sample/201001031/\n",
      "sample/201001031/160939.nc\n",
      "sample/201001031/161519.nc\n",
      "sample/201001031/162058.nc\n",
      "sample/201001031/161229.nc\n",
      "sample/201001031/161809.nc\n",
      "sample/201001031/160649.nc\n",
      "sample/201001031/160359.nc\n",
      "sample/201312116/\n",
      "sample/201312116/195417.nc\n",
      "sample/201312116/200620.nc\n",
      "sample/201312116/195117.nc\n",
      "sample/201312116/200921.nc\n",
      "sample/201312116/195718.nc\n",
      "sample/201312116/200320.nc\n",
      "sample/201312116/200019.nc\n",
      "sample/201212246/\n",
      "sample/201212246/223648.nc\n",
      "sample/201212246/224456.nc\n",
      "sample/201212246/225020.nc\n",
      "sample/201212246/224738.nc\n",
      "sample/201212246/225303.nc\n",
      "sample/201212246/223931.nc\n",
      "sample/201212246/224213.nc\n",
      "sample/201010235/\n",
      "sample/201010235/221433.nc\n",
      "sample/201010235/221723.nc\n",
      "sample/201010235/222012.nc\n",
      "sample/201010235/222840.nc\n",
      "sample/201010235/223129.nc\n",
      "sample/201010235/222301.nc\n",
      "sample/201010235/222551.nc\n",
      "sample/201211169/\n",
      "sample/201211169/210518.nc\n",
      "sample/201211169/205655.nc\n",
      "sample/201211169/205942.nc\n",
      "sample/201211169/210231.nc\n",
      "sample/201211169/205119.nc\n",
      "sample/201211169/205407.nc\n",
      "sample/201211169/204831.nc\n",
      "sample/201301117/\n",
      "sample/201301117/230011.nc\n",
      "sample/201301117/225131.nc\n",
      "sample/201301117/230305.nc\n",
      "sample/201301117/225424.nc\n",
      "sample/201301117/224838.nc\n",
      "sample/201301117/225717.nc\n",
      "sample/201301117/224545.nc\n",
      "sample/201001037/\n",
      "sample/201001037/214812.nc\n",
      "sample/201001037/215400.nc\n",
      "sample/201001037/215112.nc\n",
      "sample/201001037/214235.nc\n",
      "sample/201001037/213938.nc\n",
      "sample/201001037/215648.nc\n",
      "sample/201001037/214524.nc\n",
      "sample/201111158/\n",
      "sample/201111158/231905.nc\n",
      "sample/201111158/232140.nc\n",
      "sample/201111158/232650.nc\n",
      "sample/201111158/231630.nc\n",
      "sample/201111158/231355.nc\n",
      "sample/201111158/231119.nc\n",
      "sample/201111158/232415.nc\n",
      "sample/201001056/\n",
      "sample/201001056/115753.nc\n",
      "sample/201001056/120327.nc\n",
      "sample/201001056/120040.nc\n",
      "sample/201001056/114933.nc\n",
      "sample/201001056/114646.nc\n",
      "sample/201001056/115220.nc\n",
      "sample/201001056/115506.nc\n",
      "sample/201001116/\n",
      "sample/201001116/225602.nc\n",
      "sample/201001116/224710.nc\n",
      "sample/201001116/224118.nc\n",
      "sample/201001116/223822.nc\n",
      "sample/201001116/224414.nc\n",
      "sample/201001116/225007.nc\n",
      "sample/201001116/225305.nc\n",
      "sample/201410232/\n",
      "sample/201410232/205639.nc\n",
      "sample/201410232/211209.nc\n",
      "sample/201410232/210557.nc\n",
      "sample/201410232/210903.nc\n",
      "sample/201410232/210251.nc\n",
      "sample/201410232/205945.nc\n",
      "sample/201410232/211515.nc\n",
      "sample/201401277/\n",
      "sample/201401277/230902.nc\n",
      "sample/201401277/230626.nc\n",
      "sample/201401277/225841.nc\n",
      "sample/201401277/230351.nc\n",
      "sample/201401277/230116.nc\n",
      "sample/201401277/231412.nc\n",
      "sample/201401277/231137.nc\n",
      "sample/201501053/\n",
      "sample/201501053/200206.nc\n",
      "sample/201501053/195214.nc\n",
      "sample/201501053/194857.nc\n",
      "sample/201501053/194540.nc\n",
      "sample/201501053/195848.nc\n",
      "sample/201501053/195531.nc\n",
      "sample/201501053/194223.nc\n",
      "sample/201211168/\n",
      "sample/201211168/204009.nc\n",
      "sample/201211168/204543.nc\n",
      "sample/201211168/203146.nc\n",
      "sample/201211168/204256.nc\n",
      "sample/201211168/202859.nc\n",
      "sample/201211168/203721.nc\n",
      "sample/201211168/203433.nc\n",
      "sample/201401275/\n",
      "sample/201401275/222220.nc\n",
      "sample/201401275/222733.nc\n",
      "sample/201401275/222457.nc\n",
      "sample/201401275/223009.nc\n",
      "sample/201401275/223756.nc\n",
      "sample/201401275/223520.nc\n",
      "sample/201401275/223245.nc\n",
      "sample/201301118/\n",
      "sample/201301118/231737.nc\n",
      "sample/201301118/232031.nc\n",
      "sample/201301118/230854.nc\n",
      "sample/201301118/232325.nc\n",
      "sample/201301118/231442.nc\n",
      "sample/201301118/231148.nc\n",
      "sample/201301118/230559.nc\n",
      "sample/201001015/\n",
      "sample/201001015/215319.nc\n",
      "sample/201001015/214744.nc\n",
      "sample/201001015/220430.nc\n",
      "sample/201001015/215854.nc\n",
      "sample/201001015/215606.nc\n",
      "sample/201001015/220142.nc\n",
      "sample/201001015/215031.nc\n",
      "sample/201001051/\n",
      "sample/201001051/000323.nc\n",
      "sample/201001051/001703.nc\n",
      "sample/201001051/001135.nc\n",
      "sample/201001051/000607.nc\n",
      "sample/201001051/000038.nc\n",
      "sample/201001051/001419.nc\n",
      "sample/201001051/000851.nc\n",
      "sample/201401201/\n",
      "sample/201401201/165410.nc\n",
      "sample/201401201/170046.nc\n",
      "sample/201401201/171040.nc\n",
      "sample/201401201/170722.nc\n",
      "sample/201401201/165728.nc\n",
      "sample/201401201/170404.nc\n",
      "sample/201401201/165052.nc\n",
      "sample/201301119/\n",
      "sample/201301119/234342.nc\n",
      "sample/201301119/233501.nc\n",
      "sample/201301119/232619.nc\n",
      "sample/201301119/233207.nc\n",
      "sample/201301119/232913.nc\n",
      "sample/201301119/234048.nc\n",
      "sample/201301119/233754.nc\n",
      "sample/201301111/\n",
      "sample/201301111/155601.nc\n",
      "sample/201301111/160839.nc\n",
      "sample/201301111/160220.nc\n",
      "sample/201301111/160530.nc\n",
      "sample/201301111/155252.nc\n",
      "sample/201301111/154943.nc\n",
      "sample/201301111/155911.nc\n",
      "sample/201301113/\n",
      "sample/201301113/213322.nc\n",
      "sample/201301113/212738.nc\n",
      "sample/201301113/213906.nc\n",
      "sample/201301113/213613.nc\n",
      "sample/201301113/212446.nc\n",
      "sample/201301113/214158.nc\n",
      "sample/201301113/213029.nc\n",
      "sample/201410234/\n",
      "sample/201410234/214925.nc\n",
      "sample/201410234/214312.nc\n",
      "sample/201410234/215232.nc\n",
      "sample/201410234/215538.nc\n",
      "sample/201410234/214006.nc\n",
      "sample/201410234/215844.nc\n",
      "sample/201410234/214619.nc\n",
      "sample/201011284/\n",
      "sample/201011284/220027.nc\n",
      "sample/201011284/220311.nc\n",
      "sample/201011284/220554.nc\n",
      "sample/201011284/215458.nc\n",
      "sample/201011284/215742.nc\n",
      "sample/201011284/215214.nc\n",
      "sample/201011284/214930.nc\n",
      "sample/201001113/\n",
      "sample/201001113/211736.nc\n",
      "sample/201001113/210609.nc\n",
      "sample/201001113/211152.nc\n",
      "sample/201001113/211445.nc\n",
      "sample/201001113/212330.nc\n",
      "sample/201001113/210900.nc\n",
      "sample/201001113/212028.nc\n",
      "sample/201001097/\n",
      "sample/201001097/230036.nc\n",
      "sample/201001097/230905.nc\n",
      "sample/201001097/231155.nc\n",
      "sample/201001097/230326.nc\n",
      "sample/201001097/225457.nc\n",
      "sample/201001097/225746.nc\n",
      "sample/201001097/230615.nc\n",
      "sample/201111153/\n",
      "sample/201111153/214045.nc\n",
      "sample/201111153/215616.nc\n",
      "sample/201111153/215340.nc\n",
      "sample/201111153/214555.nc\n",
      "sample/201111153/215105.nc\n",
      "sample/201111153/214321.nc\n",
      "sample/201111153/214830.nc\n",
      "sample/201211167/\n",
      "sample/201211167/202036.nc\n",
      "sample/201211167/201213.nc\n",
      "sample/201211167/201501.nc\n",
      "sample/201211167/202324.nc\n",
      "sample/201211167/200925.nc\n",
      "sample/201211167/201748.nc\n",
      "sample/201211167/202611.nc\n",
      "sample/201001021/\n",
      "sample/201001021/221551.nc\n",
      "sample/201001021/222906.nc\n",
      "sample/201001021/222124.nc\n",
      "sample/201001021/223242.nc\n",
      "sample/201001021/221837.nc\n",
      "sample/201001021/223658.nc\n",
      "sample/201001021/222409.nc\n",
      "sample/201501059/\n",
      "sample/201501059/220044.nc\n",
      "sample/201501059/222035.nc\n",
      "sample/201501059/220720.nc\n",
      "sample/201501059/221038.nc\n",
      "sample/201501059/221357.nc\n",
      "sample/201501059/220402.nc\n",
      "sample/201501059/221716.nc\n",
      "sample/201011282/\n",
      "sample/201011282/210543.nc\n",
      "sample/201011282/210259.nc\n",
      "sample/201011282/205731.nc\n",
      "sample/201011282/205447.nc\n",
      "sample/201011282/210015.nc\n",
      "sample/201011282/205203.nc\n",
      "sample/201011282/210827.nc\n",
      "sample/201001095/\n",
      "sample/201001095/221816.nc\n",
      "sample/201001095/222106.nc\n",
      "sample/201001095/222353.nc\n",
      "sample/201001095/223220.nc\n",
      "sample/201001095/222931.nc\n",
      "sample/201001095/222642.nc\n",
      "sample/201001095/221526.nc\n",
      "sample/201001018/\n",
      "sample/201001018/232333.nc\n",
      "sample/201001018/231221.nc\n",
      "sample/201001018/230643.nc\n",
      "sample/201001018/230932.nc\n",
      "sample/201001018/232046.nc\n",
      "sample/201001018/231509.nc\n",
      "sample/201001018/231756.nc\n",
      "sample/201001117/\n",
      "sample/201001117/225900.nc\n",
      "sample/201001117/230159.nc\n",
      "sample/201001117/230458.nc\n",
      "sample/201001117/230757.nc\n",
      "sample/201001117/231643.nc\n",
      "sample/201001117/231350.nc\n",
      "sample/201001117/231054.nc\n",
      "sample/201410236/\n",
      "sample/201410236/223247.nc\n",
      "sample/201410236/222941.nc\n",
      "sample/201410236/223553.nc\n",
      "sample/201410236/224204.nc\n",
      "sample/201410236/222329.nc\n",
      "sample/201410236/222635.nc\n",
      "sample/201410236/223859.nc\n",
      "sample/201501055/\n",
      "sample/201501055/202823.nc\n",
      "sample/201501055/204810.nc\n",
      "sample/201501055/203500.nc\n",
      "sample/201501055/204451.nc\n",
      "sample/201501055/203140.nc\n",
      "sample/201501055/204134.nc\n",
      "sample/201501055/203817.nc\n",
      "sample/201010231/\n",
      "sample/201010231/090845.nc\n",
      "sample/201010231/091803.nc\n",
      "sample/201010231/085930.nc\n",
      "sample/201010231/090541.nc\n",
      "sample/201010231/091150.nc\n",
      "sample/201010231/090235.nc\n",
      "sample/201010231/085625.nc\n",
      "sample/201001092/\n",
      "sample/201001092/013845.nc\n",
      "sample/201001092/012135.nc\n",
      "sample/201001092/013302.nc\n",
      "sample/201001092/012719.nc\n",
      "sample/201001092/012427.nc\n",
      "sample/201001092/013011.nc\n",
      "sample/201001092/013554.nc\n",
      "sample/201401208/\n",
      "sample/201401208/204052.nc\n",
      "sample/201401208/205058.nc\n",
      "sample/201401208/205744.nc\n",
      "sample/201401208/204414.nc\n",
      "sample/201401208/205421.nc\n",
      "sample/201401208/203729.nc\n",
      "sample/201401208/204736.nc\n",
      "sample/201111156/\n",
      "sample/201111156/223503.nc\n",
      "sample/201111156/223738.nc\n",
      "sample/201111156/224759.nc\n",
      "sample/201111156/225034.nc\n",
      "sample/201111156/224524.nc\n",
      "sample/201111156/224014.nc\n",
      "sample/201111156/224249.nc\n",
      "sample/201001032/\n",
      "sample/201001032/193133.nc\n",
      "sample/201001032/194254.nc\n",
      "sample/201001032/194544.nc\n",
      "sample/201001032/194004.nc\n",
      "sample/201001032/193715.nc\n",
      "sample/201001032/194835.nc\n",
      "sample/201001032/193424.nc\n",
      "sample/201501057/\n",
      "sample/201501057/213417.nc\n",
      "sample/201501057/212741.nc\n",
      "sample/201501057/213059.nc\n",
      "sample/201501057/211747.nc\n",
      "sample/201501057/211429.nc\n",
      "sample/201501057/212105.nc\n",
      "sample/201501057/212423.nc\n",
      "sample/201001019/\n",
      "sample/201001019/232622.nc\n",
      "sample/201001019/233448.nc\n",
      "sample/201001019/234023.nc\n",
      "sample/201001019/233159.nc\n",
      "sample/201001019/233735.nc\n",
      "sample/201001019/232911.nc\n",
      "sample/201001019/234311.nc\n",
      "sample/201001038/\n",
      "sample/201001038/220239.nc\n",
      "sample/201001038/220527.nc\n",
      "sample/201001038/221106.nc\n",
      "sample/201001038/221354.nc\n",
      "sample/201001038/215951.nc\n",
      "sample/201001038/221643.nc\n",
      "sample/201001038/220817.nc\n",
      "sample/201401202/\n",
      "sample/201401202/180655.nc\n",
      "sample/201401202/180020.nc\n",
      "sample/201401202/181012.nc\n",
      "sample/201401202/182005.nc\n",
      "sample/201401202/180337.nc\n",
      "sample/201401202/181330.nc\n",
      "sample/201401202/181647.nc\n",
      "sample/201001046/\n",
      "sample/201001046/223945.nc\n",
      "sample/201001046/224801.nc\n",
      "sample/201001046/223659.nc\n",
      "sample/201001046/225046.nc\n",
      "sample/201001046/224515.nc\n",
      "sample/201001046/224230.nc\n",
      "sample/201001046/225331.nc\n",
      "sample/201211161/\n",
      "sample/201211161/130032.nc\n",
      "sample/201211161/131424.nc\n",
      "sample/201211161/130851.nc\n",
      "sample/201211161/131710.nc\n",
      "sample/201211161/130318.nc\n",
      "sample/201211161/131137.nc\n",
      "sample/201211161/130605.nc\n",
      "sample/201112037/\n",
      "sample/201112037/230036.nc\n",
      "sample/201112037/230352.nc\n",
      "sample/201112037/225405.nc\n",
      "sample/201112037/225051.nc\n",
      "sample/201112037/225720.nc\n",
      "sample/201112037/223750.nc\n",
      "sample/201112037/230708.nc\n",
      "sample/201001023/\n",
      "sample/201001023/230307.nc\n",
      "sample/201001023/232026.nc\n",
      "sample/201001023/231706.nc\n",
      "sample/201001023/230020.nc\n",
      "sample/201001023/231119.nc\n",
      "sample/201001023/232313.nc\n",
      "sample/201001023/231420.nc\n",
      "sample/201001094/\n",
      "sample/201001094/220407.nc\n",
      "sample/201001094/215538.nc\n",
      "sample/201001094/215828.nc\n",
      "sample/201001094/220947.nc\n",
      "sample/201001094/221235.nc\n",
      "sample/201001094/220117.nc\n",
      "sample/201001094/220657.nc\n",
      "sample/201001054/\n",
      "sample/201001054/112432.nc\n",
      "sample/201001054/112145.nc\n",
      "sample/201001054/111039.nc\n",
      "sample/201001054/111326.nc\n",
      "sample/201001054/110752.nc\n",
      "sample/201001054/111859.nc\n",
      "sample/201001054/111612.nc\n",
      "sample/201312112/\n",
      "sample/201312112/162143.nc\n",
      "sample/201312112/160335.nc\n",
      "sample/201312112/160938.nc\n",
      "sample/201312112/161540.nc\n",
      "sample/201312112/161842.nc\n",
      "sample/201312112/161239.nc\n",
      "sample/201312112/160636.nc\n",
      "sample/201211163/\n",
      "sample/201211163/190452.nc\n",
      "sample/201211163/185049.nc\n",
      "sample/201211163/185626.nc\n",
      "sample/201211163/190741.nc\n",
      "sample/201211163/185338.nc\n",
      "sample/201211163/185915.nc\n",
      "sample/201211163/190204.nc\n",
      "sample/201001042/\n",
      "sample/201001042/212514.nc\n",
      "sample/201001042/213614.nc\n",
      "sample/201001042/212229.nc\n",
      "sample/201001042/212758.nc\n",
      "sample/201001042/213044.nc\n",
      "sample/201001042/213329.nc\n",
      "sample/201001042/211944.nc\n",
      "sample/201001115/\n",
      "sample/201001115/223527.nc\n",
      "sample/201001115/222643.nc\n",
      "sample/201001115/221758.nc\n",
      "sample/201001115/223231.nc\n",
      "sample/201001115/222348.nc\n",
      "sample/201001115/222054.nc\n",
      "sample/201001115/222937.nc\n",
      "sample/201010277/\n",
      "sample/201010277/075232.nc\n",
      "sample/201010277/080340.nc\n",
      "sample/201010277/074944.nc\n",
      "sample/201010277/080054.nc\n",
      "sample/201010277/075520.nc\n",
      "sample/201010277/074654.nc\n",
      "sample/201010277/075808.nc\n",
      "sample/201001012/\n",
      "sample/201001012/205720.nc\n",
      "sample/201001012/205143.nc\n",
      "sample/201001012/210546.nc\n",
      "sample/201001012/210009.nc\n",
      "sample/201001012/210257.nc\n",
      "sample/201001012/205432.nc\n",
      "sample/201001012/204855.nc\n",
      "sample/201001016/\n",
      "sample/201001016/223248.nc\n",
      "sample/201001016/223001.nc\n",
      "sample/201001016/223535.nc\n",
      "sample/201001016/223823.nc\n",
      "sample/201001016/222714.nc\n",
      "sample/201001016/224110.nc\n",
      "sample/201001016/224358.nc\n",
      "sample/201011283/\n",
      "sample/201011283/213304.nc\n",
      "sample/201011283/214402.nc\n",
      "sample/201011283/213832.nc\n",
      "sample/201011283/213548.nc\n",
      "sample/201011283/214645.nc\n",
      "sample/201011283/213019.nc\n",
      "sample/201011283/214117.nc\n",
      "sample/201111159/\n",
      "sample/201111159/233711.nc\n",
      "sample/201111159/234222.nc\n",
      "sample/201111159/233947.nc\n",
      "sample/201111159/233437.nc\n",
      "sample/201111159/233201.nc\n",
      "sample/201111159/234458.nc\n",
      "sample/201111159/232926.nc\n",
      "sample/201312115/\n",
      "sample/201312115/193311.nc\n",
      "sample/201312115/193612.nc\n",
      "sample/201312115/193010.nc\n",
      "sample/201312115/193913.nc\n",
      "sample/201312115/194213.nc\n",
      "sample/201312115/194514.nc\n",
      "sample/201312115/194815.nc\n",
      "sample/201211162/\n",
      "sample/201211162/164731.nc\n",
      "sample/201211162/164444.nc\n",
      "sample/201211162/164158.nc\n",
      "sample/201211162/163338.nc\n",
      "sample/201211162/165017.nc\n",
      "sample/201211162/163911.nc\n",
      "sample/201211162/163625.nc\n",
      "sample/201212247/\n",
      "sample/201212247/231200.nc\n",
      "sample/201212247/230352.nc\n",
      "sample/201212247/225545.nc\n",
      "sample/201212247/230917.nc\n",
      "sample/201212247/230635.nc\n",
      "sample/201212247/230110.nc\n",
      "sample/201212247/225828.nc\n",
      "sample/201001049/\n",
      "sample/201001049/234348.nc\n",
      "sample/201001049/233802.nc\n",
      "sample/201001049/234917.nc\n",
      "sample/201001049/233518.nc\n",
      "sample/201001049/234633.nc\n",
      "sample/201001049/235201.nc\n",
      "sample/201001049/234046.nc\n",
      "sample/201010274/\n",
      "sample/201010274/070441.nc\n",
      "sample/201010274/065905.nc\n",
      "sample/201010274/064504.nc\n",
      "sample/201010274/064752.nc\n",
      "sample/201010274/065040.nc\n",
      "sample/201010274/070154.nc\n",
      "sample/201010274/065327.nc\n",
      "sample/201410239/\n",
      "sample/201410239/234056.nc\n",
      "sample/201410239/234401.nc\n",
      "sample/201410239/234707.nc\n",
      "sample/201410239/233139.nc\n",
      "sample/201410239/233751.nc\n",
      "sample/201410239/232834.nc\n",
      "sample/201410239/233445.nc\n",
      "sample/201010272/\n",
      "sample/201010272/060613.nc\n",
      "sample/201010272/061431.nc\n",
      "sample/201010272/061145.nc\n",
      "sample/201010272/061717.nc\n",
      "sample/201010272/060858.nc\n",
      "sample/201010272/062003.nc\n",
      "sample/201010272/062250.nc\n",
      "sample/201011285/\n",
      "sample/201011285/221652.nc\n",
      "sample/201011285/222525.nc\n",
      "sample/201011285/222241.nc\n",
      "sample/201011285/221936.nc\n",
      "sample/201011285/221407.nc\n",
      "sample/201011285/220839.nc\n",
      "sample/201011285/221122.nc\n",
      "sample/201112035/\n",
      "sample/201112035/220208.nc\n",
      "sample/201112035/214745.nc\n",
      "sample/201112035/215121.nc\n",
      "sample/201112035/215832.nc\n",
      "sample/201112035/220543.nc\n",
      "sample/201112035/220918.nc\n",
      "sample/201112035/215456.nc\n",
      "sample/201001034/\n",
      "sample/201001034/203404.nc\n",
      "sample/201001034/202022.nc\n",
      "sample/201001034/202817.nc\n",
      "sample/201001034/201445.nc\n",
      "sample/201001034/203115.nc\n",
      "sample/201001034/202337.nc\n",
      "sample/201001034/201733.nc\n",
      "sample/201001043/\n",
      "sample/201001043/214143.nc\n",
      "sample/201001043/213859.nc\n",
      "sample/201001043/214959.nc\n",
      "sample/201001043/214428.nc\n",
      "sample/201001043/215533.nc\n",
      "sample/201001043/214714.nc\n",
      "sample/201001043/215246.nc\n",
      "sample/201001014/\n",
      "sample/201001014/213919.nc\n",
      "sample/201001014/213057.nc\n",
      "sample/201001014/213632.nc\n",
      "sample/201001014/212809.nc\n",
      "sample/201001014/214456.nc\n",
      "sample/201001014/213345.nc\n",
      "sample/201001014/214208.nc\n",
      "sample/201301115/\n",
      "sample/201301115/220754.nc\n",
      "sample/201301115/221638.nc\n",
      "sample/201301115/221048.nc\n",
      "sample/201301115/222228.nc\n",
      "sample/201301115/221933.nc\n",
      "sample/201301115/221343.nc\n",
      "sample/201301115/220501.nc\n",
      "sample/201001013/\n",
      "sample/201001013/212520.nc\n",
      "sample/201001013/211945.nc\n",
      "sample/201001013/211657.nc\n",
      "sample/201001013/212232.nc\n",
      "sample/201001013/211410.nc\n",
      "sample/201001013/210835.nc\n",
      "sample/201001013/211122.nc\n",
      "sample/201111157/\n",
      "sample/201111157/225819.nc\n",
      "sample/201111157/225309.nc\n",
      "sample/201111157/225544.nc\n",
      "sample/201111157/230843.nc\n",
      "sample/201111157/230606.nc\n",
      "sample/201111157/230330.nc\n",
      "sample/201111157/230054.nc\n",
      "sample/201112101/\n",
      "sample/201112101/163725.nc\n",
      "sample/201112101/162942.nc\n",
      "sample/201112101/162200.nc\n",
      "sample/201112101/162708.nc\n",
      "sample/201112101/163450.nc\n",
      "sample/201112101/163216.nc\n",
      "sample/201112101/162434.nc\n",
      "sample/201112108/\n",
      "sample/201112108/233642.nc\n",
      "sample/201112108/233915.nc\n",
      "sample/201112108/234149.nc\n",
      "sample/201112108/233133.nc\n",
      "sample/201112108/232859.nc\n",
      "sample/201112108/233407.nc\n",
      "sample/201112108/232625.nc\n",
      "sample/201501052/\n",
      "sample/201501052/193548.nc\n",
      "sample/201501052/193906.nc\n",
      "sample/201501052/192234.nc\n",
      "sample/201501052/191916.nc\n",
      "sample/201501052/192553.nc\n",
      "sample/201501052/192913.nc\n",
      "sample/201501052/193231.nc\n",
      "sample/201011287/\n",
      "sample/201011287/225039.nc\n",
      "sample/201011287/225324.nc\n",
      "sample/201011287/225609.nc\n",
      "sample/201011287/224755.nc\n",
      "sample/201011287/230151.nc\n",
      "sample/201011287/230436.nc\n",
      "sample/201011287/225854.nc\n",
      "sample/201001022/\n",
      "sample/201001022/225446.nc\n",
      "sample/201001022/225732.nc\n",
      "sample/201001022/224517.nc\n",
      "sample/201001022/224230.nc\n",
      "sample/201001022/223944.nc\n",
      "sample/201001022/224911.nc\n",
      "sample/201001022/225159.nc\n",
      "sample/201401209/\n",
      "sample/201401209/210429.nc\n",
      "sample/201401209/211114.nc\n",
      "sample/201401209/211800.nc\n",
      "sample/201401209/212123.nc\n",
      "sample/201401209/211437.nc\n",
      "sample/201401209/210106.nc\n",
      "sample/201401209/210752.nc\n",
      "sample/201401204/\n",
      "sample/201401204/190607.nc\n",
      "sample/201401204/184941.nc\n",
      "sample/201401204/185933.nc\n",
      "sample/201401204/185615.nc\n",
      "sample/201401204/184624.nc\n",
      "sample/201401204/185258.nc\n",
      "sample/201401204/190250.nc\n",
      "sample/201112103/\n",
      "sample/201112103/215050.nc\n",
      "sample/201112103/214816.nc\n",
      "sample/201112103/215324.nc\n",
      "sample/201112103/214542.nc\n",
      "sample/201112103/215832.nc\n",
      "sample/201112103/215557.nc\n",
      "sample/201112103/220105.nc\n",
      "sample/201010233/\n",
      "sample/201010233/170505.nc\n",
      "sample/201010233/165332.nc\n",
      "sample/201010233/170754.nc\n",
      "sample/201010233/165020.nc\n",
      "sample/201010233/164732.nc\n",
      "sample/201010233/170216.nc\n",
      "sample/201010233/165927.nc\n",
      "sample/201001057/\n",
      "sample/201001057/122002.nc\n",
      "sample/201001057/121430.nc\n",
      "sample/201001057/120612.nc\n",
      "sample/201001057/120858.nc\n",
      "sample/201001057/122248.nc\n",
      "sample/201001057/121716.nc\n",
      "sample/201001057/121144.nc\n",
      "sample/201401207/\n",
      "sample/201401207/202032.nc\n",
      "sample/201401207/202354.nc\n",
      "sample/201401207/201346.nc\n",
      "sample/201401207/202718.nc\n",
      "sample/201401207/203042.nc\n",
      "sample/201401207/203406.nc\n",
      "sample/201401207/201709.nc\n",
      "sample/201301116/\n",
      "sample/201301116/223956.nc\n",
      "sample/201301116/222818.nc\n",
      "sample/201301116/224250.nc\n",
      "sample/201301116/223112.nc\n",
      "sample/201301116/223407.nc\n",
      "sample/201301116/222523.nc\n",
      "sample/201301116/223701.nc\n",
      "sample/201010273/\n",
      "sample/201010273/062822.nc\n",
      "sample/201010273/063642.nc\n",
      "sample/201010273/063108.nc\n",
      "sample/201010273/062536.nc\n",
      "sample/201010273/064217.nc\n",
      "sample/201010273/063929.nc\n",
      "sample/201010273/063355.nc\n",
      "sample/201312119/\n",
      "sample/201312119/213605.nc\n",
      "sample/201312119/212435.nc\n",
      "sample/201312119/213313.nc\n",
      "sample/201312119/213021.nc\n",
      "sample/201312119/212728.nc\n",
      "sample/201312119/214150.nc\n",
      "sample/201312119/213858.nc\n",
      "sample/201010239/\n",
      "sample/201010239/235200.nc\n",
      "sample/201010239/233802.nc\n",
      "sample/201010239/234913.nc\n",
      "sample/201010239/234625.nc\n",
      "sample/201010239/234049.nc\n",
      "sample/201010239/234338.nc\n",
      "sample/201010239/233515.nc\n",
      "sample/201410235/\n",
      "sample/201410235/221717.nc\n",
      "sample/201410235/221107.nc\n",
      "sample/201410235/221412.nc\n",
      "sample/201410235/220801.nc\n",
      "sample/201410235/220149.nc\n",
      "sample/201410235/222023.nc\n",
      "sample/201410235/220455.nc\n",
      "sample/201001052/\n",
      "sample/201001052/101753.nc\n",
      "sample/201001052/102039.nc\n",
      "sample/201001052/100648.nc\n",
      "sample/201001052/101507.nc\n",
      "sample/201001052/102325.nc\n",
      "sample/201001052/101220.nc\n",
      "sample/201001052/100934.nc\n",
      "sample/201001024/\n",
      "sample/201001024/232600.nc\n",
      "sample/201001024/233422.nc\n",
      "sample/201001024/232848.nc\n",
      "sample/201001024/234303.nc\n",
      "sample/201001024/233954.nc\n",
      "sample/201001024/233708.nc\n",
      "sample/201001024/233135.nc\n",
      "sample/201312117/\n",
      "sample/201312117/202727.nc\n",
      "sample/201312117/203027.nc\n",
      "sample/201312117/201824.nc\n",
      "sample/201312117/201222.nc\n",
      "sample/201312117/202425.nc\n",
      "sample/201312117/202124.nc\n",
      "sample/201312117/201523.nc\n",
      "sample/201401278/\n",
      "sample/201401278/231648.nc\n",
      "sample/201401278/233219.nc\n",
      "sample/201401278/231923.nc\n",
      "sample/201401278/232708.nc\n",
      "sample/201401278/232434.nc\n",
      "sample/201401278/232158.nc\n",
      "sample/201401278/232943.nc\n",
      "sample/201212241/\n",
      "sample/201212241/160820.nc\n",
      "sample/201212241/160010.nc\n",
      "sample/201212241/161104.nc\n",
      "sample/201212241/155728.nc\n",
      "sample/201212241/161346.nc\n",
      "sample/201212241/160253.nc\n",
      "sample/201212241/160537.nc\n",
      "sample/201001059/\n",
      "sample/201001059/125558.nc\n",
      "sample/201001059/125027.nc\n",
      "sample/201001059/125312.nc\n",
      "sample/201001059/125843.nc\n",
      "sample/201001059/124456.nc\n",
      "sample/201001059/124742.nc\n",
      "sample/201001059/130128.nc\n",
      "sample/201212248/\n",
      "sample/201212248/232816.nc\n",
      "sample/201212248/231726.nc\n",
      "sample/201212248/232009.nc\n",
      "sample/201212248/232533.nc\n",
      "sample/201212248/231443.nc\n",
      "sample/201212248/233059.nc\n",
      "sample/201212248/232251.nc\n",
      "sample/201010278/\n",
      "sample/201010278/081442.nc\n",
      "sample/201010278/082256.nc\n",
      "sample/201010278/082011.nc\n",
      "sample/201010278/081157.nc\n",
      "sample/201010278/080912.nc\n",
      "sample/201010278/081727.nc\n",
      "sample/201010278/080627.nc\n",
      "sample/201001055/\n",
      "sample/201001055/114113.nc\n",
      "sample/201001055/113826.nc\n",
      "sample/201001055/114359.nc\n",
      "sample/201001055/113006.nc\n",
      "sample/201001055/112719.nc\n",
      "sample/201001055/113252.nc\n",
      "sample/201001055/113539.nc\n",
      "sample/201001044/\n",
      "sample/201001044/220922.nc\n",
      "sample/201001044/221207.nc\n",
      "sample/201001044/215819.nc\n",
      "sample/201001044/220636.nc\n",
      "sample/201001044/220350.nc\n",
      "sample/201001044/220105.nc\n",
      "sample/201001044/221453.nc\n",
      "sample/201212249/\n",
      "sample/201212249/233624.nc\n",
      "sample/201212249/234431.nc\n",
      "sample/201212249/234714.nc\n",
      "sample/201212249/234149.nc\n",
      "sample/201212249/234956.nc\n",
      "sample/201212249/233341.nc\n",
      "sample/201212249/233906.nc\n",
      "sample/201111152/\n",
      "sample/201111152/202038.nc\n",
      "sample/201111152/201251.nc\n",
      "sample/201111152/201527.nc\n",
      "sample/201111152/201802.nc\n",
      "sample/201111152/202313.nc\n",
      "sample/201111152/201016.nc\n",
      "sample/201111152/202548.nc\n",
      "sample/201001047/\n",
      "sample/201001047/230736.nc\n",
      "sample/201001047/225918.nc\n",
      "sample/201001047/230451.nc\n",
      "sample/201001047/231020.nc\n",
      "sample/201001047/225632.nc\n",
      "sample/201001047/230204.nc\n",
      "sample/201001047/231306.nc\n",
      "sample/201312111/\n",
      "sample/201312111/122851.nc\n",
      "sample/201312111/121042.nc\n",
      "sample/201312111/121947.nc\n",
      "sample/201312111/121645.nc\n",
      "sample/201312111/122248.nc\n",
      "sample/201312111/122549.nc\n",
      "sample/201312111/121344.nc\n",
      "sample/201301112/\n",
      "sample/201301112/200443.nc\n",
      "sample/201301112/202152.nc\n",
      "sample/201301112/201900.nc\n",
      "sample/201301112/201025.nc\n",
      "sample/201301112/201316.nc\n",
      "sample/201301112/201608.nc\n",
      "sample/201301112/200734.nc\n",
      "sample/201112036/\n",
      "sample/201112036/223417.nc\n",
      "sample/201112036/222335.nc\n",
      "sample/201112036/223043.nc\n",
      "sample/201112036/221627.nc\n",
      "sample/201112036/222709.nc\n",
      "sample/201112036/221253.nc\n",
      "sample/201112036/222000.nc\n",
      "sample/201212245/\n",
      "sample/201212245/222558.nc\n",
      "sample/201212245/223124.nc\n",
      "sample/201212245/223406.nc\n",
      "sample/201212245/222315.nc\n",
      "sample/201212245/221749.nc\n",
      "sample/201212245/222033.nc\n",
      "sample/201212245/222841.nc\n",
      "sample/201001036/\n",
      "sample/201001036/211924.nc\n",
      "sample/201001036/210811.nc\n",
      "sample/201001036/211058.nc\n",
      "sample/201001036/210510.nc\n",
      "sample/201001036/211636.nc\n",
      "sample/201001036/211346.nc\n",
      "sample/201001036/210218.nc\n",
      "sample/201112031/\n",
      "sample/201112031/151803.nc\n",
      "sample/201112031/152130.nc\n",
      "sample/201112031/150741.nc\n",
      "sample/201112031/152457.nc\n",
      "sample/201112031/151435.nc\n",
      "sample/201112031/151108.nc\n",
      "sample/201112031/150414.nc\n",
      "sample/201010238/\n",
      "sample/201010238/232117.nc\n",
      "sample/201010238/231724.nc\n",
      "sample/201010238/233227.nc\n",
      "sample/201010238/232404.nc\n",
      "sample/201010238/232939.nc\n",
      "sample/201010238/232652.nc\n",
      "sample/201010238/231420.nc\n",
      "sample/201501056/\n",
      "sample/201501056/205804.nc\n",
      "sample/201501056/205445.nc\n",
      "sample/201501056/211112.nc\n",
      "sample/201501056/210121.nc\n",
      "sample/201501056/210755.nc\n",
      "sample/201501056/210438.nc\n",
      "sample/201501056/205129.nc\n",
      "sample/201001033/\n",
      "sample/201001033/200426.nc\n",
      "sample/201001033/200127.nc\n",
      "sample/201001033/195514.nc\n",
      "sample/201001033/200854.nc\n",
      "sample/201001033/201143.nc\n",
      "sample/201001033/195839.nc\n",
      "sample/201001033/195157.nc\n",
      "sample/201010271/\n",
      "sample/201010271/032507.nc\n",
      "sample/201010271/032224.nc\n",
      "sample/201010271/033033.nc\n",
      "sample/201010271/031415.nc\n",
      "sample/201010271/032750.nc\n",
      "sample/201010271/031941.nc\n",
      "sample/201010271/031658.nc\n",
      "sample/201112106/\n",
      "sample/201112106/230552.nc\n",
      "sample/201112106/223934.nc\n",
      "sample/201112106/230319.nc\n",
      "sample/201112106/225811.nc\n",
      "sample/201112106/230045.nc\n",
      "sample/201112106/224207.nc\n",
      "sample/201112106/225536.nc\n",
      "sample/201401279/\n",
      "sample/201401279/235030.nc\n",
      "sample/201401279/234007.nc\n",
      "sample/201401279/234754.nc\n",
      "sample/201401279/234242.nc\n",
      "sample/201401279/234517.nc\n",
      "sample/201401279/233731.nc\n",
      "sample/201401279/233455.nc\n",
      "sample/201112038/\n",
      "sample/201112038/231025.nc\n",
      "sample/201112038/232017.nc\n",
      "sample/201112038/233009.nc\n",
      "sample/201112038/231342.nc\n",
      "sample/201112038/232652.nc\n",
      "sample/201112038/231700.nc\n",
      "sample/201112038/232334.nc\n",
      "sample/201410231/\n",
      "sample/201410231/172929.nc\n",
      "sample/201410231/172013.nc\n",
      "sample/201410231/173540.nc\n",
      "sample/201410231/172318.nc\n",
      "sample/201410231/172623.nc\n",
      "sample/201410231/173235.nc\n",
      "sample/201410231/173845.nc\n",
      "sample/201501058/\n",
      "sample/201501058/215726.nc\n",
      "sample/201501058/214731.nc\n",
      "sample/201501058/215049.nc\n",
      "sample/201501058/215408.nc\n",
      "sample/201501058/214053.nc\n",
      "sample/201501058/213735.nc\n",
      "sample/201501058/214412.nc\n",
      "sample/201001058/\n",
      "sample/201001058/123351.nc\n",
      "sample/201001058/122819.nc\n",
      "sample/201001058/123105.nc\n",
      "sample/201001058/123925.nc\n",
      "sample/201001058/123638.nc\n",
      "sample/201001058/124211.nc\n",
      "sample/201001058/122534.nc\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf /home/sample.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec770cc-2e7d-4ca2-b908-7ee098a5b596",
   "metadata": {
    "id": "9ec770cc-2e7d-4ca2-b908-7ee098a5b596",
    "outputId": "392d73ea-0d1f-4f22-b60b-3d378251092b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version PyTorch built with: 12.1\n",
      "Number of GPUs: 1\n",
      "GPU Name: NVIDIA H100 80GB HBM3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version PyTorch built with: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb893018-e461-4170-bd08-9cefba404415",
   "metadata": {
    "id": "eb893018-e461-4170-bd08-9cefba404415",
    "outputId": "659baab6-c872-42d7-ee99-a44ea00fd074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El directorio '/home/sample' contiene 184 subcarpetas (directorios).\n",
      "\n",
      "Algunas de las subcarpetas encontradas:\n",
      "- 201001112\n",
      "- 201010232\n",
      "- 201211166\n",
      "- 201401206\n",
      "- 201111155\n",
      "- 201112109\n",
      "- 201111151\n",
      "- 201112105\n",
      "- 201010236\n",
      "- 201501051\n",
      "... y 174 más.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# El path base que quieres inspeccionar\n",
    "base_path = \"/home/sample\"\n",
    "\n",
    "# Verificar si el path base existe\n",
    "if not os.path.exists(base_path):\n",
    "    print(f\"Error: El directorio base '{base_path}' no existe.\")\n",
    "else:\n",
    "    # Listar todos los contenidos del directorio base\n",
    "    try:\n",
    "        all_contents = os.listdir(base_path)\n",
    "\n",
    "        # Filtrar para quedarnos solo con los directorios\n",
    "        subdirectories = [d for d in all_contents if os.path.isdir(os.path.join(base_path, d))]\n",
    "\n",
    "        # Contar la cantidad de subdirectorios\n",
    "        num_subdirectories = len(subdirectories)\n",
    "\n",
    "        print(f\"El directorio '{base_path}' contiene {num_subdirectories} subcarpetas (directorios).\")\n",
    "\n",
    "        # Opcional: Imprimir los primeros N nombres de subcarpetas para verificar\n",
    "        if num_subdirectories > 0:\n",
    "            print(\"\\nAlgunas de las subcarpetas encontradas:\")\n",
    "            for i, subdir_name in enumerate(subdirectories):\n",
    "                if i < 10: # Imprime las primeras 10 (o menos si hay menos)\n",
    "                    print(f\"- {subdir_name}\")\n",
    "                else:\n",
    "                    break\n",
    "            if num_subdirectories > 10:\n",
    "                print(f\"... y {num_subdirectories - 10} más.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error al intentar listar los contenidos de '{base_path}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c5fd3-2adb-477c-a88c-43534f9e647a",
   "metadata": {
    "id": "da8c5fd3-2adb-477c-a88c-43534f9e647a",
    "outputId": "13641949-af46-44a2-a46a-c47df8cc0195"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 18:54:27,522 - INFO - Semillas configuradas con valor: 42\n",
      "2025-06-02 18:54:27,525 - INFO - Usando muestra aleatoria de 10 secuencias.\n",
      "2025-06-02 18:54:27,525 - INFO - Total secuencias a usar: 10.\n",
      "2025-06-02 18:54:27,525 - INFO - Entrenamiento: 8 sec. Validación: 2 sec.\n",
      "2025-06-02 18:54:27,579 - INFO - Archivo /home/sample/201001013/212520.nc: Min=-29.00, Max=61.50\n",
      "2025-06-02 18:54:27,615 - INFO - Archivo /home/sample/201001032/194835.nc: Min=-29.00, Max=58.50\n",
      "2025-06-02 18:54:27,646 - INFO - Archivo /home/sample/201212241/161346.nc: Min=-29.00, Max=60.50\n",
      "2025-06-02 18:54:27,681 - INFO - Archivo /home/sample/201312117/203027.nc: Min=-29.00, Max=61.00\n",
      "2025-06-02 18:54:27,713 - INFO - Archivo /home/sample/201211165/194701.nc: Min=-29.00, Max=58.00\n",
      "2025-06-02 18:54:27,744 - INFO - Archivo /home/sample/201401272/183604.nc: Min=-29.00, Max=59.00\n",
      "2025-06-02 18:54:27,776 - INFO - Archivo /home/sample/201001056/120327.nc: Min=-29.00, Max=59.50\n",
      "2025-06-02 18:54:27,810 - INFO - Archivo /home/sample/201112109/235950.nc: Min=-29.00, Max=66.50\n",
      "2025-06-02 18:54:27,814 - INFO - RadarDataset inicializado con 8 secuencias válidas.\n",
      "2025-06-02 18:54:27,859 - INFO - Archivo /home/sample/201211162/165017.nc: Min=-29.00, Max=58.00\n",
      "2025-06-02 18:54:27,893 - INFO - Archivo /home/sample/201001031/162058.nc: Min=-29.00, Max=50.00\n",
      "2025-06-02 18:54:27,896 - INFO - RadarDataset inicializado con 2 secuencias válidas.\n",
      "2025-06-02 18:54:27,929 - INFO - Modelo ConvLSTM3D_Enhanced creado: 2 capas, Hidden dims: [32, 32], LayerNorm: True, PredSteps: 1\n",
      "2025-06-02 18:54:27,930 - INFO - Arquitectura del modelo:\n",
      "ConvLSTM3D_Enhanced(\n",
      "  (layers): ModuleList(\n",
      "    (0): ConvLSTM2DLayer(\n",
      "      (cell): ConvLSTMCell(\n",
      "        (conv): Conv2d(33, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): ConvLSTM2DLayer(\n",
      "      (cell): ConvLSTMCell(\n",
      "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer_norms): ModuleList(\n",
      "    (0-1): 2 x LayerNorm((32, 500, 500), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (output_conv): Conv3d(32, 1, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "2025-06-02 18:54:27,932 - INFO - Número total de parámetros entrenables: 32,112,289\n",
      "2025-06-02 18:54:27,933 - INFO - No se encontró modelo pre-entrenado. Entrenando desde cero...\n",
      "2025-06-02 18:54:27,933 - INFO - Usando dispositivo: cuda\n",
      "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-02 18:54:28,270 - INFO - Iniciando entrenamiento: 2 épocas, LR: 0.001, Batch (efectivo): 1\n",
      "2025-06-02 18:54:28,272 - INFO - Inicio Época 1 - Memoria GPU Asignada: 0.12 GB, Reservada: 0.14 GB\n",
      "2025-06-02 18:54:37,679 - INFO -   Predicciones (normalizadas): Min=0.0239, Max=0.9600, Mean=0.6304\n",
      "2025-06-02 18:54:37,682 - INFO -   Objetivos y (normalizados): Min=-40.0000, Max=0.9705, Mean=-39.3559\n",
      "2025-06-02 18:54:38,826 - INFO - Época 1/2 [1/8] - Pérdida (batch): 1624.848511\n",
      "2025-06-02 18:54:40,487 - INFO - Época 1/2 [2/8] - Pérdida (batch): 1621.658813\n",
      "2025-06-02 18:54:45,292 - INFO - Época 1/2 [3/8] - Pérdida (batch): 1640.696899\n",
      "2025-06-02 18:54:46,814 - INFO - Época 1/2 [4/8] - Pérdida (batch): 1647.251465\n",
      "2025-06-02 18:54:52,398 - INFO - Época 1/2 [5/8] - Pérdida (batch): 1646.184082\n",
      "2025-06-02 18:54:53,919 - INFO - Época 1/2 [6/8] - Pérdida (batch): 1624.791138\n",
      "2025-06-02 18:54:59,420 - INFO - Época 1/2 [7/8] - Pérdida (batch): 1603.221313\n",
      "2025-06-02 18:55:00,946 - INFO - Época 1/2 [8/8] - Pérdida (batch): 1638.704224\n",
      "2025-06-02 18:55:11,264 - INFO - Época 1 completada en 42.99s. Pérdida (train): 1630.919556, Pérdida (val): 1633.700500\n",
      "2025-06-02 18:55:11,358 - INFO - Mejor modelo guardado (Pérdida Val: 1633.700500)\n",
      "2025-06-02 18:55:11,428 - INFO - Checkpoint guardado en la época 1\n",
      "2025-06-02 18:55:11,602 - INFO - Inicio Época 2 - Memoria GPU Asignada: 0.40 GB, Reservada: 0.51 GB\n",
      "2025-06-02 18:55:21,636 - INFO - Época 2/2 [1/8] - Pérdida (batch): 1603.221313\n",
      "2025-06-02 18:55:23,220 - INFO - Época 2/2 [2/8] - Pérdida (batch): 1646.184082\n",
      "2025-06-02 18:55:24,799 - INFO - Época 2/2 [3/8] - Pérdida (batch): 1578.179321\n",
      "2025-06-02 18:55:26,323 - INFO - Época 2/2 [4/8] - Pérdida (batch): 1572.350464\n",
      "2025-06-02 18:55:27,847 - INFO - Época 2/2 [5/8] - Pérdida (batch): 1596.565552\n",
      "2025-06-02 18:55:29,371 - INFO - Época 2/2 [6/8] - Pérdida (batch): 1574.874268\n",
      "2025-06-02 18:55:30,895 - INFO - Época 2/2 [7/8] - Pérdida (batch): 1588.120483\n",
      "2025-06-02 18:55:32,420 - INFO - Época 2/2 [8/8] - Pérdida (batch): 1590.026489\n",
      "2025-06-02 18:55:42,486 - INFO - Época 2 completada en 30.89s. Pérdida (train): 1593.690247, Pérdida (val): 1583.202576\n",
      "2025-06-02 18:55:43,034 - INFO - Mejor modelo guardado (Pérdida Val: 1583.202576)\n",
      "2025-06-02 18:55:43,271 - INFO - Checkpoint guardado en la época 2\n",
      "2025-06-02 18:55:43,272 - INFO - Entrenamiento finalizado.\n",
      "2025-06-02 18:55:43,373 - INFO - Curvas de pérdida guardadas en /home/model_output_final_v_ckpt/loss_curves.png\n",
      "2025-06-02 18:55:43,378 - INFO - Modelo listo para predicción. Dtype: torch.float32, Dispositivo: cuda:0\n",
      "2025-06-02 18:55:43,379 - INFO - Generando predicciones de ejemplo...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import logging\n",
    "import xarray as xr # <<< MEJORA: Usar xarray para una lectura robusta\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchmetrics\n",
    "import torch.amp\n",
    "import matplotlib.pyplot as plt\n",
    "import pyproj\n",
    "from netCDF4 import Dataset as NCDataset\n",
    "\n",
    "\n",
    "# Configuración del Logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Configuración para reproducibilidad y rendimiento\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    logging.info(f\"Semillas configuradas con valor: {seed}\")\n",
    "\n",
    "class RadarDataset(Dataset):\n",
    "    def __init__(self, sequence_paths, seq_len=12, pred_len=5, \n",
    "                 min_dbz_norm=-29.0, max_dbz_norm=65.0):\n",
    "        self.sequence_paths = sequence_paths\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.min_dbz_norm = min_dbz_norm\n",
    "        self.max_dbz_norm = max_dbz_norm\n",
    "        logging.info(f\"RadarDataset inicializado con {len(self.sequence_paths)} secuencias.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence_files = self.sequence_paths[idx]\n",
    "        data_list = []\n",
    "\n",
    "        for file_path in sequence_files:\n",
    "            try:\n",
    "                # <<< MEJORA: Lectura automática y segura con xarray >>>\n",
    "                # xarray maneja _FillValue, scale_factor y add_offset automáticamente\n",
    "                with xr.open_dataset(file_path, mask_and_scale=True, decode_times=False) as ds:\n",
    "                    # .values extrae un array de numpy puro con NaNs donde corresponde\n",
    "                    dbz_physical = ds['DBZ'].values\n",
    "                \n",
    "                # Normalización, preservando NaNs\n",
    "                dbz_clipped = np.clip(dbz_physical, self.min_dbz_norm, self.max_dbz_norm)\n",
    "                dbz_normalized = (dbz_clipped - self.min_dbz_norm) / (self.max_dbz_norm - self.min_dbz_norm)\n",
    "                \n",
    "                data_list.append(dbz_normalized[0, ..., np.newaxis]) # [0] para quitar dim de tiempo, newaxis para canal\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error procesando archivo {file_path}. Omitiendo secuencia. Error: {e}\")\n",
    "                # Devolver la siguiente muestra si esta falla\n",
    "                return self.__getitem__((idx + 1) % len(self))\n",
    "        \n",
    "        full_sequence = np.stack(data_list, axis=1) # Forma: (Z, T, H, W, C)\n",
    "        \n",
    "        input_tensor = full_sequence[:, :self.seq_len, ...]\n",
    "        output_tensor = full_sequence[:, self.seq_len:, ...]\n",
    "\n",
    "        # Reemplazar NaNs con 0 para la entrada (X)\n",
    "        x = torch.from_numpy(np.nan_to_num(input_tensor, nan=0.0)).float()\n",
    "        # Mantener NaNs para el objetivo (Y) para la pérdida enmascarada\n",
    "        y = torch.from_numpy(output_tensor).float()\n",
    "        \n",
    "        # --- Lógica para devolver Timestamps (DEBES IMPLEMENTAR LA EXTRACCIÓN REAL) ---\n",
    "        # last_input_file_path = sequence_files[self.seq_len - 1]\n",
    "        # filename_no_ext = os.path.splitext(os.path.basename(last_input_file_path))[0]\n",
    "        # last_input_dt_utc_placeholder = datetime.utcnow() # ¡ESTO ES SOLO UN PLACEHOLDER!\n",
    "        # try:\n",
    "        #     # Intenta parsear el timestamp del nombre del archivo o del subdirectorio\n",
    "        #     # Ejemplo: parts = filename_no_ext.split('_'); timestamp_str = parts[0][-8:] + parts[1]\n",
    "        #     # last_input_dt_utc = datetime.strptime(timestamp_str, \"%Y%m%d%H%M%S\")\n",
    "        #     pass # Implementa tu lógica de parseo aquí\n",
    "        # except Exception as e_time:\n",
    "        #     logging.warning(f\"No se pudo parsear el timestamp de {last_input_file_path} en dataset. Usando placeholder. Error: {e_time}\")\n",
    "        #     # last_input_dt_utc = last_input_dt_utc_placeholder # Mantener el placeholder si falla\n",
    "    \n",
    "        # return x, y, last_input_dt_utc_placeholder # Si devuelves timestamp\n",
    "        return x, y # Si NO devuelves timestamp por ahora\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "        nn.init.xavier_uniform_(self.conv.weight)\n",
    "        if self.bias:\n",
    "            nn.init.zeros_(self.conv.bias)\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        return h_next, c_next\n",
    "    def init_hidden(self, batch_size, image_size, device):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=device))\n",
    "\n",
    "class ConvLSTM2DLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True, return_all_layers=False):\n",
    "        super(ConvLSTM2DLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "        self.cell = ConvLSTMCell(input_dim, hidden_dim, kernel_size, bias)\n",
    "\n",
    "    def forward(self, input_tensor, hidden_state=None): # input_tensor: (B, T_in, C_in, H, W)\n",
    "        b, seq_len, _, h, w = input_tensor.size() # _ es C_in\n",
    "        device = input_tensor.device\n",
    "        if hidden_state is None:\n",
    "            hidden_state = self.cell.init_hidden(b, (h, w), device)\n",
    "\n",
    "        layer_output_list = []\n",
    "        h_cur, c_cur = hidden_state\n",
    "        for t in range(seq_len):\n",
    "            h_cur, c_cur = self.cell(input_tensor=input_tensor[:, t, :, :, :], cur_state=[h_cur, c_cur])\n",
    "            layer_output_list.append(h_cur)\n",
    "\n",
    "        if self.return_all_layers:\n",
    "            layer_output = torch.stack(layer_output_list, dim=1) # (B, T_in, C_hidden, H, W)\n",
    "        else:\n",
    "            # Solo el último estado oculto como salida de la capa, pero manteniendo la dim de tiempo\n",
    "            layer_output = h_cur.unsqueeze(1) # (B, 1, C_hidden, H, W)\n",
    "\n",
    "        return layer_output, (h_cur, c_cur)\n",
    "\n",
    "class ConvLSTM3D_Enhanced(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dims=[32, 64], kernel_sizes=[(3,3), (3,3)],\n",
    "                 num_layers=2, pred_steps=1, use_layer_norm=True, use_residual=False,\n",
    "                 img_height=500, img_width=500):\n",
    "        super(ConvLSTM3D_Enhanced, self).__init__()\n",
    "        if isinstance(hidden_dims, int): hidden_dims = [hidden_dims] * num_layers\n",
    "        if isinstance(kernel_sizes, tuple): kernel_sizes = [kernel_sizes] * num_layers\n",
    "        assert len(hidden_dims) == num_layers and len(kernel_sizes) == num_layers\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.num_layers = num_layers\n",
    "        self.pred_steps = pred_steps\n",
    "        self.use_layer_norm = use_layer_norm\n",
    "        self.use_residual = use_residual\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layer_norms = nn.ModuleList() if use_layer_norm else None\n",
    "\n",
    "        current_dim = input_dim\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(\n",
    "                ConvLSTM2DLayer(input_dim=current_dim, hidden_dim=hidden_dims[i],\n",
    "                                kernel_size=kernel_sizes[i], bias=True,\n",
    "                                return_all_layers=True if i < num_layers - 1 else False)\n",
    "            )\n",
    "            if use_layer_norm:\n",
    "                self.layer_norms.append(nn.LayerNorm([hidden_dims[i], img_height, img_width]))\n",
    "            current_dim = hidden_dims[i]\n",
    "\n",
    "        self.output_conv = nn.Conv3d(in_channels=hidden_dims[-1],\n",
    "                                     out_channels=input_dim * pred_steps,\n",
    "                                     kernel_size=(1, 3, 3), padding=(0, 1, 1))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        nn.init.xavier_uniform_(self.output_conv.weight)\n",
    "        nn.init.zeros_(self.output_conv.bias)\n",
    "\n",
    "        logging.info(f\"Modelo ConvLSTM3D_Enhanced creado: {num_layers} capas, Hidden dims: {hidden_dims}, LayerNorm: {use_layer_norm}, PredSteps: {pred_steps}\")\n",
    "\n",
    "    def forward(self, x_volumetric):  # Espera (Z, B, T_in, H, W, C_in)\n",
    "        num_z_levels, b, seq_len, h, w, c_in = x_volumetric.shape\n",
    "        all_level_predictions = []\n",
    "\n",
    "        for z_idx in range(num_z_levels):\n",
    "            x_level = x_volumetric[z_idx, ...]  # (B, T_in, H, W, C_in)\n",
    "            x_level_permuted = x_level.permute(0, 1, 4, 2, 3)  # (B, T_in, C_in, H, W)\n",
    "            current_input = x_level_permuted\n",
    "\n",
    "            hidden_states_for_level = [None] * self.num_layers\n",
    "\n",
    "            for i in range(self.num_layers):\n",
    "                layer_output, hidden_state = self.layers[i](current_input, hidden_states_for_level[i])\n",
    "                hidden_states_for_level[i] = hidden_state\n",
    "\n",
    "                if self.use_layer_norm and self.layer_norms:\n",
    "                    B_ln, T_ln, C_ln, H_ln, W_ln = layer_output.shape\n",
    "                    output_reshaped_for_ln = layer_output.contiguous().view(B_ln * T_ln, C_ln, H_ln, W_ln)\n",
    "                    normalized_output = self.layer_norms[i](output_reshaped_for_ln)\n",
    "                    layer_output = normalized_output.view(B_ln, T_ln, C_ln, H_ln, W_ln)\n",
    "                current_input = layer_output\n",
    "\n",
    "            output_for_conv3d = current_input.permute(0, 2, 1, 3, 4)\n",
    "            raw_conv_output = self.output_conv(output_for_conv3d)\n",
    "            prediction_features = raw_conv_output.squeeze(2)\n",
    "            level_prediction = prediction_features.view(b, self.pred_steps, self.input_dim, h, w)\n",
    "            level_prediction = level_prediction.permute(0, 1, 3, 4, 2)\n",
    "            level_prediction = self.sigmoid(level_prediction)\n",
    "            all_level_predictions.append(level_prediction)\n",
    "\n",
    "        predictions_volumetric = torch.stack(all_level_predictions, dim=0)\n",
    "        return predictions_volumetric\n",
    "\n",
    "\n",
    "class SSIMLoss(nn.Module):\n",
    "    def __init__(self, data_range=1.0, kernel_size_for_metric=7):\n",
    "        super(SSIMLoss, self).__init__()\n",
    "        # No necesitas try-except aquí si estás usando una versión de torchmetrics que lo soporta\n",
    "        self.ssim_metric = torchmetrics.StructuralSimilarityIndexMeasure(\n",
    "            data_range=data_range,\n",
    "            kernel_size=kernel_size_for_metric,\n",
    "            reduction='elementwise_mean' # Común, o None y luego .mean()\n",
    "        ).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    def forward(self, img1, img2): # Espera (Z, B, T_pred, H, W, C)\n",
    "        num_z, batch_s, pred_t, height, width, channels = img1.shape\n",
    "\n",
    "        # SSIM se aplica típicamente a imágenes (o slices 2D/3D con un canal)\n",
    "        # Aplanar Z, B, T_pred en la dimensión de batch para SSIM\n",
    "        # Permutar para tener (Batch_flat, Canales, H, W)\n",
    "        img1_reshaped = img1.permute(0, 1, 2, 5, 3, 4).contiguous().view(-1, channels, height, width)\n",
    "        img2_reshaped = img2.permute(0, 1, 2, 5, 3, 4).contiguous().view(-1, channels, height, width)\n",
    "\n",
    "        ssim_val_elementwise = self.ssim_metric(img1_reshaped, img2_reshaped) # Esto dará un valor por imagen en el batch aplanado\n",
    "        ssim_val_mean = ssim_val_elementwise.mean() # Tomar la media sobre todos los elementos del batch aplanado\n",
    "        logging.info(f\"SSIM Mean: {ssim_val_mean.item():.4f}\")\n",
    "        return 1.0 - ssim_val_mean # Queremos maximizar SSIM, así que minimizamos 1-SSIM\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, config):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logging.info(f\"Usando dispositivo: {device}\")\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config.get('weight_decay', 1e-4))\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=config.get('lr_patience', 3), verbose=True)\n",
    "\n",
    "    criterion_mse = nn.MSELoss().to(device)\n",
    "    criterion_ssim = None\n",
    "    if config.get('use_ssim_loss', False):\n",
    "        criterion_ssim = SSIMLoss(data_range=1.0, kernel_size_for_metric=config.get('ssim_kernel_size', 7)).to(device)\n",
    "        ssim_loss_weight = config.get('ssim_loss_weight', 0.3)\n",
    "        mse_loss_weight = 1.0 - ssim_loss_weight\n",
    "        logging.info(f\"Usando SSIM loss con peso {ssim_loss_weight} y MSE con peso {mse_loss_weight}\")\n",
    "    else:\n",
    "        ssim_loss_weight = 0.0\n",
    "        mse_loss_weight = 1.0\n",
    "\n",
    "    scaler = torch.amp.GradScaler(enabled=config['use_amp'])\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses, val_losses = [], []\n",
    "    accumulation_steps = config.get('accumulation_steps', 1)\n",
    "\n",
    "    logging.info(f\"Iniciando entrenamiento: {config['epochs']} épocas, LR: {config['learning_rate']}, Batch (efectivo): {config['batch_size'] * accumulation_steps}\")\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        torch.cuda.empty_cache()\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            logging.info(f\"Inicio Época {epoch+1} - Memoria GPU Asignada: {torch.cuda.memory_allocated(device) / 1024**3:.2f} GB\")\n",
    "\n",
    "        for batch_idx, (x, y) in enumerate(train_loader):\n",
    "            x = x.to(device).permute(1, 0, 2, 3, 4, 5)\n",
    "            y = y.to(device).permute(1, 0, 2, 3, 4, 5)\n",
    "\n",
    "            with torch.amp.autocast(device_type=device.type, dtype=torch.float16, enabled=config['use_amp']):\n",
    "                predictions = model(x)\n",
    "\n",
    "                # Asegúrate que 'y' (objetivo) tenga la misma forma que 'predictions'\n",
    "                if predictions.shape != y.shape:\n",
    "                    logging.error(f\"Discrepancia de formas: Pred {predictions.shape}, Target {y.shape}\")\n",
    "                    continue\n",
    "\n",
    "                valid_mask = ~torch.isnan(y)\n",
    "                \n",
    "                loss_mse_val = criterion_mse(predictions[valid_mask], y[valid_mask])\n",
    "                current_loss = loss_mse_val\n",
    "\n",
    "                if criterion_ssim is not None:\n",
    "                    preds_for_ssim = torch.nan_to_num(predictions, nan=0.0)\n",
    "                    y_for_ssim = torch.nan_to_num(y, nan=0.0)\n",
    "                    loss_ssim_component = criterion_ssim(preds_for_ssim, y_for_ssim)\n",
    "                    current_loss = mse_loss_weight * loss_mse_val + ssim_loss_weight * loss_ssim_component\n",
    "                # <<< FIN DE LA CORRECCIÓN CRÍTICA >>>\n",
    "\n",
    "                loss_to_accumulate = current_loss / accumulation_steps\n",
    "\n",
    "            scaler.scale(loss_to_accumulate).backward()\n",
    "\n",
    "\n",
    "            if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                if config.get('clip_grad_norm', None):\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config['clip_grad_norm'])\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            running_train_loss += current_loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % config.get('log_interval', 1) == 0:\n",
    "                logging.info(f\"Época {epoch+1}/{config['epochs']} [{batch_idx+1}/{len(train_loader)}] - Pérdida (batch): {current_loss.item():.6f}\")\n",
    "\n",
    "        avg_train_loss = running_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Validación\n",
    "        if val_loader and len(val_loader) > 0:\n",
    "            model.eval()\n",
    "            running_val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for x_val, y_val in val_loader:\n",
    "                    x_val = x_val.to(device).permute(1, 0, 2, 3, 4, 5)\n",
    "                    y_val = y_val.to(device).permute(1, 0, 2, 3, 4, 5)\n",
    "\n",
    "                    with torch.amp.autocast(device_type=device.type, dtype=torch.float16, enabled=config['use_amp']):\n",
    "                        predictions_val = model(x_val)\n",
    "\n",
    "                        valid_mask_val = ~torch.isnan(y_val)\n",
    "                        \n",
    "                        val_loss_mse_val = criterion_mse(predictions_val[valid_mask_val], y_val[valid_mask_val])\n",
    "                        current_val_loss = val_loss_mse_val\n",
    "                        \n",
    "                        if criterion_ssim is not None:\n",
    "                            preds_val_for_ssim = torch.nan_to_num(predictions_val, nan=0.0)\n",
    "                            y_val_for_ssim = torch.nan_to_num(y_val, nan=0.0)\n",
    "                            val_loss_ssim_component = criterion_ssim(preds_val_for_ssim, y_val_for_ssim)\n",
    "                            current_val_loss = mse_loss_weight * val_loss_mse_val + ssim_loss_weight * val_loss_ssim_component\n",
    "                    running_val_loss += current_val_loss.item()\n",
    "\n",
    "\n",
    "            if len(val_loader) > 0:  # Evitar división por cero\n",
    "                avg_val_loss = running_val_loss / len(val_loader)\n",
    "                val_losses.append(avg_val_loss)\n",
    "                scheduler.step(avg_val_loss)\n",
    "                epoch_duration = time.time() - epoch_start_time\n",
    "                logging.info(f\"Época {epoch+1} completada en {epoch_duration:.2f}s. Pérdida (train): {avg_train_loss:.6f}, Pérdida (val): {avg_val_loss:.6f}\")\n",
    "\n",
    "                if avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    torch.save({'epoch': epoch + 1, 'model_state_dict': model.state_dict(),\n",
    "                                'optimizer_state_dict': optimizer.state_dict(), 'loss': best_val_loss},\n",
    "                               os.path.join(config['model_save_dir'], \"best_convlstm_model.pth\"))\n",
    "                    logging.info(f\"Mejor modelo guardado (Pérdida Val: {best_val_loss:.6f})\")\n",
    "            else:  # Si len(val_loader) es 0\n",
    "                epoch_duration = time.time() - epoch_start_time\n",
    "                logging.info(f\"Época {epoch+1} completada en {epoch_duration:.2f}s. Pérdida (train): {avg_train_loss:.6f} (Dataset de validación vacío, no se calculó pérdida de validación)\")\n",
    "        else:  # Si no hay val_loader\n",
    "            epoch_duration = time.time() - epoch_start_time\n",
    "            logging.info(f\"Época {epoch+1} completada en {epoch_duration:.2f}s. Pérdida (train): {avg_train_loss:.6f} (No hay val_loader)\")\n",
    "\n",
    "        # Guardar checkpoint de época\n",
    "        if (epoch + 1) % config.get('checkpoint_interval', 1) == 0:\n",
    "            torch.save({'epoch': epoch + 1, 'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(), 'train_losses': train_losses,\n",
    "                        'val_losses': val_losses if (val_loader and len(val_loader) > 0) else []},\n",
    "                       os.path.join(config['model_save_dir'], f\"checkpoint_epoch_{epoch+1}.pth\"))\n",
    "            logging.info(f\"Checkpoint guardado en la época {epoch+1}\")\n",
    "\n",
    "    logging.info(\"Entrenamiento finalizado.\")\n",
    "    if train_loader and len(train_losses) > 0:  # Solo plotear si hubo entrenamiento y pérdidas\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(train_losses, label='Pérdida Entrenamiento')\n",
    "        if val_loader and len(val_losses) > 0:\n",
    "            plt.plot(val_losses, label='Pérdida Validación')\n",
    "        plt.xlabel('Épocas')\n",
    "        plt.ylabel('Pérdida')\n",
    "        plt.legend()\n",
    "        plt.title('Curvas de Pérdida del Entrenamiento')\n",
    "        plt.savefig(os.path.join(config['model_save_dir'], \"loss_curves.png\"))\n",
    "        plt.close()\n",
    "        logging.info(f\"Curvas de pérdida guardadas en {os.path.join(config['model_save_dir'], 'loss_curves.png')}\")\n",
    "\n",
    "    return model, {'train_losses': train_losses, 'val_losses': val_losses}\n",
    "\n",
    "\n",
    "def generate_prediction_netcdf(model, data_loader, config, device, num_samples=1):\n",
    "    model.to(device).eval()\n",
    "    \n",
    "    output_dir = config['predictions_output_dir']\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # --- Parámetros de la Salida ---\n",
    "    # --- Parámetros de la Salida (leídos desde tu config) ---\n",
    "    min_dbz, max_dbz = config['min_dbz'], config['max_dbz']\n",
    "    scale_out = np.float32(config['output_nc_scale_factor'])\n",
    "    offset_out = np.float32(config['output_nc_add_offset'])\n",
    "    fill_byte_out = np.int8(config['output_nc_fill_value'])\n",
    "    fill_physical_out = (float(fill_byte_out) * scale_out) + offset_out\n",
    "\n",
    "    # --- Preparación de la Grilla (leído desde tu config) ---\n",
    "    num_z, num_y, num_x = config['expected_shape']\n",
    "    z_coords = np.arange(1.0, 1.0 + num_z * 1.0, 1.0, dtype=np.float32)\n",
    "    x_coords = np.arange(-249.5, -249.5 + num_x * 1.0, 1.0, dtype=np.float32)\n",
    "    y_coords = np.arange(-249.5, -249.5 + num_y * 1.0, 1.0, dtype=np.float32)\n",
    "    \n",
    "    # Pre-calcular grillas de lat/lon para los metadatos\n",
    "    proj = pyproj.Proj(proj=\"aeqd\", lon_0=config['sensor_longitude'], lat_0=config['sensor_latitude'], R=config['earth_radius_m'])\n",
    "    x_grid_m, y_grid_m = np.meshgrid(x_coords * 1000.0, y_coords * 1000.0)\n",
    "    lon0_grid, lat0_grid = proj(x_grid_m, y_grid_m, inverse=True)\n",
    "\n",
    "    sample_count = 0\n",
    "    with torch.no_grad():\n",
    "        # El DataLoader ahora debe devolver x, y, y el path del último input\n",
    "        for x_input_volume, _, last_input_filepath_batch in data_loader:\n",
    "            if sample_count >= num_samples: break\n",
    "            \n",
    "            x_to_model = x_input_volume[0:1].permute(1, 0, 2, 3, 4, 5).to(device)\n",
    "            last_input_filepath = last_input_filepath_batch[0]\n",
    "\n",
    "            with torch.amp.autocast(device_type=device.type, dtype=torch.float16, enabled=config['use_amp']):\n",
    "                predictions_norm = model(x_to_model)\n",
    "\n",
    "            # --- Bucle para iterar sobre cada uno de los 5 pasos de la predicción ---\n",
    "            for pred_step_idx in range(config['pred_len']):\n",
    "                \n",
    "                pred_norm_step = predictions_norm[:, 0, pred_step_idx, :, :, 0].cpu().numpy()\n",
    "\n",
    "                # --- Lógica de Desnormalización y Empaquetado ---\n",
    "                # --- Proceso de Desnormalización y Empaquetado ---\n",
    "                # 1. Desnormalizar a valores físicos (dBZ)\n",
    "                pred_physical_dbz_raw = pred_norm_step * (max_dbz - min_dbz) + min_dbz\n",
    "\n",
    "                # <<< LÍNEA DE SEGURIDAD CRÍTICA AÑADIDA >>>\n",
    "                pred_physical_dbz_clipped = np.clip(pred_physical_dbz_raw, min_dbz, max_dbz)\n",
    "                \n",
    "                # 2. Aplicar umbral físico: todo lo irrelevante se convierte en NaN\n",
    "                pred_physical_dbz_cleaned = pred_physical_dbz_clipped\n",
    "                pred_physical_dbz_cleaned[pred_physical_dbz_cleaned < config.get('MIN_RELEVANT_DBZ', 5.0)] = np.nan\n",
    "                \n",
    "                # 3. Preparar para empaquetado: Reemplazar NaNs con el valor físico de relleno\n",
    "                dbz_for_packing = np.where(np.isnan(pred_physical_dbz_cleaned), fill_physical_out, pred_physical_dbz_cleaned)\n",
    "                \n",
    "                # 4. Empaquetar a byte\n",
    "                dbz_packed_byte = np.round((dbz_for_packing - offset_out) / scale_out).astype(np.int8)\n",
    "                dbz_packed_byte[np.isclose(dbz_for_packing, fill_physical_out)] = fill_byte_out\n",
    "                dbz_final_packed = dbz_packed_byte[np.newaxis, ...]\n",
    "\n",
    "                # --- Cálculo de Timestamps para ESTE paso de predicción ---\n",
    "                try:\n",
    "                    parts = last_input_filepath.split('/')\n",
    "                    date_str, time_str = parts[-2][:8], os.path.splitext(parts[-1])[0]\n",
    "                    last_input_dt_utc = datetime.strptime(date_str + time_str, '%Y%m%d%H%M%S')\n",
    "                except Exception:\n",
    "                    last_input_dt_utc = datetime.utcnow()\n",
    "\n",
    "                lead_time_minutes = (pred_step_idx + 1) * config['prediction_interval_minutes']\n",
    "                forecast_dt_utc = last_input_dt_utc + timedelta(minutes=lead_time_minutes)\n",
    "                \n",
    "                # --- Escritura del Archivo NetCDF Completo para este paso ---\n",
    "                file_ts = forecast_dt_utc.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                output_filename = os.path.join(output_dir, f\"pred_t+{lead_time_minutes}min_{file_ts}_sample{sample_count}.nc\")\n",
    "\n",
    "                with NCDataset(output_filename, 'w', format='NETCDF3_CLASSIC') as ds_out:\n",
    "                        # <<< INICIO DE TU CÓDIGO DE ESCRITURA DETALLADO (ADAPTADO) >>>\n",
    "                        \n",
    "                        # --- Atributos Globales ---\n",
    "                        ds_out.Conventions = \"CF-1.6\"\n",
    "                        ds_out.title = f\"{config.get('radar_name', 'SAN_RAFAEL')} - Forecast t+{lead_time_minutes}min\"\n",
    "                        ds_out.institution = config.get('institution_name', \"UCAR\")\n",
    "                        ds_out.source = config.get('data_source_name', \"ConvLSTM Model Prediction\")\n",
    "                        ds_out.history = f\"Created {datetime.now(timezone.utc).isoformat()} by ConvLSTM prediction script.\"\n",
    "                        ds_out.comment = f\"Forecast data from model. Lead time: {lead_time_minutes} min.\"\n",
    "\n",
    "                        # --- Dimensiones ---\n",
    "                        ds_out.createDimension('time', None)\n",
    "                        ds_out.createDimension('bounds', 2)\n",
    "                        ds_out.createDimension('x0', num_x)\n",
    "                        ds_out.createDimension('y0', num_y)\n",
    "                        ds_out.createDimension('z0', num_z)\n",
    "\n",
    "                        # --- Variables de Tiempo ---\n",
    "                        time_value = (forecast_dt_utc.replace(tzinfo=None) - datetime(1970, 1, 1)).total_seconds()\n",
    "                        \n",
    "                        time_v = ds_out.createVariable('time', 'f8', ('time',))\n",
    "                        time_v.standard_name = \"time\"; time_v.long_name = \"Data time\"\n",
    "                        time_v.units = \"seconds since 1970-01-01T00:00:00Z\"; time_v.axis = \"T\"\n",
    "                        time_v.bounds = \"time_bounds\"; time_v.comment = forecast_dt_utc.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "                        time_v[:] = [time_value]\n",
    "\n",
    "                        # Puedes ajustar la lógica de start/stop time si lo necesitas, o simplificarla\n",
    "                        start_time_v = ds_out.createVariable('start_time', 'f8', ('time',))\n",
    "                        start_time_v[:] = [time_value - 180] # Ejemplo: 3 minutos antes\n",
    "                        stop_time_v = ds_out.createVariable('stop_time', 'f8', ('time',))\n",
    "                        stop_time_v[:] = [time_value]\n",
    "                        time_bnds_v = ds_out.createVariable('time_bounds', 'f8', ('time', 'bounds',))\n",
    "                        time_bnds_v[:] = [[time_value - 180, time_value]]\n",
    "\n",
    "                        # --- Variables de Coordenadas ---\n",
    "                        x_v = ds_out.createVariable('x0', 'f4', ('x0',)); x_v.setncatts({'standard_name':\"projection_x_coordinate\", 'units':\"km\", 'axis':\"X\"}); x_v[:] = x_coords\n",
    "                        y_v = ds_out.createVariable('y0', 'f4', ('y0',)); y_v.setncatts({'standard_name':\"projection_y_coordinate\", 'units':\"km\", 'axis':\"Y\"}); y_v[:] = y_coords\n",
    "                        z_v = ds_out.createVariable('z0', 'f4', ('z0',)); z_v.setncatts({'standard_name':\"altitude\", 'units':\"km\", 'axis':\"Z\", 'positive':\"up\"}); z_v[:] = z_coords\n",
    "                        \n",
    "                        # --- Variables de Georreferenciación ---\n",
    "                        lat0_v = ds_out.createVariable('lat0', 'f4', ('y0', 'x0',)); lat0_v.setncatts({'standard_name':\"latitude\", 'units':\"degrees_north\"}); lat0_v[:] = lat0_grid\n",
    "                        lon0_v = ds_out.createVariable('lon0', 'f4', ('y0', 'x0',)); lon0_v.setncatts({'standard_name':\"longitude\", 'units':\"degrees_east\"}); lon0_v[:] = lon0_grid\n",
    "                        \n",
    "                        gm_v = ds_out.createVariable('grid_mapping_0', 'i4'); gm_v.setncatts({'grid_mapping_name':\"azimuthal_equidistant\", 'longitude_of_projection_origin':config['sensor_longitude'], 'latitude_of_projection_origin':config['sensor_latitude'], 'false_easting':0.0, 'false_northing':0.0, 'earth_radius':config['earth_radius_m']})\n",
    "\n",
    "                        # --- Variable Principal DBZ ---\n",
    "                        dbz_v = ds_out.createVariable('DBZ', 'i1', ('time', 'z0', 'y0', 'x0'), fill_value=fill_byte_out)\n",
    "                        dbz_v.setncatts({'units':'dBZ', 'long_name':'DBZ', 'standard_name':'DBZ', 'coordinates':\"lon0 lat0\", 'grid_mapping':'grid_mapping_0', 'scale_factor':scale_out, 'add_offset':offset_out, 'valid_min':np.int8(-127), 'valid_max':np.int8(127), 'min_value':np.float32(min_dbz), 'max_value':np.float32(max_dbz)})\n",
    "                        dbz_v[:] = dbz_final_packed\n",
    "\n",
    "                logging.info(f\"Predicción t+{lead_time_minutes}min guardada en: {output_filename}\")\n",
    "\n",
    "            sample_count += 1\n",
    "\n",
    "\n",
    "def prepare_and_split_data(root_dir, train_ratio, total_seq_len, seq_stride=1):\n",
    "    \"\"\"\n",
    "    Escanea un directorio donde cada subdirectorio es un evento, ordena los\n",
    "    eventos cronológicamente, y genera secuencias de entrenamiento y validación.\n",
    "    \"\"\"\n",
    "    # 1. Encontrar todos los directorios de eventos\n",
    "    try:\n",
    "        all_event_dirs = sorted([\n",
    "            d for d in os.listdir(root_dir)\n",
    "            if os.path.isdir(os.path.join(root_dir, d)) and not d.startswith('.')\n",
    "        ])\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"El directorio del dataset no fue encontrado en: {root_dir}\")\n",
    "        return [], []\n",
    "\n",
    "    if not all_event_dirs:\n",
    "        logging.warning(f\"No se encontraron directorios de eventos en {root_dir}\")\n",
    "        return [], []\n",
    "\n",
    "    logging.info(f\"Encontrados {len(all_event_dirs)} directorios de eventos para procesar.\")\n",
    "\n",
    "    # 2. Dividir la LISTA DE DIRECTORIOS cronológicamente\n",
    "    split_idx = int(len(all_event_dirs) * train_ratio)\n",
    "    train_dirs = all_event_dirs[:split_idx]\n",
    "    val_dirs = all_event_dirs[split_idx:]\n",
    "    \n",
    "    logging.info(f\"División de eventos - Entrenamiento: {len(train_dirs)} directorios, Validación: {len(val_dirs)} directorios\")\n",
    "\n",
    "    def create_sliding_windows(event_dir_list, base_path):\n",
    "        \"\"\"Función interna para generar secuencias con ventanas deslizantes.\"\"\"\n",
    "        all_sequences = []\n",
    "        for event_dir in event_dir_list:\n",
    "            dir_path = os.path.join(base_path, event_dir)\n",
    "            files = sorted(glob.glob(os.path.join(dir_path, \"*.nc\")))\n",
    "            \n",
    "            if len(files) >= total_seq_len:\n",
    "                for i in range(0, len(files) - total_seq_len + 1, seq_stride):\n",
    "                    sequence = files[i : i + total_seq_len]\n",
    "                    all_sequences.append(sequence)\n",
    "        return all_sequences\n",
    "\n",
    "    # 3. Generar las listas de secuencias para cada conjunto\n",
    "    train_sequences = create_sliding_windows(train_dirs, root_dir)\n",
    "    val_sequences = create_sliding_windows(val_dirs, root_dir)\n",
    "\n",
    "    logging.info(f\"Generadas {len(train_sequences)} secuencias de entrenamiento y {len(val_sequences)} de validación.\")\n",
    "    \n",
    "    return train_sequences, val_sequences\n",
    "\n",
    "def main():\n",
    "    set_seed(42)\n",
    "    config = {\n",
    "        # --- Rutas y Configuración del Dataset ---\n",
    "        'dataset_dir': \"/home/sample\", # <<< ¡AJUSTA ESTA RUTA!\n",
    "        'model_save_dir': \"/home/model\",     # <<< ¡AJUSTA ESTA RUTA!\n",
    "        'predictions_output_dir': \"/home/predictions\", # <<< ¡AJUSTA ESTA RUTA!\n",
    "\n",
    "        # --- Parámetros de la Estrategia (12 -> 5) ---\n",
    "        'seq_len': 12,\n",
    "        'pred_len': 5,\n",
    "        'total_seq_len': 17,\n",
    "        'seq_stride': 1,\n",
    "\n",
    "        # --- Parámetros de División del Dataset ---\n",
    "        'train_val_split_ratio': 0.8,\n",
    "        'max_sequences_to_use': 10, # Perfecto para una prueba rápida\n",
    "\n",
    "        # --- Parámetros de Normalización y Físicos ---\n",
    "        'min_dbz': -29.0,\n",
    "        'max_dbz': 65.0,\n",
    "        'MIN_RELEVANT_DBZ': 5.0,\n",
    "        'expected_shape': (18, 500, 500),\n",
    "\n",
    "        # --- Parámetros de la Salida NetCDF (para compatibilidad con TITAN) ---\n",
    "        'output_nc_scale_factor': 0.5,\n",
    "        'output_nc_add_offset': 33.5,\n",
    "        'output_nc_fill_value': -128,\n",
    "\n",
    "        # --- Hiperparámetros del Modelo y Entrenamiento ---\n",
    "        # <<< INICIO DE LAS CLAVES FALTANTES >>>\n",
    "        'model_input_dim': 1,           # 1 canal de entrada (reflectividad)\n",
    "        'pred_steps_model': 5,          # El modelo debe saber que predice 5 pasos\n",
    "        'model_hidden_dims': [32, 32],  # Ejemplo: 2 capas de ConvLSTM\n",
    "        'model_kernel_sizes': [(3,3), (3,3)],\n",
    "        'model_num_layers': 2,\n",
    "        'model_use_layer_norm': True,\n",
    "        'model_use_residual': False,\n",
    "        # <<< FIN DE LAS CLAVES FALTANTES >>>\n",
    "        \n",
    "        'batch_size': 4,\n",
    "        'epochs': 5,\n",
    "        'learning_rate': 1e-4,\n",
    "        'use_amp': True,\n",
    "        'use_ssim_loss': False, # Empezar solo con MSE es más simple\n",
    "        'ssim_loss_weight': 0.5,\n",
    "        'ssim_kernel_size': 7,\n",
    "        'accumulation_steps': 1,\n",
    "        'clip_grad_norm': 1.0,\n",
    "        'log_interval': 10,\n",
    "        'checkpoint_interval': 1,\n",
    "        'lr_patience': 3,\n",
    "        'weight_decay': 1e-5,\n",
    "\n",
    "        # --- Otros parámetros para la generación de NetCDF ---\n",
    "        'sensor_latitude': -34.64799880981445,\n",
    "        'sensor_longitude': -68.01699829101562,\n",
    "        'earth_radius_m': 6378137.0,\n",
    "        'prediction_interval_minutes': 3\n",
    "    }\n",
    "\n",
    "    os.makedirs(config['model_save_dir'], exist_ok=True)\n",
    "    os.makedirs(config['predictions_output_dir'], exist_ok=True)\n",
    "\n",
    "    # 1. Usar nuestra nueva función para preparar los datos de forma robusta\n",
    "    train_seq_paths, val_seq_paths = prepare_and_split_data(\n",
    "        root_dir=config['dataset_dir'],\n",
    "        train_ratio=config['train_val_split_ratio'],\n",
    "        total_seq_len=config['total_seq_len'],\n",
    "        seq_stride=config.get('seq_stride', 1)\n",
    "    )\n",
    "\n",
    "    if not train_seq_paths and not val_seq_paths:\n",
    "        logging.error(\"No se generaron secuencias de entrenamiento ni de validación. Revisa la ruta del dataset y su contenido.\")\n",
    "        return\n",
    "        \n",
    "    # 2. Limitar el número de secuencias para una prueba rápida (si está configurado)\n",
    "    if config.get('max_sequences_to_use'):\n",
    "        logging.info(f\"Usando una muestra aleatoria de {config['max_sequences_to_use']} secuencias para esta ejecución.\")\n",
    "        # Mezclamos las listas para que la muestra sea variada\n",
    "        random.shuffle(train_seq_paths)\n",
    "        random.shuffle(val_seq_paths)\n",
    "        \n",
    "        num_train = int(config['max_sequences_to_use'] * config['train_val_split_ratio'])\n",
    "        num_val = config['max_sequences_to_use'] - num_train\n",
    "        \n",
    "        train_seq_paths = train_seq_paths[:num_train]\n",
    "        val_seq_paths = val_seq_paths[:num_val]\n",
    "        logging.info(f\"Muestra final -> Entrenamiento: {len(train_seq_paths)}, Validación: {len(val_seq_paths)}\")\n",
    "\n",
    "    # 3. Crear los Datasets y DataLoaders\n",
    "    # El constructor de RadarDataset ahora es mucho más simple, solo necesita la lista de secuencias\n",
    "    train_dataset = RadarDataset(train_seq_paths, seq_len=config['seq_len'], pred_len=config['pred_len'],\n",
    "                                 min_dbz_norm=config['min_dbz'], max_dbz_norm=config['max_dbz'])\n",
    "\n",
    "    val_dataset = RadarDataset(val_seq_paths, seq_len=config['seq_len'], pred_len=config['pred_len'],\n",
    "                               min_dbz_norm=config['min_dbz'], max_dbz_norm=config['max_dbz'])\n",
    "\n",
    "    # num_workers > 0 es ideal para acelerar la carga, pero puede dar problemas en algunos notebooks.\n",
    "    # Si tienes errores, prueba poniendo num_workers=0.\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    val_dataset_len = len(val_dataset) # Guardamos el largo para usarlo más adelante\n",
    "\n",
    "    # 4. Verificar que tenemos datos para continuar\n",
    "    if val_dataset_len == 0 and len(train_dataset) == 0:\n",
    "        logging.error(\"Los datasets de entrenamiento y validación están vacíos. No se puede continuar.\")\n",
    "        return\n",
    "\n",
    "    model = ConvLSTM3D_Enhanced(\n",
    "        input_dim=config['model_input_dim'], hidden_dims=config['model_hidden_dims'],\n",
    "        kernel_sizes=config['model_kernel_sizes'], num_layers=config['model_num_layers'],\n",
    "        pred_steps=config['pred_steps_model'], use_layer_norm=config['model_use_layer_norm'],\n",
    "        use_residual=config['model_use_residual'],\n",
    "        img_height=config['expected_shape'][1], img_width=config['expected_shape'][2]\n",
    "    )\n",
    "    model.float() # Asegurar que el modelo se inicialice en float32\n",
    "\n",
    "    logging.info(f\"Arquitectura del modelo:\\n{model}\")\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    logging.info(f\"Número total de parámetros entrenables: {total_params:,}\")\n",
    "\n",
    "    device_for_execution = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model_path = os.path.join(config['model_save_dir'], \"best_convlstm_model.pth\")\n",
    "    if os.path.exists(model_path):\n",
    "        logging.info(f\"Cargando modelo pre-entrenado desde: {model_path}\")\n",
    "        # Cargar a CPU, luego asegurar .float(), luego mover a device\n",
    "        checkpoint_data = torch.load(model_path, map_location='cpu', weights_only=True) #weights_only=True por seguridad\n",
    "        model.load_state_dict(checkpoint_data['model_state_dict'])\n",
    "        model.float() # Asegurar float32 después de cargar\n",
    "        logging.info(f\"Modelo cargado. Dtype parámetros: {next(model.parameters()).dtype}\")\n",
    "        trained_model = model\n",
    "    else:\n",
    "        logging.info(\"No se encontró modelo pre-entrenado. Entrenando desde cero...\")\n",
    "        if not train_loader:\n",
    "            logging.error(\"No hay datos de entrenamiento y no se encontró modelo pre-entrenado. Saliendo.\")\n",
    "            return\n",
    "        trained_model, history = train_model(model, train_loader, val_loader, config) # train_model se encarga de .to(device)\n",
    "\n",
    "    trained_model.to(device_for_execution) # Mover el modelo final al dispositivo\n",
    "    trained_model.float() # Re-asegurar float32 después de mover (por si acaso)\n",
    "    logging.info(f\"Modelo listo para predicción. Dtype: {next(trained_model.parameters()).dtype}, Dispositivo: {next(trained_model.parameters()).device}\")\n",
    "\n",
    "    # Priorizar val_loader para predicciones, si no, usar train_loader\n",
    "    prediction_loader = val_loader if val_loader and val_dataset_len > 0 else train_loader\n",
    "    num_prediction_samples = min(5, val_dataset_len if val_loader and val_dataset_len > 0 else (len(train_loader.dataset) if train_loader else 0))\n",
    "\n",
    "    if prediction_loader and num_prediction_samples > 0:\n",
    "        logging.info(\"Generando predicciones de ejemplo...\")\n",
    "        generate_prediction_netcdf(trained_model, prediction_loader, config,\n",
    "                                   device=device_for_execution,\n",
    "                                   num_samples=num_prediction_samples)\n",
    "    else:\n",
    "        logging.warning(\"No hay datos disponibles en val_loader o train_loader para generar predicciones de ejemplo.\")\n",
    "\n",
    "    logging.info(\"Proceso completado.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae001fd-5f38-499d-acdc-b5851649dbd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
