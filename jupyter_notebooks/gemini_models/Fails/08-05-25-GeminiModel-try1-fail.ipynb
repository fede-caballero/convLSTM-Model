{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a95315-21c1-41de-a409-09f3319d9b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting netCDF4\n",
      "  Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting cftime (from netCDF4)\n",
      "  Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from netCDF4) (2024.8.30)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from netCDF4) (2.1.2)\n",
      "Requirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (24.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (2.5.1+cu121)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.57.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.2.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (72.1.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
      "Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: pyparsing, lightning-utilities, kiwisolver, fonttools, cycler, contourpy, cftime, netCDF4, matplotlib, torchmetrics\n",
      "Successfully installed cftime-1.6.4.post1 contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 lightning-utilities-0.14.3 matplotlib-3.10.3 netCDF4-1.7.2 pyparsing-3.2.3 torchmetrics-1.7.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install netCDF4 torchmetrics matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec770cc-2e7d-4ca2-b908-7ee098a5b596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version PyTorch built with: 12.1\n",
      "Number of GPUs: 1\n",
      "GPU Name: NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version PyTorch built with: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da8c5fd3-2adb-477c-a88c-43534f9e647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 02:13:40,168 - INFO - Semillas configuradas con valor: 42\n",
      "2025-05-09 02:13:40,168 - INFO - Total secuencias a usar: 50.\n",
      "2025-05-09 02:13:40,169 - INFO - Entrenamiento: 40 secuencias. Validación: 10 secuencias.\n",
      "2025-05-09 02:13:40,170 - INFO - RadarDataset inicializado con 40 secuencias válidas.\n",
      "2025-05-09 02:13:40,171 - INFO - RadarDataset inicializado con 10 secuencias válidas.\n",
      "2025-05-09 02:13:40,196 - INFO - Modelo ConvLSTM3D_Enhanced creado: 3 capas, Hidden dims: [64, 128, 64], LayerNorm: True, Residual: False, PredSteps: 1\n",
      "2025-05-09 02:13:40,197 - INFO - Arquitectura del modelo:\n",
      "ConvLSTM3D_Enhanced(\n",
      "  (layers): ModuleList(\n",
      "    (0): ConvLSTM2DLayer(\n",
      "      (cell): ConvLSTMCell(\n",
      "        (conv): Conv2d(65, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): ConvLSTM2DLayer(\n",
      "      (cell): ConvLSTMCell(\n",
      "        (conv): Conv2d(192, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): ConvLSTM2DLayer(\n",
      "      (cell): ConvLSTMCell(\n",
      "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer_norms): ModuleList(\n",
      "    (0): LayerNorm((64, 500, 500), eps=1e-05, elementwise_affine=True)\n",
      "    (1): LayerNorm((128, 500, 500), eps=1e-05, elementwise_affine=True)\n",
      "    (2): LayerNorm((64, 500, 500), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (output_conv): Conv3d(64, 1, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      ")\n",
      "2025-05-09 02:13:40,197 - INFO - Número total de parámetros entrenables: 129,478,465\n",
      "2025-05-09 02:13:40,198 - INFO - Usando dispositivo: cuda\n",
      "2025-05-09 02:13:40,281 - INFO - Usando SSIM loss con peso 0.3 y MSE con peso 0.7\n",
      "/tmp/ipykernel_1162/3333953389.py:294: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=config['use_amp'])\n",
      "2025-05-09 02:13:40,281 - INFO - Iniciando entrenamiento: 3 épocas, LR: 0.0001, Batch (efectivo): 4\n",
      "2025-05-09 02:13:41,247 - INFO - Forma de entrada al modelo (primer batch): torch.Size([1, 18, 6, 500, 500, 1])\n",
      "2025-05-09 02:13:41,248 - INFO - Forma objetivo (primer batch): torch.Size([1, 18, 1, 500, 500, 1])\n",
      "/tmp/ipykernel_1162/3333953389.py:315: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=config['use_amp']):\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacity of 79.25 GiB of which 661.25 MiB is free. Including non-PyTorch memory, this process has 78.58 GiB memory in use. Of the allocated memory 75.66 GiB is allocated by PyTorch, and 2.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 631\u001b[0m\n\u001b[1;32m    628\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProceso completado.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 631\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 618\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    615\u001b[0m total_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    616\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNúmero total de parámetros entrenables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_params\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 618\u001b[0m trained_model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_loader:\n\u001b[1;32m    621\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerando predicciones de ejemplo usando el conjunto de validación...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 316\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, config)\u001b[0m\n\u001b[1;32m    313\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForma objetivo (primer batch): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(enabled\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_amp\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m--> 316\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     loss_mse_val \u001b[38;5;241m=\u001b[39m criterion_mse(predictions, y)\n\u001b[1;32m    318\u001b[0m     current_loss \u001b[38;5;241m=\u001b[39m loss_mse_val\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 222\u001b[0m, in \u001b[0;36mConvLSTM3D_Enhanced.forward\u001b[0;34m(self, x_volumetric)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_residual \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    220\u001b[0m     residual_input \u001b[38;5;241m=\u001b[39m current_input\n\u001b[0;32m--> 222\u001b[0m layer_output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_layer_norm \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norms:\n\u001b[1;32m    225\u001b[0m     B_ln, T_ln, C_ln, H_ln, W_ln \u001b[38;5;241m=\u001b[39m layer_output\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 166\u001b[0m, in \u001b[0;36mConvLSTM2DLayer.forward\u001b[0;34m(self, input_tensor, hidden_state)\u001b[0m\n\u001b[1;32m    164\u001b[0m h_cur, c_cur \u001b[38;5;241m=\u001b[39m hidden_state\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(seq_len):\n\u001b[0;32m--> 166\u001b[0m     h_cur, c_cur \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcell\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mh_cur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_cur\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     layer_output_list\u001b[38;5;241m.\u001b[39mappend(h_cur)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_all_layers:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 142\u001b[0m, in \u001b[0;36mConvLSTMCell.forward\u001b[0;34m(self, input_tensor, cur_state)\u001b[0m\n\u001b[1;32m    140\u001b[0m o \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(cc_o)\n\u001b[1;32m    141\u001b[0m g \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(cc_g)\n\u001b[0;32m--> 142\u001b[0m c_next \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc_cur\u001b[49m \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m*\u001b[39m g\n\u001b[1;32m    143\u001b[0m h_next \u001b[38;5;241m=\u001b[39m o \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(c_next)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m h_next, c_next\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacity of 79.25 GiB of which 661.25 MiB is free. Including non-PyTorch memory, this process has 78.58 GiB memory in use. Of the allocated memory 75.66 GiB is allocated by PyTorch, and 2.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta # Asegúrate de importar timedelta\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from netCDF4 import Dataset as NCDataset # Renombrar para evitar conflicto con la clase Dataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics # Para métricas adicionales como SSIM\n",
    "\n",
    "# Configuración del Logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Configuración para reproducibilidad y rendimiento\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Configura las semillas para reproducibilidad.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    logging.info(f\"Semillas configuradas con valor: {seed}\")\n",
    "\n",
    "class RadarDataset(Dataset):\n",
    "    def __init__(self, data_dir, subdirs_list, seq_len=6, pred_len=1,\n",
    "                 min_dbz=-30, max_dbz=70,\n",
    "                 expected_shape=(18, 500, 500), variable_name='DBZ'):\n",
    "        self.data_dir = data_dir\n",
    "        self.subdirs_list = subdirs_list\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.min_dbz = min_dbz\n",
    "        self.max_dbz = max_dbz\n",
    "        self.expected_z, self.expected_h, self.expected_w = expected_shape\n",
    "        self.variable_name = variable_name\n",
    "        self.valid_sequences = self._validate_subdirs()\n",
    "        if not self.valid_sequences:\n",
    "            logging.error(\"No se encontraron secuencias válidas. Verifica los datos y la estructura de carpetas.\")\n",
    "            raise ValueError(\"No se encontraron secuencias válidas.\")\n",
    "        logging.info(f\"RadarDataset inicializado con {len(self.valid_sequences)} secuencias válidas.\")\n",
    "\n",
    "    def _validate_subdirs(self):\n",
    "        valid_sequences = []\n",
    "        for subdir_name in self.subdirs_list:\n",
    "            subdir_path = os.path.join(self.data_dir, subdir_name)\n",
    "            if not os.path.isdir(subdir_path):\n",
    "                logging.warning(f\"Subdirectorio {subdir_name} no encontrado en {self.data_dir}. Omitiendo.\")\n",
    "                continue\n",
    "            # Ignorar carpetas de checkpoints de Jupyter\n",
    "            if \".ipynb_checkpoints\" in subdir_name:\n",
    "                logging.info(f\"Omitiendo directorio de checkpoints: {subdir_name}\")\n",
    "                continue\n",
    "            files = sorted(glob.glob(os.path.join(subdir_path, \"*.nc\")))\n",
    "            if len(files) >= self.seq_len + self.pred_len:\n",
    "                valid_sequences.append((files, subdir_name))\n",
    "            else:\n",
    "                logging.warning(f\"Subdirectorio {subdir_name} tiene {len(files)} archivos, necesita {self.seq_len + self.pred_len}. Omitiendo.\")\n",
    "        return valid_sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence_files, subdir_name = self.valid_sequences[idx]\n",
    "        input_data_list = []\n",
    "        output_data_list = []\n",
    "\n",
    "        for i in range(self.seq_len):\n",
    "            file_path = sequence_files[i]\n",
    "            try:\n",
    "                with NCDataset(file_path, 'r') as nc_file:\n",
    "                    dbz = nc_file.variables[self.variable_name][0, ...].astype(np.float32)\n",
    "                    if dbz.shape != (self.expected_z, self.expected_h, self.expected_w):\n",
    "                        logging.warning(f\"Forma inesperada {dbz.shape} en {file_path} para {subdir_name}. Omitiendo muestra.\")\n",
    "                        return self.__getitem__((idx + 1) % len(self))\n",
    "                    dbz = np.clip(dbz, self.min_dbz, self.max_dbz)\n",
    "                    dbz = (dbz - self.min_dbz) / (self.max_dbz - self.min_dbz)\n",
    "                    dbz = dbz[..., np.newaxis]\n",
    "                    input_data_list.append(dbz)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error cargando entrada {file_path} para {subdir_name}: {e}. Omitiendo muestra.\")\n",
    "                return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        for i in range(self.seq_len, self.seq_len + self.pred_len):\n",
    "            file_path = sequence_files[i]\n",
    "            try:\n",
    "                with NCDataset(file_path, 'r') as nc_file:\n",
    "                    dbz = nc_file.variables[self.variable_name][0, ...].astype(np.float32)\n",
    "                    if dbz.shape != (self.expected_z, self.expected_h, self.expected_w):\n",
    "                        logging.warning(f\"Forma inesperada {dbz.shape} en {file_path} para {subdir_name}. Omitiendo muestra.\")\n",
    "                        return self.__getitem__((idx + 1) % len(self))\n",
    "                    dbz = np.clip(dbz, self.min_dbz, self.max_dbz)\n",
    "                    dbz = (dbz - self.min_dbz) / (self.max_dbz - self.min_dbz)\n",
    "                    dbz = dbz[..., np.newaxis]\n",
    "                    output_data_list.append(dbz)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error cargando salida {file_path} para {subdir_name}: {e}. Omitiendo muestra.\")\n",
    "                return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        if len(input_data_list) != self.seq_len or len(output_data_list) != self.pred_len:\n",
    "            logging.warning(f\"No se pudieron cargar suficientes archivos para la secuencia {idx} en {subdir_name}. Omitiendo.\")\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        input_tensor = np.stack(input_data_list, axis=1)\n",
    "        output_tensor = np.stack(output_data_list, axis=1)\n",
    "        x = torch.from_numpy(input_tensor).float()\n",
    "        y = torch.from_numpy(output_tensor).float()\n",
    "        return x, y\n",
    "\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        return h_next, c_next\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
    "\n",
    "class ConvLSTM2DLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True, return_all_layers=False):\n",
    "        super(ConvLSTM2DLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "        self.cell = ConvLSTMCell(input_dim, hidden_dim, kernel_size, bias)\n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        b, seq_len, _, h, w = input_tensor.size()\n",
    "        if hidden_state is None:\n",
    "            hidden_state = self.cell.init_hidden(b, (h, w))\n",
    "        layer_output_list = []\n",
    "        h_cur, c_cur = hidden_state\n",
    "        for t in range(seq_len):\n",
    "            h_cur, c_cur = self.cell(input_tensor=input_tensor[:, t, :, :, :], cur_state=[h_cur, c_cur])\n",
    "            layer_output_list.append(h_cur)\n",
    "        if self.return_all_layers:\n",
    "            layer_output = torch.stack(layer_output_list, dim=1)\n",
    "        else:\n",
    "            layer_output = layer_output_list[-1].unsqueeze(1)\n",
    "        return layer_output, (h_cur, c_cur)\n",
    "\n",
    "class ConvLSTM3D_Enhanced(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dims=[32, 64], kernel_sizes=[(3,3), (3,3)],\n",
    "                 num_layers=2, pred_steps=1, use_layer_norm=True, use_residual=False,\n",
    "                 img_height=500, img_width=500):\n",
    "        super(ConvLSTM3D_Enhanced, self).__init__()\n",
    "        if isinstance(hidden_dims, int): hidden_dims = [hidden_dims] * num_layers\n",
    "        if isinstance(kernel_sizes, tuple): kernel_sizes = [kernel_sizes] * num_layers\n",
    "        assert len(hidden_dims) == num_layers and len(kernel_sizes) == num_layers\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.num_layers = num_layers\n",
    "        self.pred_steps = pred_steps\n",
    "        self.use_layer_norm = use_layer_norm\n",
    "        self.use_residual = use_residual\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layer_norms = nn.ModuleList() if use_layer_norm else None\n",
    "\n",
    "        current_dim = input_dim\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(\n",
    "                ConvLSTM2DLayer(input_dim=current_dim, hidden_dim=hidden_dims[i],\n",
    "                                kernel_size=kernel_sizes[i], bias=True, return_all_layers=True)\n",
    "            )\n",
    "            if use_layer_norm:\n",
    "                 self.layer_norms.append(nn.LayerNorm([hidden_dims[i], img_height, img_width]))\n",
    "            current_dim = hidden_dims[i]\n",
    "\n",
    "        self.output_conv = nn.Conv3d(in_channels=hidden_dims[-1],\n",
    "                                     out_channels=input_dim * pred_steps,\n",
    "                                     kernel_size=(1, 3, 3), padding=(0, 1, 1))\n",
    "        logging.info(f\"Modelo ConvLSTM3D_Enhanced creado: {num_layers} capas, Hidden dims: {hidden_dims}, LayerNorm: {use_layer_norm}, Residual: {use_residual}, PredSteps: {pred_steps}\")\n",
    "\n",
    "    def forward(self, x_volumetric):\n",
    "        num_z_levels, b, seq_len, h, w, c_in = x_volumetric.shape\n",
    "        all_level_predictions = []\n",
    "\n",
    "        for z_idx in range(num_z_levels):\n",
    "            x_level = x_volumetric[z_idx, ...]\n",
    "            x_level_permuted = x_level.permute(0, 1, 4, 2, 3)\n",
    "            current_input = x_level_permuted\n",
    "            residual_input = None\n",
    "\n",
    "            for i in range(self.num_layers):\n",
    "                if self.use_residual and i > 0:\n",
    "                    residual_input = current_input\n",
    "\n",
    "                layer_output, _ = self.layers[i](current_input)\n",
    "\n",
    "                if self.use_layer_norm and self.layer_norms:\n",
    "                    B_ln, T_ln, C_ln, H_ln, W_ln = layer_output.shape\n",
    "                    output_reshaped_for_ln = layer_output.contiguous().view(B_ln * T_ln, C_ln, H_ln, W_ln)\n",
    "                    normalized_output = self.layer_norms[i](output_reshaped_for_ln)\n",
    "                    layer_output = normalized_output.view(B_ln, T_ln, C_ln, H_ln, W_ln)\n",
    "\n",
    "                if self.use_residual and residual_input is not None:\n",
    "                    if residual_input.shape[2] == layer_output.shape[2]:\n",
    "                        layer_output = layer_output + residual_input\n",
    "                current_input = layer_output\n",
    "\n",
    "            output_for_conv3d = current_input.permute(0, 2, 1, 3, 4)\n",
    "            level_prediction = self.output_conv(output_for_conv3d)\n",
    "            level_prediction = level_prediction.view(b, self.pred_steps, self.input_dim, h, w)\n",
    "            level_prediction = level_prediction.permute(0, 1, 3, 4, 2)\n",
    "            all_level_predictions.append(level_prediction)\n",
    "\n",
    "        predictions_volumetric = torch.stack(all_level_predictions, dim=0)\n",
    "        return predictions_volumetric\n",
    "\n",
    "class SSIMLoss(nn.Module):\n",
    "    def __init__(self, data_range=1.0, kernel_size_for_metric=7): # Usar kernel_size_for_metric\n",
    "        super(SSIMLoss, self).__init__()\n",
    "        self.ssim_metric = torchmetrics.StructuralSimilarityIndexMeasure(\n",
    "            data_range=data_range, \n",
    "            kernel_size=kernel_size_for_metric, # Pasar como kernel_size\n",
    "            reduction='elementwise_mean' \n",
    "            # Asegúrate que tu versión de torchmetrics use 'reduction'. Si no, quítalo y calcula la media manualmente.\n",
    "        ).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        num_z, batch_s, pred_t, height, width, channels = img1.shape\n",
    "        if pred_t != 1 or channels != 1:\n",
    "            logging.debug(f\"SSIMLoss: T_pred={pred_t}, channels={channels}. Se aplanarán estas dimensiones para SSIM.\")\n",
    "        \n",
    "        img1_reshaped = img1.permute(0, 1, 2, 5, 3, 4).contiguous().view(-1, channels, height, width)\n",
    "        img2_reshaped = img2.permute(0, 1, 2, 5, 3, 4).contiguous().view(-1, channels, height, width)\n",
    "        \n",
    "        ssim_val = self.ssim_metric(img1_reshaped, img2_reshaped)\n",
    "        return 1.0 - ssim_val\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, config):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logging.info(f\"Usando dispositivo: {device}\")\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config.get('weight_decay', 1e-5))\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=config.get('lr_patience', 3), verbose=True)\n",
    "    \n",
    "    criterion_mse = nn.MSELoss().to(device)\n",
    "    criterion_ssim = None\n",
    "    ssim_loss_weight = 0.0\n",
    "    mse_loss_weight = 1.0\n",
    "\n",
    "    if config.get('use_ssim_loss', False):\n",
    "        try:\n",
    "            criterion_ssim = SSIMLoss(\n",
    "                data_range=1.0, \n",
    "                kernel_size_for_metric=config.get('ssim_kernel_size', 7) # Usar el nuevo nombre del config\n",
    "            ).to(device)\n",
    "            ssim_loss_weight = config.get('ssim_loss_weight', 0.3)\n",
    "            mse_loss_weight = 1.0 - ssim_loss_weight\n",
    "            logging.info(f\"Usando SSIM loss con peso {ssim_loss_weight} y MSE con peso {mse_loss_weight}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al inicializar SSIMLoss: {e}. Se usará solo MSE.\")\n",
    "            criterion_ssim = None # Asegurar que quede None si falla\n",
    "            ssim_loss_weight = 0.0\n",
    "            mse_loss_weight = 1.0\n",
    "\n",
    "    scaler = GradScaler(enabled=config['use_amp'])\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses, val_losses = [], []\n",
    "    accumulation_steps = config.get('accumulation_steps', 1)\n",
    "\n",
    "    logging.info(f\"Iniciando entrenamiento: {config['epochs']} épocas, LR: {config['learning_rate']}, Batch (efectivo): {config['batch_size'] * accumulation_steps}\")\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for batch_idx, (x, y) in enumerate(train_loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            if batch_idx == 0 and epoch == 0:\n",
    "                logging.info(f\"Forma de entrada al modelo (primer batch): {x.shape}\")\n",
    "                logging.info(f\"Forma objetivo (primer batch): {y.shape}\")\n",
    "\n",
    "            with autocast(enabled=config['use_amp']):\n",
    "                predictions = model(x)\n",
    "                loss_mse_val = criterion_mse(predictions, y)\n",
    "                current_loss = loss_mse_val\n",
    "\n",
    "                if criterion_ssim is not None:\n",
    "                    loss_ssim_component = criterion_ssim(predictions, y)\n",
    "                    current_loss = mse_loss_weight * loss_mse_val + ssim_loss_weight * loss_ssim_component\n",
    "                \n",
    "                loss = current_loss / accumulation_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                if config.get('clip_grad_norm', None):\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config['clip_grad_norm'])\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            running_train_loss += loss.item() * accumulation_steps\n",
    "            if (batch_idx + 1) % config.get('log_interval', 20) == 0:\n",
    "                logging.info(f\"Época {epoch+1}/{config['epochs']} [{batch_idx+1}/{len(train_loader)}] - Pérdida: {loss.item() * accumulation_steps:.6f}\")\n",
    "        \n",
    "        avg_train_loss = running_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        if val_loader: # Solo validar si val_loader existe\n",
    "            model.eval()\n",
    "            running_val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for x_val, y_val in val_loader:\n",
    "                    x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "                    with autocast(enabled=config['use_amp']):\n",
    "                        predictions_val = model(x_val)\n",
    "                        val_loss_mse_val = criterion_mse(predictions_val, y_val)\n",
    "                        current_val_loss = val_loss_mse_val\n",
    "                        if criterion_ssim is not None:\n",
    "                            val_loss_ssim_component = criterion_ssim(predictions_val, y_val)\n",
    "                            current_val_loss = mse_loss_weight * val_loss_mse_val + ssim_loss_weight * val_loss_ssim_component\n",
    "                    running_val_loss += current_val_loss.item()\n",
    "            \n",
    "            avg_val_loss = running_val_loss / len(val_loader)\n",
    "            val_losses.append(avg_val_loss)\n",
    "            scheduler.step(avg_val_loss)\n",
    "            epoch_duration = time.time() - epoch_start_time\n",
    "            logging.info(f\"Época {epoch+1} completada en {epoch_duration:.2f}s. Pérdida (train): {avg_train_loss:.6f}, Pérdida (val): {avg_val_loss:.6f}\")\n",
    "\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save({'epoch': epoch + 1, 'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(), 'loss': best_val_loss},\n",
    "                           os.path.join(config['model_save_dir'], \"best_convlstm_model.pth\"))\n",
    "                logging.info(f\"Mejor modelo guardado (Pérdida Val: {best_val_loss:.6f})\")\n",
    "        else: # Si no hay val_loader\n",
    "            epoch_duration = time.time() - epoch_start_time\n",
    "            logging.info(f\"Época {epoch+1} completada en {epoch_duration:.2f}s. Pérdida (train): {avg_train_loss:.6f} (No hay datos de validación)\")\n",
    "\n",
    "\n",
    "        if (epoch + 1) % config.get('checkpoint_interval', 5) == 0:\n",
    "            torch.save({'epoch': epoch + 1, 'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(), 'train_losses': train_losses,\n",
    "                        'val_losses': val_losses if val_loader else []}, # Guardar lista vacía si no hay val_losses\n",
    "                       os.path.join(config['model_save_dir'], f\"checkpoint_epoch_{epoch+1}.pth\"))\n",
    "            logging.info(f\"Checkpoint guardado en la época {epoch+1}\")\n",
    "\n",
    "    logging.info(\"Entrenamiento finalizado.\")\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(train_losses, label='Pérdida Entrenamiento')\n",
    "    if val_loader: # Solo plotear si hay datos de validación\n",
    "        plt.plot(val_losses, label='Pérdida Validación')\n",
    "    plt.xlabel('Épocas'); plt.ylabel('Pérdida'); plt.legend()\n",
    "    plt.savefig(os.path.join(config['model_save_dir'], \"loss_curves.png\")); plt.close()\n",
    "    return model, {'train_losses': train_losses, 'val_losses': val_losses if val_loader else []}\n",
    "\n",
    "\n",
    "def generate_prediction_netcdf(model, data_loader, config, device, num_samples=1):\n",
    "    output_dir = config['predictions_output_dir']\n",
    "    min_dbz = config['min_dbz']\n",
    "    max_dbz = config['max_dbz']\n",
    "    variable_name = config.get('dbz_variable_name_pred', 'DBZ_predicted')\n",
    "\n",
    "    sensor_latitude = config.get('sensor_latitude', -34.64799880981445)\n",
    "    sensor_longitude = config.get('sensor_longitude', -68.01699829101562)\n",
    "    sensor_altitude_km = config.get('sensor_altitude_km', 0.550000011920929)\n",
    "    grid_minz_km = config.get('grid_minz_km', 1.0)\n",
    "    grid_dz_km = config.get('grid_dz_km', 0.5)\n",
    "    grid_minx_km = config.get('grid_minx_km', -249.75)\n",
    "    grid_dx_km = config.get('grid_dx_km', 0.5)\n",
    "    grid_miny_km = config.get('grid_miny_km', -249.75)\n",
    "    grid_dy_km = config.get('grid_dy_km', 0.5)\n",
    "    radar_name = config.get('radar_name', \"La Llave\")\n",
    "    institution_name = config.get('institution_name', \"Tu Institucion/Universidad\")\n",
    "    data_source_name = config.get('data_source_name', \"Gobierno de Mendoza\")\n",
    "    projection_var_name_in_file = config.get('projection_variable_name', \"radar_projection_info\")\n",
    "\n",
    "    model.eval()\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    num_z_output = config['expected_shape'][0]\n",
    "    height = config['expected_shape'][1]\n",
    "    width = config['expected_shape'][2]\n",
    "\n",
    "    z_coord_values = np.arange(grid_minz_km, grid_minz_km + num_z_output * grid_dz_km, grid_dz_km)[:num_z_output]\n",
    "    x_coord_values = np.arange(grid_minx_km, grid_minx_km + width * grid_dx_km, grid_dx_km)[:width]\n",
    "    y_coord_values = np.arange(grid_miny_km, grid_miny_km + height * grid_dy_km, grid_dy_km)[:height]\n",
    "    \n",
    "    base_dt_for_samples = datetime.utcnow() # Placeholder - ¡DEBES MEJORAR ESTO!\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (x_input_volume, y_true_volume) in enumerate(data_loader):\n",
    "            if i >= num_samples: break\n",
    "\n",
    "            current_pred_datetime = base_dt_for_samples + timedelta(minutes=i * config.get('prediction_interval_minutes', 5))\n",
    "            x_to_model = x_input_volume.to(device)\n",
    "\n",
    "            with autocast(enabled=config['use_amp']):\n",
    "                prediction_norm = model(x_to_model)\n",
    "\n",
    "            pred_data_np = prediction_norm.squeeze(1).squeeze(1).squeeze(-1).cpu().numpy()\n",
    "            pred_data_desnorm = pred_data_np * (max_dbz - min_dbz) + min_dbz\n",
    "            pred_data_final_for_nc = np.expand_dims(pred_data_desnorm, axis=0)\n",
    "\n",
    "            file_timestamp_str = current_pred_datetime.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_filename = os.path.join(output_dir, f\"pred_{variable_name}_{file_timestamp_str}_sample{i}.nc\")\n",
    "\n",
    "            with NCDataset(output_filename, 'w', format='NETCDF4') as ncfile:\n",
    "                ncfile.Conventions = \"CF-1.7\"\n",
    "                ncfile.title = f\"Radar Reflectivity Forecast ({variable_name}) from ConvLSTM Model\"\n",
    "                ncfile.institution = institution_name\n",
    "                ncfile.source_data_description = f\"Based on input data from {data_source_name}, Radar: {radar_name}.\"\n",
    "                ncfile.source_model_description = \"ConvLSTM neural network prediction.\"\n",
    "                ncfile.history = f\"Created {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')} by prediction script.\"\n",
    "                ncfile.comment = \"Model-generated forecast. Not for operational use without verification.\"\n",
    "                ncfile.radar_name = radar_name\n",
    "                ncfile.sensor_latitude = sensor_latitude\n",
    "                ncfile.sensor_longitude = sensor_longitude\n",
    "                ncfile.sensor_altitude = sensor_altitude_km\n",
    "                ncfile.references = f\"Tesis de {config.get('author_name', '[Tu Nombre]')}, {config.get('author_institution', '[Tu Universidad/Institucion]')}\"\n",
    "\n",
    "\n",
    "                ncfile.createDimension('time', 1)\n",
    "                ncfile.createDimension('level', num_z_output)\n",
    "                ncfile.createDimension('y', height)\n",
    "                ncfile.createDimension('x', width)\n",
    "\n",
    "                time_var = ncfile.createVariable('time', 'f8', ('time',))\n",
    "                epoch_time = datetime(1970, 1, 1, 0, 0, 0)\n",
    "                time_value_seconds = (current_pred_datetime.replace(tzinfo=None) - epoch_time).total_seconds()\n",
    "                time_var[:] = [time_value_seconds]\n",
    "                time_var.units = \"seconds since 1970-01-01 00:00:00 UTC\"\n",
    "                time_var.calendar = \"gregorian\"\n",
    "                time_var.long_name = \"time of forecast\"; time_var.standard_name = \"time\"; time_var.axis = \"T\"\n",
    "\n",
    "                z_coord = ncfile.createVariable('level', 'f4', ('level',))\n",
    "                z_coord[:] = z_coord_values\n",
    "                z_coord.units = \"km\"; z_coord.positive = \"up\"; z_coord.long_name = \"altitude\"; z_coord.standard_name = \"altitude\"; z_coord.axis = \"Z\"\n",
    "\n",
    "                x_coord = ncfile.createVariable('x', 'f4', ('x',))\n",
    "                x_coord[:] = x_coord_values\n",
    "                x_coord.units = \"km\"; x_coord.long_name = \"projection_x_coordinate\"; x_coord.standard_name = \"projection_x_coordinate\"; x_coord.axis = \"X\"\n",
    "\n",
    "                y_coord = ncfile.createVariable('y', 'f4', ('y',))\n",
    "                y_coord[:] = y_coord_values\n",
    "                y_coord.units = \"km\"; y_coord.long_name = \"projection_y_coordinate\"; y_coord.standard_name = \"projection_y_coordinate\"; y_coord.axis = \"Y\"\n",
    "                \n",
    "                projection_var = ncfile.createVariable(projection_var_name_in_file, 'i4')\n",
    "                projection_var.grid_mapping_name = \"lambert_azimuthal_equal_area\"\n",
    "                projection_var.longitude_of_projection_origin = sensor_longitude\n",
    "                projection_var.latitude_of_projection_origin = sensor_latitude\n",
    "                projection_var.false_easting = 0.0\n",
    "                projection_var.false_northing = 0.0\n",
    "                # Add Earth model parameters if needed by RadxConvert for this projection\n",
    "                # projection_var.semi_major_axis = 6378137.0 \n",
    "                # projection_var.inverse_flattening = 298.257223563\n",
    "\n",
    "                pred_dbz_var = ncfile.createVariable(variable_name, 'f4', ('time', 'level', 'y', 'x'),\n",
    "                                                 fill_value=np.float32(config.get('fill_value', -9999.0)))\n",
    "                pred_dbz_var.units = 'dBZ'\n",
    "                pred_dbz_var.long_name = 'Predicted Radar Reflectivity'\n",
    "                pred_dbz_var.coordinates = \"time level y x\" \n",
    "                pred_dbz_var.grid_mapping = projection_var_name_in_file\n",
    "                pred_dbz_var[:] = pred_data_final_for_nc\n",
    "\n",
    "            logging.info(f\"Predicción de muestra con metadatos CF guardada en: {output_filename}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    set_seed(42)\n",
    "    config = {\n",
    "        'data_dir': \"/home/first_try_nc\", # O \"/root/gdrive_mount/ruta_a_netCDF_en_drive\"\n",
    "        'model_save_dir': \"/home/model_output_enhanced_v3\", # Nueva version para no sobreescribir\n",
    "        'predictions_output_dir': \"/home/predictions_enhanced_v3\",\n",
    "        'seq_len': 6, 'pred_len': 1, 'pred_steps_model': 1,\n",
    "        'min_dbz': -30.0, 'max_dbz': 70.0, 'fill_value': -9999.0,\n",
    "        'expected_shape': (18, 500, 500),\n",
    "        'dbz_variable_name': 'DBZ',\n",
    "        'dbz_variable_name_pred': 'DBZ_forecast',\n",
    "\n",
    "        'sensor_latitude': -34.64799880981445,\n",
    "        'sensor_longitude': -68.01699829101562,\n",
    "        'sensor_altitude_km': 0.550000011920929,\n",
    "        'grid_minz_km': 1.0, 'grid_dz_km': 0.5,\n",
    "        'grid_minx_km': -249.75, 'grid_dx_km': 0.5,\n",
    "        'grid_miny_km': -249.75, 'grid_dy_km': 0.5,\n",
    "        'radar_name': \"La Llave\",\n",
    "        'institution_name': \"Universidad de Mendoza - Federico Caballero\", # ¡Actualiza esto!\n",
    "        'author_name': \"Federico Caballero\", # Para el atributo 'references'\n",
    "        'author_institution': \"Universidad de Mendoza\", # Para el atributo 'references'\n",
    "        'data_source_name': \"Gobierno de Mendoza\",\n",
    "        'projection_variable_name': \"lambert_azimuthal_projection\",\n",
    "        'prediction_interval_minutes': 5,\n",
    "\n",
    "        'model_input_dim': 1,\n",
    "        'model_hidden_dims': [32, 64, 32],\n",
    "        'model_kernel_sizes': [(3,3), (3,3), (3,3)],\n",
    "        'model_num_layers': 3,\n",
    "        'model_use_layer_norm': True,\n",
    "        'model_use_residual': False,\n",
    "\n",
    "        'batch_size': 1,\n",
    "        'epochs': 3, # Reducido para una prueba rápida inicial con el cambio de SSIM\n",
    "        'learning_rate': 1e-4,\n",
    "        'weight_decay': 1e-5,\n",
    "        'lr_patience': 7,\n",
    "        'use_amp': True,\n",
    "        'accumulation_steps': 4,\n",
    "        'clip_grad_norm': 1.0,\n",
    "        'log_interval': 5, # Reducido para ver logs más rápido en prueba corta\n",
    "        'checkpoint_interval': 1, # Guardar checkpoint más frecuente en prueba corta\n",
    "\n",
    "        'use_ssim_loss': True,\n",
    "        'ssim_kernel_size': 7, # Cambiado de ssim_win_size a ssim_kernel_size\n",
    "        'ssim_loss_weight': 0.3,\n",
    "\n",
    "        'train_val_split_ratio': 0.8,\n",
    "        'max_sequences_to_use': 20, # Reducido para prueba rápida\n",
    "    }\n",
    "\n",
    "    os.makedirs(config['model_save_dir'], exist_ok=True)\n",
    "    os.makedirs(config['predictions_output_dir'], exist_ok=True)\n",
    "\n",
    "    all_subdirs_available = sorted([\n",
    "        d for d in os.listdir(config['data_dir']) \n",
    "        if os.path.isdir(os.path.join(config['data_dir'], d)) and not d.startswith('.') # Excluir .ipynb_checkpoints\n",
    "    ])\n",
    "    if not all_subdirs_available: logging.error(f\"No subdirs in {config['data_dir']}\"); return\n",
    "\n",
    "    if config['max_sequences_to_use'] and config['max_sequences_to_use'] < len(all_subdirs_available):\n",
    "        logging.info(f\"Usando muestra aleatoria de {config['max_sequences_to_use']} secuencias.\")\n",
    "        random.shuffle(all_subdirs_available)\n",
    "        subdirs_to_use = all_subdirs_available[:config['max_sequences_to_use']]\n",
    "    else:\n",
    "        subdirs_to_use = all_subdirs_available\n",
    "    logging.info(f\"Total secuencias a usar: {len(subdirs_to_use)}.\")\n",
    "    if not subdirs_to_use : logging.error(\"No hay secuencias para procesar después del filtrado/muestreo.\"); return\n",
    "\n",
    "\n",
    "    split_idx = int(len(subdirs_to_use) * config['train_val_split_ratio'])\n",
    "    train_subdirs, val_subdirs = subdirs_to_use[:split_idx], subdirs_to_use[split_idx:]\n",
    "    \n",
    "    # Asegurarse que haya datos para entrenamiento y opcionalmente para validación\n",
    "    if not train_subdirs:\n",
    "        logging.error(\"No hay secuencias de entrenamiento después de la división. Revisa max_sequences_to_use y train_val_split_ratio.\")\n",
    "        return\n",
    "    logging.info(f\"Entrenamiento: {len(train_subdirs)} secuencias. Validación: {len(val_subdirs)} secuencias.\")\n",
    "\n",
    "\n",
    "    train_dataset = RadarDataset(config['data_dir'], train_subdirs, seq_len=config['seq_len'], pred_len=config['pred_len'],\n",
    "                                 min_dbz=config['min_dbz'], max_dbz=config['max_dbz'],\n",
    "                                 expected_shape=config['expected_shape'], variable_name=config['dbz_variable_name'])\n",
    "    \n",
    "    val_loader = None\n",
    "    if val_subdirs:\n",
    "        val_dataset = RadarDataset(config['data_dir'], val_subdirs, seq_len=config['seq_len'], pred_len=config['pred_len'],\n",
    "                                   min_dbz=config['min_dbz'], max_dbz=config['max_dbz'],\n",
    "                                   expected_shape=config['expected_shape'], variable_name=config['dbz_variable_name'])\n",
    "        if len(val_dataset) > 0:\n",
    "             val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=2, pin_memory=True, prefetch_factor=2 if config.get('batch_size',1) > 1 else None)\n",
    "        else:\n",
    "            logging.info(\"El dataset de validación está vacío después de la inicialización (puede ser por no haber secuencias válidas).\")\n",
    "    else:\n",
    "        logging.info(\"No se han especificado subdirectorios para validación.\")\n",
    "\n",
    "\n",
    "    if len(train_dataset) == 0:\n",
    "        logging.error(\"Dataset de entrenamiento vacío. Revisa la carga de datos y el split.\"); return\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=2, pin_memory=True, prefetch_factor=2 if config.get('batch_size',1) > 1 else None)\n",
    "    \n",
    "    model = ConvLSTM3D_Enhanced(\n",
    "        input_dim=config['model_input_dim'], hidden_dims=config['model_hidden_dims'],\n",
    "        kernel_sizes=config['model_kernel_sizes'], num_layers=config['model_num_layers'],\n",
    "        pred_steps=config['pred_steps_model'], use_layer_norm=config['model_use_layer_norm'],\n",
    "        use_residual=config['model_use_residual'],\n",
    "        img_height=config['expected_shape'][1], img_width=config['expected_shape'][2]\n",
    "    )\n",
    "    logging.info(f\"Arquitectura del modelo:\\n{model}\")\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    logging.info(f\"Número total de parámetros entrenables: {total_params:,}\")\n",
    "\n",
    "    trained_model, history = train_model(model, train_loader, val_loader, config)\n",
    "\n",
    "    if val_loader:\n",
    "        logging.info(\"Generando predicciones de ejemplo usando el conjunto de validación...\")\n",
    "        generate_prediction_netcdf(trained_model, val_loader, config,\n",
    "                                   device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "                                   num_samples=min(5, len(val_dataset) if val_dataset else 0))\n",
    "    else:\n",
    "        logging.info(\"No hay datos de validación (val_loader es None), se omiten las predicciones de ejemplo.\")\n",
    "\n",
    "    logging.info(\"Proceso completado.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec8c64-b9ab-4b1a-a742-d0bca5569527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
