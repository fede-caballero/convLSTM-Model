{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6399b35-6488-4a16-92d6-d7d9acfe944d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTORCH_CUDA_ALLOC_CONF set to: expandable_segments:True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "print(f\"PYTORCH_CUDA_ALLOC_CONF set to: {os.environ.get('PYTORCH_CUDA_ALLOC_CONF')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a95315-21c1-41de-a409-09f3319d9b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: netCDF4 in /opt/conda/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.11/site-packages (1.7.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.10.3)\n",
      "Requirement already satisfied: cftime in /opt/conda/lib/python3.11/site-packages (from netCDF4) (1.6.4.post1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from netCDF4) (2024.8.30)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from netCDF4) (2.1.2)\n",
      "Requirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (24.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (2.5.1+cu121)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (0.14.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (72.1.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install netCDF4 torchmetrics matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec770cc-2e7d-4ca2-b908-7ee098a5b596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version PyTorch built with: 12.1\n",
      "Number of GPUs: 1\n",
      "GPU Name: NVIDIA A800 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version PyTorch built with: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb893018-e461-4170-bd08-9cefba404415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El directorio '/home/Big-Sample-Livianos-757-carpetas' contiene 751 subcarpetas (directorios).\n",
      "\n",
      "Algunas de las subcarpetas encontradas:\n",
      "- 2015110818\n",
      "- 2017032935\n",
      "- .ipynb_checkpoints\n",
      "- 2017022432\n",
      "- 2018022325\n",
      "- 2020020310\n",
      "- 2015122110\n",
      "- 2018122719\n",
      "- 2016021032\n",
      "- 2017022514\n",
      "... y 741 más.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# El path base que quieres inspeccionar\n",
    "base_path = \"/home/Big-Sample-Livianos-757-carpetas\" # O \"/home/f-caballero/ruta/completa/Big-Sample-Livianos-757-carpetas\"\n",
    "\n",
    "# Verificar si el path base existe\n",
    "if not os.path.exists(base_path):\n",
    "    print(f\"Error: El directorio base '{base_path}' no existe.\")\n",
    "else:\n",
    "    # Listar todos los contenidos del directorio base\n",
    "    try:\n",
    "        all_contents = os.listdir(base_path)\n",
    "        \n",
    "        # Filtrar para quedarnos solo con los directorios\n",
    "        subdirectories = [d for d in all_contents if os.path.isdir(os.path.join(base_path, d))]\n",
    "        \n",
    "        # Contar la cantidad de subdirectorios\n",
    "        num_subdirectories = len(subdirectories)\n",
    "        \n",
    "        print(f\"El directorio '{base_path}' contiene {num_subdirectories} subcarpetas (directorios).\")\n",
    "        \n",
    "        # Opcional: Imprimir los primeros N nombres de subcarpetas para verificar\n",
    "        if num_subdirectories > 0:\n",
    "            print(\"\\nAlgunas de las subcarpetas encontradas:\")\n",
    "            for i, subdir_name in enumerate(subdirectories):\n",
    "                if i < 10: # Imprime las primeras 10 (o menos si hay menos)\n",
    "                    print(f\"- {subdir_name}\")\n",
    "                else:\n",
    "                    break\n",
    "            if num_subdirectories > 10:\n",
    "                print(f\"... y {num_subdirectories - 10} más.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error al intentar listar los contenidos de '{base_path}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da8c5fd3-2adb-477c-a88c-43534f9e647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 22:53:44,619 - INFO - Semillas configuradas con valor: 42\n",
      "2025-05-11 22:53:44,624 - INFO - Total secuencias a usar: 750.\n",
      "2025-05-11 22:53:44,625 - INFO - Entrenamiento: 600 sec. Validación: 150 sec.\n",
      "2025-05-11 22:53:44,644 - INFO - RadarDataset inicializado con 600 secuencias válidas.\n",
      "2025-05-11 22:53:44,650 - INFO - RadarDataset inicializado con 150 secuencias válidas.\n",
      "2025-05-11 22:53:44,658 - INFO - Modelo ConvLSTM3D_Enhanced creado: 2 capas, Hidden dims: [32, 32], LayerNorm: True, Residual: False, PredSteps: 1\n",
      "2025-05-11 22:53:44,658 - INFO - Arquitectura del modelo:\n",
      "ConvLSTM3D_Enhanced(\n",
      "  (layers): ModuleList(\n",
      "    (0): ConvLSTM2DLayer(\n",
      "      (cell): ConvLSTMCell(\n",
      "        (conv): Conv2d(33, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): ConvLSTM2DLayer(\n",
      "      (cell): ConvLSTMCell(\n",
      "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer_norms): ModuleList(\n",
      "    (0-1): 2 x LayerNorm((32, 500, 500), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (output_conv): Conv3d(32, 1, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      ")\n",
      "2025-05-11 22:53:44,659 - INFO - Número total de parámetros entrenables: 32,112,289\n",
      "2025-05-11 22:53:44,659 - INFO - Usando dispositivo: cuda\n",
      "2025-05-11 22:53:44,678 - INFO - Usando SSIM loss con peso 0.3 y MSE con peso 0.7\n",
      "2025-05-11 22:53:44,678 - INFO - Iniciando entrenamiento: 10 épocas, LR: 0.0001, Batch (efectivo): 1\n",
      "2025-05-11 22:53:45,740 - INFO - Forma de entrada al modelo (después de permutar): torch.Size([18, 1, 6, 500, 500, 1])\n",
      "2025-05-11 22:53:45,742 - INFO - Forma objetivo (después de permutar): torch.Size([18, 1, 1, 500, 500, 1])\n",
      "2025-05-11 22:53:48,006 - INFO - Época 1/10 [1/600] - Pérdida: 1.069142\n",
      "2025-05-11 22:53:50,273 - INFO - Época 1/10 [2/600] - Pérdida: 1.065324\n",
      "2025-05-11 22:53:52,540 - INFO - Época 1/10 [3/600] - Pérdida: 1.044125\n",
      "2025-05-11 22:53:54,806 - INFO - Época 1/10 [4/600] - Pérdida: 1.060951\n",
      "2025-05-11 22:53:57,075 - INFO - Época 1/10 [5/600] - Pérdida: 1.049484\n",
      "2025-05-11 22:53:59,342 - INFO - Época 1/10 [6/600] - Pérdida: 0.616540\n",
      "2025-05-11 22:54:01,609 - INFO - Época 1/10 [7/600] - Pérdida: 0.368018\n",
      "2025-05-11 22:54:03,878 - INFO - Época 1/10 [8/600] - Pérdida: 0.285673\n",
      "2025-05-11 22:54:06,144 - INFO - Época 1/10 [9/600] - Pérdida: 0.319614\n",
      "2025-05-11 22:54:08,411 - INFO - Época 1/10 [10/600] - Pérdida: 0.327495\n",
      "2025-05-11 22:54:10,679 - INFO - Época 1/10 [11/600] - Pérdida: 0.309486\n",
      "2025-05-11 22:54:12,946 - INFO - Época 1/10 [12/600] - Pérdida: 0.088010\n",
      "2025-05-11 22:54:15,214 - INFO - Época 1/10 [13/600] - Pérdida: 0.080592\n",
      "2025-05-11 22:54:17,481 - INFO - Época 1/10 [14/600] - Pérdida: 0.084193\n",
      "2025-05-11 22:54:19,747 - INFO - Época 1/10 [15/600] - Pérdida: 0.092914\n",
      "2025-05-11 22:54:22,017 - INFO - Época 1/10 [16/600] - Pérdida: 0.086228\n",
      "2025-05-11 22:54:24,284 - INFO - Época 1/10 [17/600] - Pérdida: 0.304170\n",
      "2025-05-11 22:54:26,552 - INFO - Época 1/10 [18/600] - Pérdida: 0.317302\n",
      "2025-05-11 22:54:28,820 - INFO - Época 1/10 [19/600] - Pérdida: 0.312673\n",
      "2025-05-11 22:54:31,088 - INFO - Época 1/10 [20/600] - Pérdida: 0.312458\n",
      "2025-05-11 22:54:33,356 - INFO - Época 1/10 [21/600] - Pérdida: 0.298128\n",
      "2025-05-11 22:54:35,625 - INFO - Época 1/10 [22/600] - Pérdida: 0.126756\n",
      "2025-05-11 22:54:37,893 - INFO - Época 1/10 [23/600] - Pérdida: 0.287789\n",
      "2025-05-11 22:54:40,160 - INFO - Época 1/10 [24/600] - Pérdida: 0.290698\n",
      "2025-05-11 22:54:42,428 - INFO - Época 1/10 [25/600] - Pérdida: 0.266639\n",
      "2025-05-11 22:54:44,696 - INFO - Época 1/10 [26/600] - Pérdida: 0.190712\n",
      "2025-05-11 22:54:46,963 - INFO - Época 1/10 [27/600] - Pérdida: 0.264965\n",
      "2025-05-11 22:54:49,231 - INFO - Época 1/10 [28/600] - Pérdida: 0.215077\n",
      "2025-05-11 22:54:51,499 - INFO - Época 1/10 [29/600] - Pérdida: 0.190295\n",
      "2025-05-11 22:54:53,768 - INFO - Época 1/10 [30/600] - Pérdida: 0.237300\n",
      "2025-05-11 22:54:56,035 - INFO - Época 1/10 [31/600] - Pérdida: 0.028521\n",
      "2025-05-11 22:54:58,304 - INFO - Época 1/10 [32/600] - Pérdida: 0.264645\n",
      "2025-05-11 22:55:00,571 - INFO - Época 1/10 [33/600] - Pérdida: 0.282639\n",
      "2025-05-11 22:55:02,839 - INFO - Época 1/10 [34/600] - Pérdida: 0.265031\n",
      "2025-05-11 22:55:05,108 - INFO - Época 1/10 [35/600] - Pérdida: -0.068694\n",
      "2025-05-11 22:55:07,376 - INFO - Época 1/10 [36/600] - Pérdida: 0.069263\n",
      "2025-05-11 22:55:09,644 - INFO - Época 1/10 [37/600] - Pérdida: 0.040812\n",
      "2025-05-11 22:55:11,912 - INFO - Época 1/10 [38/600] - Pérdida: -0.033792\n",
      "2025-05-11 22:55:14,179 - INFO - Época 1/10 [39/600] - Pérdida: 0.146414\n",
      "2025-05-11 22:55:16,448 - INFO - Época 1/10 [40/600] - Pérdida: -0.011356\n",
      "2025-05-11 22:55:18,715 - INFO - Época 1/10 [41/600] - Pérdida: 0.238263\n",
      "2025-05-11 22:55:20,983 - INFO - Época 1/10 [42/600] - Pérdida: 0.254806\n",
      "2025-05-11 22:55:23,250 - INFO - Época 1/10 [43/600] - Pérdida: 0.150769\n",
      "2025-05-11 22:55:25,518 - INFO - Época 1/10 [44/600] - Pérdida: 0.229494\n",
      "2025-05-11 22:55:27,785 - INFO - Época 1/10 [45/600] - Pérdida: 0.265549\n",
      "2025-05-11 22:55:30,053 - INFO - Época 1/10 [46/600] - Pérdida: 0.235689\n",
      "2025-05-11 22:55:32,322 - INFO - Época 1/10 [47/600] - Pérdida: 0.010250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 651\u001b[0m\n\u001b[1;32m    648\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProceso completado.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 651\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 639\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    636\u001b[0m total_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    637\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNúmero total de parámetros entrenables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_params\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 639\u001b[0m trained_model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_loader:\n\u001b[1;32m    642\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerando predicciones de ejemplo usando el conjunto de validación...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 368\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, config)\u001b[0m\n\u001b[1;32m    364\u001b[0m         current_loss \u001b[38;5;241m=\u001b[39m mse_loss_weight \u001b[38;5;241m*\u001b[39m loss_mse_val \u001b[38;5;241m+\u001b[39m ssim_loss_weight \u001b[38;5;241m*\u001b[39m loss_ssim_component\n\u001b[1;32m    366\u001b[0m     loss \u001b[38;5;241m=\u001b[39m current_loss \u001b[38;5;241m/\u001b[39m accumulation_steps\n\u001b[0;32m--> 368\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader):\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip_grad_norm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta # Asegúrate de importar timedelta\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from netCDF4 import Dataset as NCDataset # Renombrar para evitar conflicto con la clase Dataset\n",
    "# from torch.cuda.amp import autocast # Se usará torch.amp.autocast\n",
    "# from torch.cuda.amp import GradScaler # Se usará torch.amp.GradScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics # Para métricas adicionales como SSIM\n",
    "from torch.utils.checkpoint import checkpoint # <--- IMPORTANTE PARA GRADIENT CHECKPOINTING\n",
    "import torch.amp # <--- IMPORTANTE PARA APIS MODERNAS DE AMP\n",
    "\n",
    "# Configuración del Logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Configuración para reproducibilidad y rendimiento\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Configura las semillas para reproducibilidad.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    logging.info(f\"Semillas configuradas con valor: {seed}\")\n",
    "\n",
    "class RadarDataset(Dataset):\n",
    "    def __init__(self, data_dir, subdirs_list, seq_len=6, pred_len=1,\n",
    "                 min_dbz=-30, max_dbz=70,\n",
    "                 expected_shape=(18, 500, 500), variable_name='DBZ'):\n",
    "        self.data_dir = data_dir\n",
    "        self.subdirs_list = subdirs_list\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.min_dbz = min_dbz\n",
    "        self.max_dbz = max_dbz\n",
    "        self.expected_z, self.expected_h, self.expected_w = expected_shape\n",
    "        self.variable_name = variable_name\n",
    "        self.valid_sequences = self._validate_subdirs()\n",
    "        if not self.valid_sequences:\n",
    "            logging.error(\"No se encontraron secuencias válidas. Verifica los datos y la estructura de carpetas.\")\n",
    "            raise ValueError(\"No se encontraron secuencias válidas.\")\n",
    "        logging.info(f\"RadarDataset inicializado con {len(self.valid_sequences)} secuencias válidas.\")\n",
    "\n",
    "    def _validate_subdirs(self):\n",
    "        valid_sequences = []\n",
    "        for subdir_name in self.subdirs_list:\n",
    "            subdir_path = os.path.join(self.data_dir, subdir_name)\n",
    "            if not os.path.isdir(subdir_path):\n",
    "                logging.warning(f\"Subdirectorio {subdir_name} no encontrado en {self.data_dir}. Omitiendo.\")\n",
    "                continue\n",
    "            if \".ipynb_checkpoints\" in subdir_name:\n",
    "                logging.debug(f\"Omitiendo directorio de checkpoints: {subdir_name}\")\n",
    "                continue\n",
    "            files = sorted(glob.glob(os.path.join(subdir_path, \"*.nc\")))\n",
    "            if len(files) >= self.seq_len + self.pred_len:\n",
    "                valid_sequences.append((files, subdir_name))\n",
    "            else:\n",
    "                logging.warning(f\"Subdirectorio {subdir_name} tiene {len(files)} archivos, necesita {self.seq_len + self.pred_len}. Omitiendo.\")\n",
    "        return valid_sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence_files, subdir_name = self.valid_sequences[idx]\n",
    "        input_data_list = []\n",
    "        output_data_list = []\n",
    "\n",
    "        for i in range(self.seq_len):\n",
    "            file_path = sequence_files[i]\n",
    "            try:\n",
    "                with NCDataset(file_path, 'r') as nc_file:\n",
    "                    dbz = nc_file.variables[self.variable_name][0, ...].astype(np.float32)\n",
    "                    if dbz.shape != (self.expected_z, self.expected_h, self.expected_w):\n",
    "                        logging.warning(f\"Forma inesperada {dbz.shape} en {file_path} para {subdir_name}. Omitiendo muestra.\")\n",
    "                        return self.__getitem__((idx + 1) % len(self))\n",
    "                    dbz = np.clip(dbz, self.min_dbz, self.max_dbz)\n",
    "                    dbz = (dbz - self.min_dbz) / (self.max_dbz - self.min_dbz)\n",
    "                    dbz = dbz[..., np.newaxis]\n",
    "                    input_data_list.append(dbz)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error cargando entrada {file_path} para {subdir_name}: {e}. Omitiendo muestra.\")\n",
    "                return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        for i in range(self.seq_len, self.seq_len + self.pred_len):\n",
    "            file_path = sequence_files[i]\n",
    "            try:\n",
    "                with NCDataset(file_path, 'r') as nc_file:\n",
    "                    dbz = nc_file.variables[self.variable_name][0, ...].astype(np.float32)\n",
    "                    if dbz.shape != (self.expected_z, self.expected_h, self.expected_w):\n",
    "                        logging.warning(f\"Forma inesperada {dbz.shape} en {file_path} para {subdir_name}. Omitiendo muestra.\")\n",
    "                        return self.__getitem__((idx + 1) % len(self))\n",
    "                    dbz = np.clip(dbz, self.min_dbz, self.max_dbz)\n",
    "                    dbz = (dbz - self.min_dbz) / (self.max_dbz - self.min_dbz)\n",
    "                    dbz = dbz[..., np.newaxis]\n",
    "                    output_data_list.append(dbz)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error cargando salida {file_path} para {subdir_name}: {e}. Omitiendo muestra.\")\n",
    "                return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        if len(input_data_list) != self.seq_len or len(output_data_list) != self.pred_len:\n",
    "            logging.warning(f\"No se pudieron cargar suficientes archivos para la secuencia {idx} en {subdir_name}. Omitiendo.\")\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        input_tensor = np.stack(input_data_list, axis=1)\n",
    "        output_tensor = np.stack(output_data_list, axis=1)\n",
    "        x = torch.from_numpy(input_tensor).float()\n",
    "        y = torch.from_numpy(output_tensor).float()\n",
    "        return x, y\n",
    "\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        return h_next, c_next\n",
    "    def init_hidden(self, batch_size, image_size, device):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=device))\n",
    "\n",
    "class ConvLSTM2DLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True, return_all_layers=False):\n",
    "        super(ConvLSTM2DLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "        self.cell = ConvLSTMCell(input_dim, hidden_dim, kernel_size, bias)\n",
    "    def forward(self, input_tensor, hidden_state=None): # input_tensor: (B, T_in, C_in, H, W)\n",
    "        b, seq_len, _, h, w = input_tensor.size()\n",
    "        device = input_tensor.device\n",
    "        if hidden_state is None:\n",
    "            hidden_state = self.cell.init_hidden(b, (h, w), device)\n",
    "        layer_output_list = []\n",
    "        h_cur, c_cur = hidden_state\n",
    "        for t in range(seq_len):\n",
    "            h_cur, c_cur = self.cell(input_tensor=input_tensor[:, t, :, :, :], cur_state=[h_cur, c_cur])\n",
    "            layer_output_list.append(h_cur)\n",
    "        if self.return_all_layers:\n",
    "            layer_output = torch.stack(layer_output_list, dim=1)\n",
    "        else:\n",
    "            layer_output = layer_output_list[-1].unsqueeze(1)\n",
    "        return layer_output, (h_cur, c_cur)\n",
    "\n",
    "class ConvLSTM3D_Enhanced(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dims=[32, 64], kernel_sizes=[(3,3), (3,3)],\n",
    "                 num_layers=2, pred_steps=1, use_layer_norm=True, use_residual=False,\n",
    "                 img_height=500, img_width=500):\n",
    "        super(ConvLSTM3D_Enhanced, self).__init__()\n",
    "        if isinstance(hidden_dims, int): hidden_dims = [hidden_dims] * num_layers\n",
    "        if isinstance(kernel_sizes, tuple): kernel_sizes = [kernel_sizes] * num_layers\n",
    "        assert len(hidden_dims) == num_layers and len(kernel_sizes) == num_layers\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.num_layers = num_layers\n",
    "        self.pred_steps = pred_steps\n",
    "        self.use_layer_norm = use_layer_norm\n",
    "        self.use_residual = use_residual\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layer_norms = nn.ModuleList() if use_layer_norm else None\n",
    "\n",
    "        current_dim = input_dim\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(\n",
    "                ConvLSTM2DLayer(input_dim=current_dim, hidden_dim=hidden_dims[i],\n",
    "                                kernel_size=kernel_sizes[i], bias=True, return_all_layers=True)\n",
    "            )\n",
    "            if use_layer_norm:\n",
    "                 self.layer_norms.append(nn.LayerNorm([hidden_dims[i], img_height, img_width]))\n",
    "            current_dim = hidden_dims[i]\n",
    "\n",
    "        self.output_conv = nn.Conv3d(in_channels=hidden_dims[-1],\n",
    "                                     out_channels=input_dim * pred_steps, # Esto será self.input_dim si pred_steps=1\n",
    "                                     kernel_size=(1, 3, 3), padding=(0, 1, 1))\n",
    "        logging.info(f\"Modelo ConvLSTM3D_Enhanced creado: {num_layers} capas, Hidden dims: {hidden_dims}, LayerNorm: {use_layer_norm}, Residual: {use_residual}, PredSteps: {pred_steps}\")\n",
    "\n",
    "    def forward(self, x_volumetric): # Espera (Z, B, T_in, H, W, C_in)\n",
    "        num_z_levels, b, seq_len, h, w, c_in = x_volumetric.shape\n",
    "        all_level_predictions = []\n",
    "\n",
    "        for z_idx in range(num_z_levels):\n",
    "            x_level = x_volumetric[z_idx, ...] # (B, T_in, H, W, C_in)\n",
    "            x_level_permuted = x_level.permute(0, 1, 4, 2, 3) # (B, T_in, C_in, H, W)\n",
    "            current_input = x_level_permuted\n",
    "            # residual_input = None # Lógica residual simplificada/omitida por ahora para claridad\n",
    "\n",
    "            for i in range(self.num_layers):\n",
    "                # if self.use_residual and i > 0:\n",
    "                #     residual_input = current_input # Necesitaría lógica de proyección si canales cambian\n",
    "                \n",
    "                if self.training: # Aplicar checkpointing solo durante el entrenamiento\n",
    "                    # El tercer argumento para checkpoint es el hidden_state para ConvLSTM2DLayer.forward\n",
    "                    # Como nuestra capa lo inicializa si es None, podemos pasar None.\n",
    "                    layer_output, _ = checkpoint(self.layers[i], current_input, None, use_reentrant=False)\n",
    "                else:\n",
    "                    layer_output, _ = self.layers[i](current_input)\n",
    "\n",
    "                if self.use_layer_norm and self.layer_norms:\n",
    "                    B_ln, T_ln, C_ln, H_ln, W_ln = layer_output.shape\n",
    "                    output_reshaped_for_ln = layer_output.contiguous().view(B_ln * T_ln, C_ln, H_ln, W_ln)\n",
    "                    normalized_output = self.layer_norms[i](output_reshaped_for_ln)\n",
    "                    layer_output = normalized_output.view(B_ln, T_ln, C_ln, H_ln, W_ln)\n",
    "\n",
    "                # if self.use_residual and residual_input is not None:\n",
    "                #     if residual_input.shape == layer_output.shape: # Simplificado\n",
    "                #         layer_output = layer_output + residual_input\n",
    "                current_input = layer_output\n",
    "            \n",
    "            # current_input ahora es (B, T_in, C_last_hidden, H, W)\n",
    "            output_for_conv3d = current_input.permute(0, 2, 1, 3, 4) # (B, C_last_hidden, T_in, H, W)\n",
    "            \n",
    "            # raw_conv_output tendrá forma (B, self.input_dim*self.pred_steps, T_in_out, H, W)\n",
    "            # donde T_in_out = T_in debido a kernel_size[0]=1, padding[0]=0 en Conv3d\n",
    "            # Ejemplo: (1, 1*1, 3, 500, 500) si T_in=3, pred_steps=1, input_dim=1\n",
    "            raw_conv_output = self.output_conv(output_for_conv3d)\n",
    "\n",
    "            # Seleccionar el último paso temporal de la salida de Conv3D\n",
    "            # Esto asume que la predicción para t+1 se basa en la salida en el último paso t de la secuencia de entrada.\n",
    "            prediction_at_final_step = raw_conv_output[:, :, -1, :, :] # Forma: (B, self.input_dim*self.pred_steps, H, W)\n",
    "                                                                      # Ejemplo: (1, 1, 500, 500)\n",
    "\n",
    "            # Remodelar para que coincida con (B, self.pred_steps, self.input_dim, H, W)\n",
    "            # prediction_at_final_step es (B, C_total_out, H, W) donde C_total_out = self.input_dim * self.pred_steps\n",
    "            level_prediction = prediction_at_final_step.view(b, self.pred_steps, self.input_dim, h, w)\n",
    "            \n",
    "            # Permutar a la forma de salida deseada para apilar sobre Z\n",
    "            # (B, pred_steps, H, W, C_out=self.input_dim)\n",
    "            level_prediction = level_prediction.permute(0, 1, 3, 4, 2)\n",
    "            all_level_predictions.append(level_prediction)\n",
    "\n",
    "        predictions_volumetric = torch.stack(all_level_predictions, dim=0) # (Z, B, pred_steps, H, W, C_out)\n",
    "        return predictions_volumetric\n",
    "\n",
    "class SSIMLoss(nn.Module):\n",
    "    def __init__(self, data_range=1.0, kernel_size_for_metric=7):\n",
    "        super(SSIMLoss, self).__init__()\n",
    "        try:\n",
    "            self.ssim_metric = torchmetrics.StructuralSimilarityIndexMeasure(\n",
    "                data_range=data_range, \n",
    "                kernel_size=kernel_size_for_metric\n",
    "            ).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "            self._has_reduction = hasattr(self.ssim_metric, 'reduction') and self.ssim_metric.reduction in ['elementwise_mean', 'sum']\n",
    "        except TypeError: \n",
    "             self.ssim_metric = torchmetrics.StructuralSimilarityIndexMeasure(\n",
    "                data_range=data_range, \n",
    "                kernel_size=kernel_size_for_metric,\n",
    "                reduction='elementwise_mean' \n",
    "            ).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "             self._has_reduction = True\n",
    "\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        num_z, batch_s, pred_t, height, width, channels = img1.shape\n",
    "        if pred_t != 1 or channels != 1:\n",
    "            logging.debug(f\"SSIMLoss: T_pred={pred_t}, channels={channels}. Se aplanarán estas dimensiones para SSIM.\")\n",
    "        \n",
    "        img1_reshaped = img1.permute(0, 1, 2, 5, 3, 4).contiguous().view(-1, channels, height, width)\n",
    "        img2_reshaped = img2.permute(0, 1, 2, 5, 3, 4).contiguous().view(-1, channels, height, width)\n",
    "        \n",
    "        ssim_val = self.ssim_metric(img1_reshaped, img2_reshaped)\n",
    "        if not self._has_reduction and ssim_val.ndim > 0 and ssim_val.numel() > 1:\n",
    "            ssim_val = ssim_val.mean()\n",
    "        return 1.0 - ssim_val\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, config):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logging.info(f\"Usando dispositivo: {device}\")\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config.get('weight_decay', 1e-5))\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=config.get('lr_patience', 3), verbose=True)\n",
    "    \n",
    "    criterion_mse = nn.MSELoss().to(device)\n",
    "    criterion_ssim = None\n",
    "    ssim_loss_weight = 0.0\n",
    "    mse_loss_weight = 1.0\n",
    "\n",
    "    if config.get('use_ssim_loss', False):\n",
    "        try:\n",
    "            criterion_ssim = SSIMLoss(\n",
    "                data_range=1.0, \n",
    "                kernel_size_for_metric=config.get('ssim_kernel_size', 7)\n",
    "            ).to(device)\n",
    "            ssim_loss_weight = config.get('ssim_loss_weight', 0.3)\n",
    "            mse_loss_weight = 1.0 - ssim_loss_weight\n",
    "            logging.info(f\"Usando SSIM loss con peso {ssim_loss_weight} y MSE con peso {mse_loss_weight}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al inicializar SSIMLoss: {e}. Se usará solo MSE.\")\n",
    "            criterion_ssim = None\n",
    "            ssim_loss_weight = 0.0\n",
    "            mse_loss_weight = 1.0\n",
    "\n",
    "    scaler = torch.amp.GradScaler(enabled=config['use_amp'])\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    train_losses, val_losses = [], []\n",
    "    accumulation_steps = config.get('accumulation_steps', 1)\n",
    "\n",
    "    logging.info(f\"Iniciando entrenamiento: {config['epochs']} épocas, LR: {config['learning_rate']}, Batch (efectivo): {config['batch_size'] * accumulation_steps}\")\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for batch_idx, (x, y) in enumerate(train_loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            if x.dim() == 6 and y.dim() == 6:\n",
    "                x = x.permute(1, 0, 2, 3, 4, 5) \n",
    "                y = y.permute(1, 0, 2, 3, 4, 5)\n",
    "            else:\n",
    "                logging.error(f\"Formas inesperadas para x o y antes de la permutación: x={x.shape}, y={y.shape}\")\n",
    "                continue\n",
    "\n",
    "            if batch_idx == 0 and epoch == 0:\n",
    "                logging.info(f\"Forma de entrada al modelo (después de permutar): {x.shape}\")\n",
    "                logging.info(f\"Forma objetivo (después de permutar): {y.shape}\")\n",
    "\n",
    "            with torch.amp.autocast(device_type='cuda', dtype=torch.float16, enabled=config['use_amp']):\n",
    "                predictions = model(x)\n",
    "                loss_mse_val = criterion_mse(predictions, y)\n",
    "                current_loss = loss_mse_val\n",
    "\n",
    "                if criterion_ssim is not None:\n",
    "                    loss_ssim_component = criterion_ssim(predictions, y)\n",
    "                    current_loss = mse_loss_weight * loss_mse_val + ssim_loss_weight * loss_ssim_component\n",
    "                \n",
    "                loss = current_loss / accumulation_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                if config.get('clip_grad_norm', None):\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config['clip_grad_norm'])\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            running_train_loss += loss.item() * accumulation_steps\n",
    "            if (batch_idx + 1) % config.get('log_interval', 20) == 0:\n",
    "                logging.info(f\"Época {epoch+1}/{config['epochs']} [{batch_idx+1}/{len(train_loader)}] - Pérdida: {loss.item() * accumulation_steps:.6f}\")\n",
    "        \n",
    "        avg_train_loss = running_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            running_val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for x_val, y_val in val_loader:\n",
    "                    x_val = x_val.to(device)\n",
    "                    y_val = y_val.to(device)\n",
    "                    if x_val.dim() == 6 and y_val.dim() == 6:\n",
    "                        x_val = x_val.permute(1, 0, 2, 3, 4, 5)\n",
    "                        y_val = y_val.permute(1, 0, 2, 3, 4, 5)\n",
    "                    else:\n",
    "                        logging.error(f\"Formas inesperadas (val) x={x_val.shape}, y={y_val.shape}\")\n",
    "                        continue\n",
    "                    \n",
    "                    with torch.amp.autocast(device_type='cuda', dtype=torch.float16, enabled=config['use_amp']):\n",
    "                        predictions_val = model(x_val)\n",
    "                        val_loss_mse_val = criterion_mse(predictions_val, y_val)\n",
    "                        current_val_loss = val_loss_mse_val\n",
    "                        if criterion_ssim is not None:\n",
    "                            val_loss_ssim_component = criterion_ssim(predictions_val, y_val)\n",
    "                            current_val_loss = mse_loss_weight * val_loss_mse_val + ssim_loss_weight * val_loss_ssim_component\n",
    "                    running_val_loss += current_val_loss.item()\n",
    "            \n",
    "            avg_val_loss = running_val_loss / len(val_loader)\n",
    "            val_losses.append(avg_val_loss)\n",
    "            scheduler.step(avg_val_loss)\n",
    "            epoch_duration = time.time() - epoch_start_time\n",
    "            logging.info(f\"Época {epoch+1} completada en {epoch_duration:.2f}s. Pérdida (train): {avg_train_loss:.6f}, Pérdida (val): {avg_val_loss:.6f}\")\n",
    "\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save({'epoch': epoch + 1, 'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(), 'loss': best_val_loss},\n",
    "                           os.path.join(config['model_save_dir'], \"best_convlstm_model.pth\"))\n",
    "                logging.info(f\"Mejor modelo guardado (Pérdida Val: {best_val_loss:.6f})\")\n",
    "        else:\n",
    "            epoch_duration = time.time() - epoch_start_time\n",
    "            logging.info(f\"Época {epoch+1} completada en {epoch_duration:.2f}s. Pérdida (train): {avg_train_loss:.6f} (No hay datos de validación)\")\n",
    "\n",
    "        if (epoch + 1) % config.get('checkpoint_interval', 5) == 0:\n",
    "            torch.save({'epoch': epoch + 1, 'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(), 'train_losses': train_losses,\n",
    "                        'val_losses': val_losses if val_loader else []},\n",
    "                       os.path.join(config['model_save_dir'], f\"checkpoint_epoch_{epoch+1}.pth\"))\n",
    "            logging.info(f\"Checkpoint guardado en la época {epoch+1}\")\n",
    "\n",
    "    logging.info(\"Entrenamiento finalizado.\")\n",
    "    if train_loader: # Solo plotear si hubo entrenamiento\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(train_losses, label='Pérdida Entrenamiento')\n",
    "        if val_loader:\n",
    "            plt.plot(val_losses, label='Pérdida Validación')\n",
    "        plt.xlabel('Épocas'); plt.ylabel('Pérdida'); plt.legend()\n",
    "        plt.savefig(os.path.join(config['model_save_dir'], \"loss_curves.png\")); plt.close()\n",
    "    return model, {'train_losses': train_losses, 'val_losses': val_losses if val_loader else []}\n",
    "\n",
    "def generate_prediction_netcdf(model, data_loader, config, device, num_samples=1):\n",
    "    output_dir = config['predictions_output_dir']\n",
    "    min_dbz = config['min_dbz']\n",
    "    max_dbz = config['max_dbz']\n",
    "    variable_name = config.get('dbz_variable_name_pred', 'DBZ_predicted')\n",
    "\n",
    "    sensor_latitude = config.get('sensor_latitude', -34.64799880981445)\n",
    "    sensor_longitude = config.get('sensor_longitude', -68.01699829101562)\n",
    "    sensor_altitude_km = config.get('sensor_altitude_km', 0.550000011920929)\n",
    "    grid_minz_km = config.get('grid_minz_km', 1.0)\n",
    "    grid_dz_km = config.get('grid_dz_km', 0.5)\n",
    "    grid_minx_km = config.get('grid_minx_km', -249.75)\n",
    "    grid_dx_km = config.get('grid_dx_km', 0.5)\n",
    "    grid_miny_km = config.get('grid_miny_km', -249.75)\n",
    "    grid_dy_km = config.get('grid_dy_km', 0.5)\n",
    "    radar_name = config.get('radar_name', \"La Llave\")\n",
    "    institution_name = config.get('institution_name', \"Tu Institucion/Universidad\")\n",
    "    data_source_name = config.get('data_source_name', \"Gobierno de Mendoza\")\n",
    "    projection_var_name_in_file = config.get('projection_variable_name', \"radar_projection_info\")\n",
    "\n",
    "    model.eval()\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    num_z_output = config['expected_shape'][0]\n",
    "    height = config['expected_shape'][1]\n",
    "    width = config['expected_shape'][2]\n",
    "\n",
    "    z_coord_values = np.arange(grid_minz_km, grid_minz_km + num_z_output * grid_dz_km, grid_dz_km)[:num_z_output]\n",
    "    x_coord_values = np.arange(grid_minx_km, grid_minx_km + width * grid_dx_km, grid_dx_km)[:width]\n",
    "    y_coord_values = np.arange(grid_miny_km, grid_miny_km + height * grid_dy_km, grid_dy_km)[:height]\n",
    "    \n",
    "    base_dt_for_samples = datetime.utcnow()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (x_input_volume, y_true_volume) in enumerate(data_loader):\n",
    "            if i >= num_samples: break\n",
    "\n",
    "            current_pred_datetime = base_dt_for_samples + timedelta(minutes=i * config.get('prediction_interval_minutes', 5))\n",
    "            \n",
    "            x_to_model = x_input_volume.to(device)\n",
    "            if x_to_model.dim() == 6:\n",
    "                 x_to_model = x_to_model.permute(1, 0, 2, 3, 4, 5)\n",
    "\n",
    "            with torch.amp.autocast(device_type='cuda', dtype=torch.float16, enabled=config['use_amp']):\n",
    "                prediction_norm = model(x_to_model) # Espera (Z,B,T,H,W,C) -> Sale (Z,B,T_pred,H,W,C)\n",
    "\n",
    "            # prediction_norm es (Z, B=1, T_pred=1, H, W, C=1)\n",
    "            # Quitar B, T_pred, C para obtener (Z, H, W)\n",
    "            pred_data_np = prediction_norm.squeeze(1).squeeze(1).squeeze(-1).cpu().numpy() \n",
    "            pred_data_desnorm = pred_data_np * (max_dbz - min_dbz) + min_dbz\n",
    "            pred_data_final_for_nc = np.expand_dims(pred_data_desnorm, axis=0) # (1=time, Z, H, W)\n",
    "\n",
    "            file_timestamp_str = current_pred_datetime.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_filename = os.path.join(output_dir, f\"pred_{variable_name}_{file_timestamp_str}_sample{i}.nc\")\n",
    "\n",
    "            with NCDataset(output_filename, 'w', format='NETCDF4') as ncfile:\n",
    "                ncfile.Conventions = \"CF-1.7\"\n",
    "                ncfile.title = f\"Radar Reflectivity Forecast ({variable_name}) from ConvLSTM Model\"\n",
    "                ncfile.institution = institution_name\n",
    "                ncfile.source_data_description = f\"Based on input data from {data_source_name}, Radar: {radar_name}.\"\n",
    "                ncfile.source_model_description = \"ConvLSTM neural network prediction.\"\n",
    "                ncfile.history = f\"Created {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')} by prediction script.\"\n",
    "                ncfile.comment = \"Model-generated forecast. Not for operational use without verification.\"\n",
    "                ncfile.radar_name = radar_name; ncfile.sensor_latitude = sensor_latitude\n",
    "                ncfile.sensor_longitude = sensor_longitude; ncfile.sensor_altitude = sensor_altitude_km\n",
    "                ncfile.references = f\"Tesis de {config.get('author_name', '[Tu Nombre]')}, {config.get('author_institution', '[Tu Universidad/Institucion]')}\"\n",
    "\n",
    "                ncfile.createDimension('time', 1); ncfile.createDimension('level', num_z_output)\n",
    "                ncfile.createDimension('y', height); ncfile.createDimension('x', width)\n",
    "\n",
    "                time_var = ncfile.createVariable('time', 'f8', ('time',))\n",
    "                epoch_time = datetime(1970, 1, 1, 0, 0, 0)\n",
    "                time_value_seconds = (current_pred_datetime.replace(tzinfo=None) - epoch_time).total_seconds()\n",
    "                time_var[:] = [time_value_seconds]\n",
    "                time_var.units = \"seconds since 1970-01-01 00:00:00 UTC\"; time_var.calendar = \"gregorian\"\n",
    "                time_var.long_name = \"time of forecast\"; time_var.standard_name = \"time\"; time_var.axis = \"T\"\n",
    "\n",
    "                z_coord = ncfile.createVariable('level', 'f4', ('level',))\n",
    "                z_coord[:] = z_coord_values\n",
    "                z_coord.units = \"km\"; z_coord.positive = \"up\"; z_coord.long_name = \"altitude\"; z_coord.standard_name = \"altitude\"; z_coord.axis = \"Z\"\n",
    "\n",
    "                x_coord = ncfile.createVariable('x', 'f4', ('x',))\n",
    "                x_coord[:] = x_coord_values\n",
    "                x_coord.units = \"km\"; x_coord.long_name = \"projection_x_coordinate\"; x_coord.standard_name = \"projection_x_coordinate\"; x_coord.axis = \"X\"\n",
    "\n",
    "                y_coord = ncfile.createVariable('y', 'f4', ('y',))\n",
    "                y_coord[:] = y_coord_values\n",
    "                y_coord.units = \"km\"; y_coord.long_name = \"projection_y_coordinate\"; y_coord.standard_name = \"projection_y_coordinate\"; y_coord.axis = \"Y\"\n",
    "                \n",
    "                projection_var = ncfile.createVariable(projection_var_name_in_file, 'i4')\n",
    "                projection_var.grid_mapping_name = \"lambert_azimuthal_equal_area\"\n",
    "                projection_var.longitude_of_projection_origin = sensor_longitude\n",
    "                projection_var.latitude_of_projection_origin = sensor_latitude\n",
    "                projection_var.false_easting = 0.0; projection_var.false_northing = 0.0\n",
    "\n",
    "                pred_dbz_var = ncfile.createVariable(variable_name, 'f4', ('time', 'level', 'y', 'x'),\n",
    "                                                 fill_value=np.float32(config.get('fill_value', -9999.0)))\n",
    "                pred_dbz_var.units = 'dBZ'; pred_dbz_var.long_name = 'Predicted Radar Reflectivity'\n",
    "                pred_dbz_var.coordinates = \"time level y x\"; pred_dbz_var.grid_mapping = projection_var_name_in_file\n",
    "                pred_dbz_var[:] = pred_data_final_for_nc\n",
    "            logging.info(f\"Predicción de muestra con metadatos CF guardada en: {output_filename}\")\n",
    "\n",
    "def main():\n",
    "    # Celda 1 del Notebook:\n",
    "    # import os\n",
    "    # os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "    # print(f\"PYTORCH_CUDA_ALLOC_CONF set to: {os.environ.get('PYTORCH_CUDA_ALLOC_CONF')}\")\n",
    "    # Asegúrate de REINICIAR EL KERNEL después de ejecutar esto por primera vez.\n",
    "\n",
    "    set_seed(42)\n",
    "    config = {\n",
    "        'data_dir': \"/home/Big-Sample-Livianos-757-carpetas\",\n",
    "        'model_save_dir': \"/home/model_output_final_v_ckpt\", \n",
    "        'predictions_output_dir': \"/home/predictions_final_v_ckpt\",\n",
    "        \n",
    "        'seq_len': 6,\n",
    "        'pred_len': 1, 'pred_steps_model': 1,\n",
    "        'min_dbz': -30.0, 'max_dbz': 70.0, 'fill_value': -9999.0,\n",
    "        'expected_shape': (18, 500, 500),\n",
    "        'dbz_variable_name': 'DBZ', 'dbz_variable_name_pred': 'DBZ_forecast',\n",
    "\n",
    "        'sensor_latitude': -34.64799880981445, 'sensor_longitude': -68.01699829101562,\n",
    "        'sensor_altitude_km': 0.550000011920929, 'grid_minz_km': 1.0, 'grid_dz_km': 0.5,\n",
    "        'grid_minx_km': -249.75, 'grid_dx_km': 0.5, 'grid_miny_km': -249.75, 'grid_dy_km': 0.5,\n",
    "        'radar_name': \"La Llave\", 'institution_name': \"Universidad de Mendoza - Federico Caballero\",\n",
    "        'author_name': \"Federico Caballero\", 'author_institution': \"Universidad de Mendoza\",\n",
    "        'data_source_name': \"Gobierno de Mendoza\", 'projection_variable_name': \"lambert_azimuthal_projection\",\n",
    "        'prediction_interval_minutes': 5,\n",
    "\n",
    "        'model_input_dim': 1,\n",
    "        'model_hidden_dims': [32, 32], # REDUCIDO\n",
    "        'model_kernel_sizes': [(3,3), (3,3)], # AJUSTADO\n",
    "        'model_num_layers': 2, # REDUCIDO\n",
    "        'model_use_layer_norm': True, 'model_use_residual': False,\n",
    "\n",
    "        'batch_size': 1, 'epochs': 10, \n",
    "        'learning_rate': 1e-4, 'weight_decay': 1e-5, 'lr_patience': 3, # Reducido patience para prueba rápida\n",
    "        'use_amp': True, 'accumulation_steps': 1, \n",
    "        'clip_grad_norm': 1.0, 'log_interval': 1, \n",
    "        'checkpoint_interval': 1,\n",
    "\n",
    "        'use_ssim_loss': True, 'ssim_kernel_size': 7, 'ssim_loss_weight': 0.3,\n",
    "\n",
    "        'train_val_split_ratio': 0.8,\n",
    "        'max_sequences_to_use': None, \n",
    "    }\n",
    "\n",
    "    os.makedirs(config['model_save_dir'], exist_ok=True)\n",
    "    os.makedirs(config['predictions_output_dir'], exist_ok=True)\n",
    "\n",
    "    all_subdirs_available = sorted([\n",
    "        d for d in os.listdir(config['data_dir']) \n",
    "        if os.path.isdir(os.path.join(config['data_dir'], d)) and not d.startswith('.')\n",
    "    ])\n",
    "    if not all_subdirs_available: logging.error(f\"No subdirs in {config['data_dir']}\"); return\n",
    "\n",
    "    if config['max_sequences_to_use'] and config['max_sequences_to_use'] < len(all_subdirs_available):\n",
    "        logging.info(f\"Usando muestra aleatoria de {config['max_sequences_to_use']} secuencias.\")\n",
    "        random.shuffle(all_subdirs_available)\n",
    "        subdirs_to_use = all_subdirs_available[:config['max_sequences_to_use']]\n",
    "    else: subdirs_to_use = all_subdirs_available\n",
    "    logging.info(f\"Total secuencias a usar: {len(subdirs_to_use)}.\")\n",
    "    if not subdirs_to_use : logging.error(\"No hay secuencias para procesar.\"); return\n",
    "\n",
    "    split_idx = int(len(subdirs_to_use) * config['train_val_split_ratio'])\n",
    "    train_subdirs, val_subdirs = subdirs_to_use[:split_idx], subdirs_to_use[split_idx:]\n",
    "    if not train_subdirs: logging.error(\"No hay secuencias de entrenamiento.\"); return\n",
    "    logging.info(f\"Entrenamiento: {len(train_subdirs)} sec. Validación: {len(val_subdirs)} sec.\")\n",
    "\n",
    "    train_dataset = RadarDataset(config['data_dir'], train_subdirs, seq_len=config['seq_len'], pred_len=config['pred_len'],\n",
    "                                 min_dbz=config['min_dbz'], max_dbz=config['max_dbz'],\n",
    "                                 expected_shape=config['expected_shape'], variable_name=config['dbz_variable_name'])\n",
    "    val_loader = None; val_dataset_len = 0\n",
    "    if val_subdirs:\n",
    "        val_dataset = RadarDataset(config['data_dir'], val_subdirs, seq_len=config['seq_len'], pred_len=config['pred_len'],\n",
    "                                   min_dbz=config['min_dbz'], max_dbz=config['max_dbz'],\n",
    "                                   expected_shape=config['expected_shape'], variable_name=config['dbz_variable_name'])\n",
    "        val_dataset_len = len(val_dataset)\n",
    "        if val_dataset_len > 0:\n",
    "             val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=2, pin_memory=True)\n",
    "        else: logging.info(\"Dataset de validación vacío.\")\n",
    "    else: logging.info(\"No subdirectorios para validación.\")\n",
    "\n",
    "    if len(train_dataset) == 0: logging.error(\"Dataset de entrenamiento vacío.\"); return\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    model = ConvLSTM3D_Enhanced(\n",
    "        input_dim=config['model_input_dim'], hidden_dims=config['model_hidden_dims'],\n",
    "        kernel_sizes=config['model_kernel_sizes'], num_layers=config['model_num_layers'],\n",
    "        pred_steps=config['pred_steps_model'], use_layer_norm=config['model_use_layer_norm'],\n",
    "        use_residual=config['model_use_residual'],\n",
    "        img_height=config['expected_shape'][1], img_width=config['expected_shape'][2]\n",
    "    )\n",
    "    logging.info(f\"Arquitectura del modelo:\\n{model}\")\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    logging.info(f\"Número total de parámetros entrenables: {total_params:,}\")\n",
    "\n",
    "    trained_model, history = train_model(model, train_loader, val_loader, config)\n",
    "\n",
    "    if val_loader:\n",
    "        logging.info(\"Generando predicciones de ejemplo usando el conjunto de validación...\")\n",
    "        generate_prediction_netcdf(trained_model, val_loader, config,\n",
    "                                   device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "                                   num_samples=min(5, val_dataset_len))\n",
    "    else:\n",
    "        logging.info(\"No val_loader, se omiten predicciones de ejemplo.\")\n",
    "    logging.info(\"Proceso completado.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec8c64-b9ab-4b1a-a742-d0bca5569527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
