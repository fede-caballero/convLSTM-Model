{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a95315-21c1-41de-a409-09f3319d9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install netCDF4 torchmetrics matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec770cc-2e7d-4ca2-b908-7ee098a5b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version PyTorch built with: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c5fd3-2adb-477c-a88c-43534f9e647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta # Asegúrate de importar timedelta\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from netCDF4 import Dataset as NCDataset # Renombrar para evitar conflicto con la clase Dataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics # Para métricas adicionales como SSIM\n",
    "\n",
    "# Configuración del Logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Configuración para reproducibilidad y rendimiento\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Configura las semillas para reproducibilidad.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    logging.info(f\"Semillas configuradas con valor: {seed}\")\n",
    "\n",
    "class RadarDataset(Dataset):\n",
    "    def __init__(self, data_dir, subdirs_list, seq_len=6, pred_len=1,\n",
    "                 min_dbz=-30, max_dbz=70,\n",
    "                 expected_shape=(18, 500, 500), variable_name='DBZ'):\n",
    "        self.data_dir = data_dir\n",
    "        self.subdirs_list = subdirs_list\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.min_dbz = min_dbz\n",
    "        self.max_dbz = max_dbz\n",
    "        self.expected_z, self.expected_h, self.expected_w = expected_shape\n",
    "        self.variable_name = variable_name\n",
    "        self.valid_sequences = self._validate_subdirs()\n",
    "        if not self.valid_sequences:\n",
    "            logging.error(\"No se encontraron secuencias válidas. Verifica los datos y la estructura de carpetas.\")\n",
    "            raise ValueError(\"No se encontraron secuencias válidas.\")\n",
    "        logging.info(f\"RadarDataset inicializado con {len(self.valid_sequences)} secuencias válidas.\")\n",
    "\n",
    "    def _validate_subdirs(self):\n",
    "        valid_sequences = []\n",
    "        for subdir_name in self.subdirs_list:\n",
    "            subdir_path = os.path.join(self.data_dir, subdir_name)\n",
    "            if not os.path.isdir(subdir_path):\n",
    "                logging.warning(f\"Subdirectorio {subdir_name} no encontrado en {self.data_dir}. Omitiendo.\")\n",
    "                continue\n",
    "            files = sorted(glob.glob(os.path.join(subdir_path, \"*.nc\")))\n",
    "            if len(files) >= self.seq_len + self.pred_len:\n",
    "                # Guardamos la tupla de (lista_de_archivos, nombre_subdirectorio)\n",
    "                # para poder acceder al nombre y potencialmente parsear el tiempo si es necesario\n",
    "                valid_sequences.append((files, subdir_name))\n",
    "            else:\n",
    "                logging.warning(f\"Subdirectorio {subdir_name} tiene {len(files)} archivos, necesita {self.seq_len + self.pred_len}. Omitiendo.\")\n",
    "        return valid_sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence_files, subdir_name = self.valid_sequences[idx] # Ahora obtenemos también subdir_name\n",
    "        input_data_list = []\n",
    "        output_data_list = []\n",
    "        # ### ¡DEBES ADAPTAR ESTO! ###\n",
    "        # Para el tiempo de predicción, necesitamos el tiempo del último archivo de entrada.\n",
    "        # Asumimos que el nombre del archivo o el subdir_name contiene información temporal parseable.\n",
    "        # Ejemplo: si el último archivo de entrada es '.../2020020320/040919.nc'\n",
    "        # y el siguiente es 041419.nc (5 minutos después), ese sería el target.\n",
    "        # Por ahora, solo pasaremos los datos. El manejo del tiempo real se hará en generate_prediction.\n",
    "        # Si necesitas pasar el tiempo exacto de la predicción objetivo desde aquí:\n",
    "        # last_input_file_name = os.path.basename(sequence_files[self.seq_len - 1])\n",
    "        # target_file_name = os.path.basename(sequence_files[self.seq_len])\n",
    "        # Podrías parsear estos nombres para obtener datetimes.\n",
    "\n",
    "        for i in range(self.seq_len):\n",
    "            file_path = sequence_files[i]\n",
    "            try:\n",
    "                with NCDataset(file_path, 'r') as nc_file:\n",
    "                    dbz = nc_file.variables[self.variable_name][0, ...].astype(np.float32)\n",
    "                    if dbz.shape != (self.expected_z, self.expected_h, self.expected_w):\n",
    "                        logging.warning(f\"Forma inesperada {dbz.shape} en {file_path}. Omitiendo.\")\n",
    "                        return self.__getitem__((idx + 1) % len(self))\n",
    "                    dbz = np.clip(dbz, self.min_dbz, self.max_dbz)\n",
    "                    dbz = (dbz - self.min_dbz) / (self.max_dbz - self.min_dbz)\n",
    "                    dbz = dbz[..., np.newaxis]\n",
    "                    input_data_list.append(dbz)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error cargando entrada {file_path}: {e}. Omitiendo.\")\n",
    "                return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        for i in range(self.seq_len, self.seq_len + self.pred_len):\n",
    "            file_path = sequence_files[i]\n",
    "            try:\n",
    "                with NCDataset(file_path, 'r') as nc_file:\n",
    "                    dbz = nc_file.variables[self.variable_name][0, ...].astype(np.float32)\n",
    "                    if dbz.shape != (self.expected_z, self.expected_h, self.expected_w):\n",
    "                        logging.warning(f\"Forma inesperada {dbz.shape} en {file_path}. Omitiendo.\")\n",
    "                        return self.__getitem__((idx + 1) % len(self))\n",
    "                    dbz = np.clip(dbz, self.min_dbz, self.max_dbz)\n",
    "                    dbz = (dbz - self.min_dbz) / (self.max_dbz - self.min_dbz)\n",
    "                    dbz = dbz[..., np.newaxis]\n",
    "                    output_data_list.append(dbz)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error cargando salida {file_path}: {e}. Omitiendo.\")\n",
    "                return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        if len(input_data_list) != self.seq_len or len(output_data_list) != self.pred_len:\n",
    "            logging.warning(f\"No se pudieron cargar suficientes archivos para la secuencia {idx} en {subdir_name}. Omitiendo.\")\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        input_tensor = np.stack(input_data_list, axis=1)\n",
    "        output_tensor = np.stack(output_data_list, axis=1)\n",
    "        x = torch.from_numpy(input_tensor).float()\n",
    "        y = torch.from_numpy(output_tensor).float()\n",
    "        # Devolvemos también el nombre del subdirectorio (o el path del último archivo de entrada)\n",
    "        # para ayudar a determinar el tiempo de la predicción más tarde.\n",
    "        # Por simplicidad, aquí solo devolvemos x e y. El manejo del tiempo se hará en generate_prediction.\n",
    "        # Si quieres pasar el tiempo, necesitarías una estructura más compleja o modificar el DataLoader.\n",
    "        return x, y #, subdir_name # o sequence_files[self.seq_len - 1]\n",
    "\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        return h_next, c_next\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
    "\n",
    "class ConvLSTM2DLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True, return_all_layers=False):\n",
    "        super(ConvLSTM2DLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "        self.cell = ConvLSTMCell(input_dim, hidden_dim, kernel_size, bias)\n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        b, seq_len, _, h, w = input_tensor.size()\n",
    "        if hidden_state is None:\n",
    "            hidden_state = self.cell.init_hidden(b, (h, w))\n",
    "        layer_output_list = []\n",
    "        h_cur, c_cur = hidden_state\n",
    "        for t in range(seq_len):\n",
    "            h_cur, c_cur = self.cell(input_tensor=input_tensor[:, t, :, :, :], cur_state=[h_cur, c_cur])\n",
    "            layer_output_list.append(h_cur)\n",
    "        if self.return_all_layers:\n",
    "            layer_output = torch.stack(layer_output_list, dim=1)\n",
    "        else:\n",
    "            layer_output = layer_output_list[-1].unsqueeze(1)\n",
    "        return layer_output, (h_cur, c_cur)\n",
    "\n",
    "class ConvLSTM3D_Enhanced(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dims=[32, 64], kernel_sizes=[(3,3), (3,3)],\n",
    "                 num_layers=2, pred_steps=1, use_layer_norm=True, use_residual=False,\n",
    "                 img_height=500, img_width=500): # Añadir dimensiones de imagen para LayerNorm\n",
    "        super(ConvLSTM3D_Enhanced, self).__init__()\n",
    "        if isinstance(hidden_dims, int): hidden_dims = [hidden_dims] * num_layers\n",
    "        if isinstance(kernel_sizes, tuple): kernel_sizes = [kernel_sizes] * num_layers\n",
    "        assert len(hidden_dims) == num_layers and len(kernel_sizes) == num_layers\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.num_layers = num_layers\n",
    "        self.pred_steps = pred_steps\n",
    "        self.use_layer_norm = use_layer_norm\n",
    "        self.use_residual = use_residual\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layer_norms = nn.ModuleList() if use_layer_norm else None\n",
    "\n",
    "        current_dim = input_dim\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(\n",
    "                ConvLSTM2DLayer(input_dim=current_dim, hidden_dim=hidden_dims[i],\n",
    "                                kernel_size=kernel_sizes[i], bias=True, return_all_layers=True)\n",
    "            )\n",
    "            if use_layer_norm:\n",
    "                # LayerNorm se aplica sobre C, H, W.\n",
    "                # La forma de salida de ConvLSTM2DLayer es (B, T, C_hidden, H, W)\n",
    "                # Para aplicar LayerNorm a cada (C,H,W) slice individualmente\n",
    "                # a través de B y T, puedes usar nn.GroupNorm(1, C_hidden) como una alternativa\n",
    "                # que funciona bien, o una LayerNorm reajustada.\n",
    "                # Aquí usamos LayerNorm que espera (..., C, H, W)\n",
    "                 self.layer_norms.append(nn.LayerNorm([hidden_dims[i], img_height, img_width]))\n",
    "            current_dim = hidden_dims[i]\n",
    "\n",
    "        self.output_conv = nn.Conv3d(in_channels=hidden_dims[-1],\n",
    "                                     out_channels=input_dim * pred_steps,\n",
    "                                     kernel_size=(1, 3, 3), padding=(0, 1, 1))\n",
    "        logging.info(f\"Modelo ConvLSTM3D_Enhanced creado: {num_layers} capas, Hidden dims: {hidden_dims}, LayerNorm: {use_layer_norm}, Residual: {use_residual}, PredSteps: {pred_steps}\")\n",
    "\n",
    "    def forward(self, x_volumetric):\n",
    "        num_z_levels, b, seq_len, h, w, c_in = x_volumetric.shape\n",
    "        all_level_predictions = []\n",
    "\n",
    "        for z_idx in range(num_z_levels):\n",
    "            x_level = x_volumetric[z_idx, ...]\n",
    "            x_level_permuted = x_level.permute(0, 1, 4, 2, 3) # (B, T_in, C_in, H, W)\n",
    "            current_input = x_level_permuted\n",
    "            residual_input = None # Definir para conexiones residuales\n",
    "\n",
    "            for i in range(self.num_layers):\n",
    "                if self.use_residual and i > 0: # Guardar entrada para conexión residual\n",
    "                    residual_input = current_input\n",
    "\n",
    "                layer_output, _ = self.layers[i](current_input) # (B, T, C_hidden, H, W)\n",
    "\n",
    "                if self.use_layer_norm and self.layer_norms:\n",
    "                    # Aplicar LayerNorm. La salida es (B, T, C_hidden, H, W)\n",
    "                    # LayerNorm espera (..., C_hidden, H, W). Aplicamos por cada B, T.\n",
    "                    B_ln, T_ln, C_ln, H_ln, W_ln = layer_output.shape\n",
    "                    output_reshaped_for_ln = layer_output.contiguous().view(B_ln * T_ln, C_ln, H_ln, W_ln)\n",
    "                    normalized_output = self.layer_norms[i](output_reshaped_for_ln)\n",
    "                    layer_output = normalized_output.view(B_ln, T_ln, C_ln, H_ln, W_ln)\n",
    "\n",
    "                if self.use_residual and residual_input is not None:\n",
    "                    # Asegurar que las dimensiones de los canales coincidan o usar una convolución 1x1\n",
    "                    if residual_input.shape[2] == layer_output.shape[2]: # Comparar canales C_hidden\n",
    "                        layer_output = layer_output + residual_input\n",
    "                    # else: podrías añadir una conv 1x1 en residual_input para igualar canales\n",
    "\n",
    "                current_input = layer_output\n",
    "\n",
    "            output_for_conv3d = current_input.permute(0, 2, 1, 3, 4) # (B, C_last_hidden, T_seq, H, W)\n",
    "            level_prediction = self.output_conv(output_for_conv3d)\n",
    "            level_prediction = level_prediction.view(b, self.pred_steps, self.input_dim, h, w)\n",
    "            level_prediction = level_prediction.permute(0, 1, 3, 4, 2) # (B, pred_steps, H, W, C_out)\n",
    "            all_level_predictions.append(level_prediction)\n",
    "\n",
    "        predictions_volumetric = torch.stack(all_level_predictions, dim=0) # (Z, B, pred_steps, H, W, C_out)\n",
    "        return predictions_volumetric\n",
    "\n",
    "# (SSIMLoss y train_model permanecen mayormente iguales, pero asegúrate que SSIMLoss\n",
    "# y las métricas en train_model manejen la forma de salida (Z,B,T,H,W,C) correctamente)\n",
    "\n",
    "class SSIMLoss(nn.Module):\n",
    "    def __init__(self, data_range=1.0, win_size=7): # win_size más pequeño puede ser mejor para características locales\n",
    "        super(SSIMLoss, self).__init__()\n",
    "        self.ssim_metric = torchmetrics.StructuralSimilarityIndexMeasure(\n",
    "            data_range=data_range, win_size=win_size, reduction='elementwise_mean'\n",
    "        ).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")) # Mover a dispositivo\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        # img1, img2: (Z, B, T_pred, H, W, C)\n",
    "        # torchmetrics SSIM espera (N, C, H, W)\n",
    "        num_z, batch_s, pred_t, height, width, channels = img1.shape\n",
    "\n",
    "        # Asumimos T_pred=1, C=1 para el cálculo típico de pérdida por imagen\n",
    "        if pred_t != 1 or channels != 1:\n",
    "            logging.warning(f\"SSIMLoss: T_pred={pred_t}, channels={channels}. Se aplanarán estas dimensiones para SSIM.\")\n",
    "        \n",
    "        # Aplanar Z, B, T_pred para que se conviertan en el batch N para SSIM\n",
    "        # (Z * B * T_pred, C=1, H, W)\n",
    "        img1_reshaped = img1.permute(0, 1, 2, 5, 3, 4).contiguous().view(-1, channels, height, width)\n",
    "        img2_reshaped = img2.permute(0, 1, 2, 5, 3, 4).contiguous().view(-1, channels, height, width)\n",
    "        \n",
    "        ssim_val = self.ssim_metric(img1_reshaped, img2_reshaped)\n",
    "        return 1.0 - ssim_val # Queremos maximizar SSIM, así que minimizamos 1 - SSIM\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, config):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logging.info(f\"Usando dispositivo: {device}\")\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config.get('weight_decay', 1e-5))\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=config.get('lr_patience', 3), verbose=True)\n",
    "    \n",
    "    criterion_mse = nn.MSELoss().to(device)\n",
    "    criterion_ssim = None\n",
    "    if config.get('use_ssim_loss', False): # Añadir opción para usar SSIM\n",
    "        criterion_ssim = SSIMLoss(data_range=1.0, win_size=config.get('ssim_win_size', 7)).to(device)\n",
    "        ssim_loss_weight = config.get('ssim_loss_weight', 0.3) # e.g. 0.7*MSE + 0.3*SSIM\n",
    "        mse_loss_weight = 1.0 - ssim_loss_weight\n",
    "\n",
    "    scaler = GradScaler(enabled=config['use_amp'])\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses, val_losses = [], []\n",
    "    accumulation_steps = config.get('accumulation_steps', 1)\n",
    "\n",
    "    logging.info(f\"Iniciando entrenamiento: {config['epochs']} épocas, LR: {config['learning_rate']}, Batch (efectivo): {config['batch_size'] * accumulation_steps}\")\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for batch_idx, (x, y) in enumerate(train_loader):\n",
    "            # x: (Z, B_loader, T_in, H, W, C_in), y: (Z, B_loader, T_out, H, W, C_out)\n",
    "            # DataLoader batch_size (B_loader) es usualmente 1 para estos datos grandes.\n",
    "            # El modelo espera (Z, B_model, T_in, H, W, C_in)\n",
    "            x = x.to(device) # (Z, B_loader=1, T_in, H, W, C_in)\n",
    "            y = y.to(device) # (Z, B_loader=1, T_out, H, W, C_out)\n",
    "            # No es necesario squeeze/unsqueeze si B_loader ya es el B_model esperado (típicamente 1)\n",
    "\n",
    "            if batch_idx == 0 and epoch == 0:\n",
    "                logging.info(f\"Forma de entrada al modelo (primer batch): {x.shape}\")\n",
    "                logging.info(f\"Forma objetivo (primer batch): {y.shape}\")\n",
    "\n",
    "            with autocast(enabled=config['use_amp']):\n",
    "                predictions = model(x) # (Z, B_model, T_out, H, W, C_out)\n",
    "                loss_mse_val = criterion_mse(predictions, y)\n",
    "                if criterion_ssim:\n",
    "                    loss_ssim_val = criterion_ssim(predictions, y)\n",
    "                    loss = mse_loss_weight * loss_mse_val + ssim_loss_weight * loss_ssim_val\n",
    "                else:\n",
    "                    loss = loss_mse_val\n",
    "                loss = loss / accumulation_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                if config.get('clip_grad_norm', None):\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config['clip_grad_norm'])\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            running_train_loss += loss.item() * accumulation_steps\n",
    "            if (batch_idx + 1) % config.get('log_interval', 20) == 0: # Aumentar log interval para batches grandes\n",
    "                logging.info(f\"Época {epoch+1}/{config['epochs']} [{batch_idx+1}/{len(train_loader)}] - Pérdida: {loss.item() * accumulation_steps:.6f}\")\n",
    "        \n",
    "        avg_train_loss = running_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val in val_loader:\n",
    "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "                with autocast(enabled=config['use_amp']):\n",
    "                    predictions_val = model(x_val)\n",
    "                    val_loss_mse_val = criterion_mse(predictions_val, y_val)\n",
    "                    if criterion_ssim:\n",
    "                        val_loss_ssim_val = criterion_ssim(predictions_val, y_val)\n",
    "                        current_val_loss = mse_loss_weight * val_loss_mse_val + ssim_loss_weight * val_loss_ssim_val\n",
    "                    else:\n",
    "                        current_val_loss = val_loss_mse_val\n",
    "                running_val_loss += current_val_loss.item()\n",
    "        \n",
    "        avg_val_loss = running_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        scheduler.step(avg_val_loss)\n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "        logging.info(f\"Época {epoch+1} completada en {epoch_duration:.2f}s. Pérdida (train): {avg_train_loss:.6f}, Pérdida (val): {avg_val_loss:.6f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({'epoch': epoch + 1, 'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(), 'loss': best_val_loss},\n",
    "                       os.path.join(config['model_save_dir'], \"best_convlstm_model.pth\"))\n",
    "            logging.info(f\"Mejor modelo guardado (Pérdida Val: {best_val_loss:.6f})\")\n",
    "        if (epoch + 1) % config.get('checkpoint_interval', 5) == 0:\n",
    "            torch.save({'epoch': epoch + 1, 'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(), 'train_losses': train_losses,\n",
    "                        'val_losses': val_losses},\n",
    "                       os.path.join(config['model_save_dir'], f\"checkpoint_epoch_{epoch+1}.pth\"))\n",
    "            logging.info(f\"Checkpoint guardado en la época {epoch+1}\")\n",
    "\n",
    "    logging.info(\"Entrenamiento finalizado.\")\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(train_losses, label='Pérdida Entrenamiento')\n",
    "    plt.plot(val_losses, label='Pérdida Validación')\n",
    "    plt.xlabel('Épocas'); plt.ylabel('Pérdida'); plt.legend()\n",
    "    plt.savefig(os.path.join(config['model_save_dir'], \"loss_curves.png\")); plt.close()\n",
    "    return model, {'train_losses': train_losses, 'val_losses': val_losses}\n",
    "\n",
    "\n",
    "def generate_prediction_netcdf(model, data_loader, config, device, num_samples=1):\n",
    "    \"\"\"Genera y guarda predicciones en formato NetCDF con metadatos CF.\"\"\"\n",
    "    output_dir = config['predictions_output_dir']\n",
    "    min_dbz = config['min_dbz']\n",
    "    max_dbz = config['max_dbz']\n",
    "    variable_name = config.get('dbz_variable_name_pred', 'DBZ_predicted') # Nombre para la variable predicha\n",
    "\n",
    "    sensor_latitude = config.get('sensor_latitude', -34.64799880981445)\n",
    "    sensor_longitude = config.get('sensor_longitude', -68.01699829101562)\n",
    "    sensor_altitude_km = config.get('sensor_altitude_km', 0.550000011920929)\n",
    "    grid_minz_km = config.get('grid_minz_km', 1.0)\n",
    "    grid_dz_km = config.get('grid_dz_km', 0.5)\n",
    "    grid_minx_km = config.get('grid_minx_km', -249.75)\n",
    "    grid_dx_km = config.get('grid_dx_km', 0.5)\n",
    "    grid_miny_km = config.get('grid_miny_km', -249.75)\n",
    "    grid_dy_km = config.get('grid_dy_km', 0.5)\n",
    "    radar_name = config.get('radar_name', \"La Llave\")\n",
    "    institution_name = config.get('institution_name', \"Tu Institucion/Universidad\") # ¡Cambia esto!\n",
    "    data_source_name = config.get('data_source_name', \"Gobierno de Mendoza\")\n",
    "    # Nombre de la variable que contiene la información de la proyección\n",
    "    projection_var_name_in_file = config.get('projection_variable_name', \"radar_projection_info\")\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # --- Preparar arrays de coordenadas (asumiendo que son constantes) ---\n",
    "    num_z_output = config['expected_shape'][0] # 18\n",
    "    height = config['expected_shape'][1]       # 500\n",
    "    width = config['expected_shape'][2]        # 500\n",
    "\n",
    "    z_coord_values = np.arange(grid_minz_km, grid_minz_km + num_z_output * grid_dz_km, grid_dz_km)[:num_z_output]\n",
    "    x_coord_values = np.arange(grid_minx_km, grid_minx_km + width * grid_dx_km, grid_dx_km)[:width]\n",
    "    y_coord_values = np.arange(grid_miny_km, grid_miny_km + height * grid_dy_km, grid_dy_km)[:height]\n",
    "\n",
    "    # Determinar el tiempo base de la predicción.\n",
    "    # ### ¡DEBES ADAPTAR ESTO! ###\n",
    "    # Esto es un placeholder. Necesitas una lógica para obtener el tiempo correcto.\n",
    "    # Por ejemplo, si el DataLoader pudiera pasar el nombre del último archivo de la secuencia de entrada\n",
    "    # o si los nombres de las subcarpetas (e.g., '2020020320') se pueden usar para derivar el tiempo.\n",
    "    # Asumamos que podemos obtener el subdir_name del DataLoader si modificamos RadarDataset para devolverlo.\n",
    "    # O, si el DataLoader devuelve (x, y, subdir_name_or_last_input_file_path)\n",
    "    \n",
    "    # Iterar sobre el data_loader para generar predicciones\n",
    "    # for i, (x_input_volume, y_true_volume, source_info) in enumerate(data_loader):\n",
    "    #     # 'source_info' podría ser el subdir_name o path del último archivo de entrada\n",
    "    #     # para derivar 'current_pred_time'\n",
    "    #     ...\n",
    "    # Por ahora, simplificamos y usamos un tiempo base fijo + incremento para las muestras:\n",
    "    base_dt_for_samples = datetime.utcnow() # O tomarlo de config si se puede estimar\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (x_input_volume, y_true_volume) in enumerate(data_loader):\n",
    "            if i >= num_samples: break\n",
    "\n",
    "            current_pred_datetime = base_dt_for_samples + timedelta(minutes=i * config.get('prediction_interval_minutes', 5))\n",
    "\n",
    "            x_to_model = x_input_volume.to(device) # (Z, B=1, T_in, H, W, C_in)\n",
    "\n",
    "            with autocast(enabled=config['use_amp']):\n",
    "                prediction_norm = model(x_to_model) # (Z, B=1, T_out, H, W, C_out)\n",
    "\n",
    "            pred_data_np = prediction_norm.squeeze(1).squeeze(1).squeeze(-1).cpu().numpy() # (Z, H, W)\n",
    "            pred_data_desnorm = pred_data_np * (max_dbz - min_dbz) + min_dbz\n",
    "            pred_data_final_for_nc = np.expand_dims(pred_data_desnorm, axis=0) # (1=time, Z, H, W)\n",
    "\n",
    "            file_timestamp_str = current_pred_datetime.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_filename = os.path.join(output_dir, f\"pred_{variable_name}_{file_timestamp_str}_sample{i}.nc\")\n",
    "\n",
    "            with NCDataset(output_filename, 'w', format='NETCDF4') as ncfile:\n",
    "                ncfile.Conventions = \"CF-1.7\"\n",
    "                ncfile.title = f\"Radar Reflectivity Forecast ({variable_name}) from ConvLSTM Model\"\n",
    "                ncfile.institution = institution_name\n",
    "                ncfile.source_data_description = f\"Based on input data from {data_source_name}, Radar: {radar_name}.\"\n",
    "                ncfile.source_model_description = \"ConvLSTM neural network prediction.\"\n",
    "                ncfile.history = f\"Created {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')} by prediction script.\"\n",
    "                ncfile.comment = \"Model-generated forecast. Not for operational use without verification.\"\n",
    "                ncfile.radar_name = radar_name\n",
    "                ncfile.sensor_latitude = sensor_latitude\n",
    "                ncfile.sensor_longitude = sensor_longitude\n",
    "                ncfile.sensor_altitude = sensor_altitude_km\n",
    "                ncfile.references = \"Tesis de [Tu Nombre], [Tu Universidad/Institucion]\" # ¡Actualiza esto!\n",
    "\n",
    "                ncfile.createDimension('time', 1)\n",
    "                ncfile.createDimension('level', num_z_output)\n",
    "                ncfile.createDimension('y', height)\n",
    "                ncfile.createDimension('x', width)\n",
    "\n",
    "                time_var = ncfile.createVariable('time', 'f8', ('time',))\n",
    "                epoch_time = datetime(1970, 1, 1, 0, 0, 0)\n",
    "                time_value_seconds = (current_pred_datetime.replace(tzinfo=None) - epoch_time).total_seconds()\n",
    "                time_var[:] = [time_value_seconds]\n",
    "                time_var.units = \"seconds since 1970-01-01 00:00:00 UTC\"\n",
    "                time_var.calendar = \"gregorian\"\n",
    "                time_var.long_name = \"time of forecast\"; time_var.standard_name = \"time\"; time_var.axis = \"T\"\n",
    "\n",
    "                z_coord = ncfile.createVariable('level', 'f4', ('level',))\n",
    "                z_coord[:] = z_coord_values\n",
    "                z_coord.units = \"km\"; z_coord.positive = \"up\"; z_coord.long_name = \"altitude\"; z_coord.standard_name = \"altitude\"; z_coord.axis = \"Z\"\n",
    "\n",
    "                x_coord = ncfile.createVariable('x', 'f4', ('x',))\n",
    "                x_coord[:] = x_coord_values\n",
    "                x_coord.units = \"km\"; x_coord.long_name = \"projection_x_coordinate\"; x_coord.standard_name = \"projection_x_coordinate\"; x_coord.axis = \"X\"\n",
    "\n",
    "                y_coord = ncfile.createVariable('y', 'f4', ('y',))\n",
    "                y_coord[:] = y_coord_values\n",
    "                y_coord.units = \"km\"; y_coord.long_name = \"projection_y_coordinate\"; y_coord.standard_name = \"projection_y_coordinate\"; y_coord.axis = \"Y\"\n",
    "                \n",
    "                # Variable de Proyección\n",
    "                # Para MDV proj_type=8 (PROJ_AZIMUTHAL_ORTHOGRAPHIC o PROJ_LAMBERT_AZIMUTHAL),\n",
    "                # el nombre CF podría ser \"azimuthal_equidistant\" o \"lambert_azimuthal_equal_area\".\n",
    "                # Py-ART usa \"AEA\" para Lambert Azimuthal Equal Area.\n",
    "                # Vamos a usar \"lambert_azimuthal_equal_area\" que es un nombre CF estándar.\n",
    "                projection_var = ncfile.createVariable(projection_var_name_in_file, 'i4')\n",
    "                projection_var.grid_mapping_name = \"lambert_azimuthal_equal_area\"\n",
    "                projection_var.longitude_of_projection_origin = sensor_longitude\n",
    "                projection_var.latitude_of_projection_origin = sensor_latitude\n",
    "                projection_var.false_easting = 0.0\n",
    "                projection_var.false_northing = 0.0\n",
    "                # Podrías necesitar:\n",
    "                # projection_var.semi_major_axis = 6378137.0 (para WGS84)\n",
    "                # projection_var.inverse_flattening = 298.257223563 (para WGS84)\n",
    "\n",
    "                pred_dbz_var = ncfile.createVariable(variable_name, 'f4', ('time', 'level', 'y', 'x'),\n",
    "                                                 fill_value=np.float32(config.get('fill_value', -9999.0)))\n",
    "                pred_dbz_var.units = 'dBZ'\n",
    "                pred_dbz_var.long_name = 'Predicted Radar Reflectivity'\n",
    "                pred_dbz_var.coordinates = \"time level y x\" # Opcional, pero bueno tenerlo.\n",
    "                pred_dbz_var.grid_mapping = projection_var_name_in_file\n",
    "                pred_dbz_var[:] = pred_data_final_for_nc\n",
    "\n",
    "            logging.info(f\"Predicción de muestra con metadatos CF guardada en: {output_filename}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    set_seed(42)\n",
    "    # --- Configuración del Experimento ---\n",
    "    config = {\n",
    "        'data_dir': \"/home/first_try_nc\",\n",
    "        'model_save_dir': \"/home/model_output_enhanced_v2\",\n",
    "        'predictions_output_dir': \"/home/predictions_enhanced_v2\",\n",
    "        'seq_len': 6, 'pred_len': 1, 'pred_steps_model': 1,\n",
    "        'min_dbz': -30.0, 'max_dbz': 70.0, 'fill_value': -9999.0,\n",
    "        'expected_shape': (18, 500, 500), # (Z, H, W)\n",
    "        'dbz_variable_name': 'DBZ', # Variable en archivos de entrada\n",
    "        'dbz_variable_name_pred': 'DBZ_forecast', # Variable en archivos de salida\n",
    "\n",
    "        # Metadatos para NetCDF de salida (tomados de tu MDV y convenciones CF)\n",
    "        'sensor_latitude': -34.64799880981445,\n",
    "        'sensor_longitude': -68.01699829101562,\n",
    "        'sensor_altitude_km': 0.550000011920929,\n",
    "        'grid_minz_km': 1.0, 'grid_dz_km': 0.5,\n",
    "        'grid_minx_km': -249.75, 'grid_dx_km': 0.5,\n",
    "        'grid_miny_km': -249.75, 'grid_dy_km': 0.5,\n",
    "        'radar_name': \"La Llave\",\n",
    "        'institution_name': \"Universidad de Mendoza - Federico Caballero\", # ¡Actualiza esto!\n",
    "        'data_source_name': \"Gobierno de Mendoza\",\n",
    "        'projection_variable_name': \"lambert_azimuthal_projection\", # Nombre de la var de grid_mapping\n",
    "        'prediction_interval_minutes': 5, # Asumiendo que tus secuencias son cada 5 minutos\n",
    "\n",
    "        # Hiperparámetros del modelo\n",
    "        'model_input_dim': 1,\n",
    "        'model_hidden_dims': [64, 128, 64],\n",
    "        'model_kernel_sizes': [(3,3), (3,3), (3,3)],\n",
    "        'model_num_layers': 3,\n",
    "        'model_use_layer_norm': True,\n",
    "        'model_use_residual': False, # Prueba True si el modelo es muy profundo\n",
    "\n",
    "        # Hiperparámetros de entrenamiento\n",
    "        'batch_size': 1, # Para DataLoader. El modelo internamente procesa Z niveles x B=1.\n",
    "        'epochs': 50, # Aumentado para un entrenamiento más completo\n",
    "        'learning_rate': 1e-4,\n",
    "        'weight_decay': 1e-5,\n",
    "        'lr_patience': 7, # Aumentada un poco la paciencia\n",
    "        'use_amp': True,\n",
    "        'accumulation_steps': 4, # Efectivo batch size = 4\n",
    "        'clip_grad_norm': 1.0,\n",
    "        'log_interval': 10, # Log cada 10 batches *efectivos* (10 * accumulation_steps)\n",
    "        'checkpoint_interval': 5,\n",
    "        'use_ssim_loss': True, # Habilitar pérdida combinada\n",
    "        'ssim_win_size': 7, # Tamaño de ventana para SSIM\n",
    "        'ssim_loss_weight': 0.3, # 30% SSIM, 70% MSE\n",
    "\n",
    "        'train_val_split_ratio': 0.8,\n",
    "        'max_sequences_to_use': None, # None para usar todas las secuencias disponibles\n",
    "                                      # Pon un número (e.g. 200) para pruebas rápidas\n",
    "    }\n",
    "\n",
    "    os.makedirs(config['model_save_dir'], exist_ok=True)\n",
    "    os.makedirs(config['predictions_output_dir'], exist_ok=True)\n",
    "\n",
    "    all_subdirs_available = sorted([d for d in os.listdir(config['data_dir']) if os.path.isdir(os.path.join(config['data_dir'], d))])\n",
    "    if not all_subdirs_available: logging.error(f\"No subdirs in {config['data_dir']}\"); return\n",
    "\n",
    "    if config['max_sequences_to_use'] and config['max_sequences_to_use'] < len(all_subdirs_available):\n",
    "        logging.info(f\"Usando muestra aleatoria de {config['max_sequences_to_use']} secuencias.\")\n",
    "        random.shuffle(all_subdirs_available)\n",
    "        subdirs_to_use = all_subdirs_available[:config['max_sequences_to_use']]\n",
    "    else:\n",
    "        subdirs_to_use = all_subdirs_available\n",
    "    logging.info(f\"Total secuencias a usar: {len(subdirs_to_use)}.\")\n",
    "\n",
    "    split_idx = int(len(subdirs_to_use) * config['train_val_split_ratio'])\n",
    "    train_subdirs, val_subdirs = subdirs_to_use[:split_idx], subdirs_to_use[split_idx:]\n",
    "    logging.info(f\"Entrenamiento: {len(train_subdirs)} secuencias. Validación: {len(val_subdirs)} secuencias.\")\n",
    "\n",
    "    train_dataset = RadarDataset(config['data_dir'], train_subdirs, seq_len=config['seq_len'], pred_len=config['pred_len'],\n",
    "                                 min_dbz=config['min_dbz'], max_dbz=config['max_dbz'],\n",
    "                                 expected_shape=config['expected_shape'], variable_name=config['dbz_variable_name'])\n",
    "    val_dataset = RadarDataset(config['data_dir'], val_subdirs, seq_len=config['seq_len'], pred_len=config['pred_len'],\n",
    "                               min_dbz=config['min_dbz'], max_dbz=config['max_dbz'],\n",
    "                               expected_shape=config['expected_shape'], variable_name=config['dbz_variable_name'])\n",
    "\n",
    "    if len(train_dataset) == 0 or (len(val_subdirs) > 0 and len(val_dataset) == 0) : # Asegurarse que val_dataset se cree si hay val_subdirs\n",
    "        logging.error(\"Dataset de entrenamiento o validación vacío. Revisa la carga de datos y el split.\"); return\n",
    "\n",
    "    # num_workers=0 puede ser más estable en algunos entornos, especialmente si hay problemas con la carga de datos\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=2, pin_memory=True, prefetch_factor=2 if config.get('batch_size',1) > 1 else None)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=2, pin_memory=True, prefetch_factor=2 if config.get('batch_size',1) > 1 else None) if len(val_dataset) > 0 else None\n",
    "\n",
    "\n",
    "    model = ConvLSTM3D_Enhanced(\n",
    "        input_dim=config['model_input_dim'], hidden_dims=config['model_hidden_dims'],\n",
    "        kernel_sizes=config['model_kernel_sizes'], num_layers=config['model_num_layers'],\n",
    "        pred_steps=config['pred_steps_model'], use_layer_norm=config['model_use_layer_norm'],\n",
    "        use_residual=config['model_use_residual'],\n",
    "        img_height=config['expected_shape'][1], img_width=config['expected_shape'][2] # Pasar H, W para LayerNorm\n",
    "    )\n",
    "    logging.info(f\"Arquitectura del modelo:\\n{model}\")\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    logging.info(f\"Número total de parámetros entrenables: {total_params:,}\")\n",
    "\n",
    "    trained_model, history = train_model(model, train_loader, val_loader, config)\n",
    "\n",
    "    if val_loader: # Solo generar predicciones si hay datos de validación\n",
    "        logging.info(\"Generando predicciones de ejemplo usando el conjunto de validación...\")\n",
    "        generate_prediction_netcdf(trained_model, val_loader, config,\n",
    "                                   device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "                                   num_samples=min(5, len(val_dataset)))\n",
    "    else:\n",
    "        logging.info(\"No hay datos de validación, se omiten las predicciones de ejemplo.\")\n",
    "\n",
    "    logging.info(\"Proceso completado.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
